{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 74 Final Project\n",
    "## Logan Chang, Prof. Vosoughi, 23W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## IMPORTS\n",
    "import autograd.numpy as np\n",
    "from autograd import grad \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import precision_recall_fscore_support, f1_score, roc_curve, auc, roc_auc_score, accuracy_score, silhouette_score, confusion_matrix\n",
    "from sklearn.metrics.cluster import rand_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression, Perceptron, SGDClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Standard Functions for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## export results from regression prediction to csv\n",
    "def out_results(y_hat, class_name, num):\n",
    "    outdf = pd.DataFrame({'id': range(len(y_hat)), 'predicted': y_hat})\n",
    "    if num != 0:\n",
    "        outdf.to_csv(f'{class_name}_{num}.csv', index=False)\n",
    "    else:\n",
    "        outdf.to_csv(f'{class_name}.csv', index=False)\n",
    "\n",
    "## construct cutoff labels \n",
    "def construct_labels(df_train, cutoff):\n",
    "    df_train['cutoff'] = [1 if x>cutoff else 0 for x in df_train['overall']]\n",
    "    return df_train['cutoff']\n",
    "    \n",
    "## get classification metrics and aggregate to results dict\n",
    "def get_metrics(results, y_test, y_pred, num_classes):\n",
    "    ## accuracy, precision, recall, f1, confusion matrix\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(y_test, y_pred, average='macro')\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    if num_classes != 5:\n",
    "        roc_auc = roc_auc_score(y_test, y_pred)\n",
    "    c_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    ## aggregate metrics to results dict\n",
    "    results['Accuracy'].append(accuracy)\n",
    "    results['Precision'].append(precision)\n",
    "    results['Recall'].append(recall)\n",
    "    results['F1'].append(f1)\n",
    "    if num_classes != 5:\n",
    "        results['ROC_AUC'].append(roc_auc)\n",
    "    results['Confusion Matrix'].append(c_matrix)\n",
    "    \n",
    "    return results\n",
    "\n",
    "## print formatting of average classification metrics for k-fold CV\n",
    "def cv_metrics(model, num_classes, gaussian=False):  \n",
    "    \n",
    "    kf = KFold(n_splits=5)\n",
    "    ## data transform for gaussian model\n",
    "    if gaussian:\n",
    "        X = X_train.toarray()\n",
    "    else:\n",
    "        X = X_train\n",
    "    \n",
    "    ## instantiate output structs\n",
    "    results = {'Accuracy' : [], 'Precision' : [], 'Recall' : [], 'F1' : [], 'ROC_AUC': [], 'Confusion Matrix': []}\n",
    "    matrix = np.zeros((num_classes, num_classes))\n",
    "    \n",
    "    ## aggregate metrics across all folds\n",
    "    for train_index, test_index in kf.split(X, y_train):\n",
    "        cv_X_train = X[train_index]\n",
    "        cv_X_test = X[test_index]\n",
    "        cv_y_train = y_train[train_index]\n",
    "        cv_y_test = y_train[test_index]\n",
    "\n",
    "        model.fit(cv_X_train, cv_y_train)\n",
    "        y_hat = model.predict(cv_X_test).astype(int)\n",
    "        results = get_metrics(results, cv_y_test, y_hat, num_classes)\n",
    "\n",
    "    ## average metrics\n",
    "    f1_avg = sum(results['F1']) / len(results['F1'])\n",
    "    accuracy_avg = sum(results['Accuracy']) / len(results['Accuracy'])\n",
    "    precision_avg = sum(results['Precision']) / len(results['Precision'])\n",
    "    if num_classes != 5:\n",
    "        roc_auc_avg = sum(results['ROC_AUC']) / len(results['ROC_AUC'])\n",
    "    for item in results['Confusion Matrix']:\n",
    "        matrix = np.add(matrix, item)\n",
    "    matrix_avg = matrix / len(results['Confusion Matrix'])\n",
    "\n",
    "    ## print results\n",
    "    print(f\"Accuracy Average: {accuracy_avg}\")\n",
    "    print(f\"Precision Average: {precision_avg}\")\n",
    "    print(f\"F1 Score Average: {f1_avg}\")\n",
    "    if num_classes != 5:\n",
    "        print(f\"ROC AUC Score Average: {roc_auc_avg}\")\n",
    "    print(\"Confusion Matrix Average:\")\n",
    "    for i in range(num_classes):\n",
    "        print(str(matrix_avg[i]))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Processing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read data\n",
    "df_train = pd.read_csv('Train.csv').fillna('NULL')\n",
    "df_test = pd.read_csv('Test.csv').fillna('NULL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## vectorize both text features into TF-IDF matrices\n",
    "\n",
    "## vectorizer for reviewText\n",
    "review_vectorizer = TfidfVectorizer(max_features = 1500)\n",
    "train_review_mat = review_vectorizer.fit_transform(df_train['reviewText'].tolist())\n",
    "test_review_mat = review_vectorizer.transform(df_test['reviewText'].tolist())\n",
    "\n",
    "## vectorizer for summary\n",
    "summary_vectorizer = TfidfVectorizer(max_features = 1500)\n",
    "train_summary_mat = summary_vectorizer.fit_transform(df_train['summary'].tolist())\n",
    "test_summary_mat = summary_vectorizer.transform(df_test['summary'].tolist())\n",
    "\n",
    "## build train, test features\n",
    "### keep csr format of TF-IDF matrices\n",
    "X_train = hstack((train_review_mat, train_summary_mat), format='csr')\n",
    "X_test = hstack((test_review_mat, test_summary_mat), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## add verified review to feature matrix\n",
    "train_verified = df_train['verified'].astype(int).values.reshape(len(df_train['verified']), 1)\n",
    "test_verified = df_test['verified'].astype(int).values.reshape(len(df_test['verified']), 1)\n",
    "X_train = hstack((X_train, train_verified), format='csr')\n",
    "X_test = hstack((X_test, test_verified), format='csr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(29189, 3001)\n",
      "(4500, 3001)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set binary cutoff to 1\n",
    "y_train = construct_labels(df_train, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression with optimal hyperparameters had an average macro f1 score of 0.7677168793563615 using the following hyperparameters: {'C': 1, 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "logReg = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)\n",
    "logReg_params = {'penalty':['l1', 'l2'], 'C':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "logReg_tuner = GridSearchCV(logReg, logReg_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "logReg_tuner.fit(X_train, y_train)\n",
    "print('Logisitic Regression with optimal hyperparameters had an average macro f1 score of '+str(logReg_tuner.best_score_)+' using the following hyperparameters: '+str(logReg_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.081772</td>\n",
       "      <td>0.007043</td>\n",
       "      <td>0.004382</td>\n",
       "      <td>0.001005</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.587992</td>\n",
       "      <td>0.525875</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.606684</td>\n",
       "      <td>0.594970</td>\n",
       "      <td>0.581133</td>\n",
       "      <td>0.028376</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.380659</td>\n",
       "      <td>0.600190</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.587840</td>\n",
       "      <td>0.526970</td>\n",
       "      <td>0.588144</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.581144</td>\n",
       "      <td>0.027982</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059086</td>\n",
       "      <td>0.006212</td>\n",
       "      <td>0.004066</td>\n",
       "      <td>0.000536</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.598415</td>\n",
       "      <td>0.571461</td>\n",
       "      <td>0.592660</td>\n",
       "      <td>0.613658</td>\n",
       "      <td>0.605990</td>\n",
       "      <td>0.596437</td>\n",
       "      <td>0.014351</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.064297</td>\n",
       "      <td>0.003966</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000336</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.598437</td>\n",
       "      <td>0.544519</td>\n",
       "      <td>0.593506</td>\n",
       "      <td>0.616859</td>\n",
       "      <td>0.607000</td>\n",
       "      <td>0.592064</td>\n",
       "      <td>0.025064</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.070071</td>\n",
       "      <td>0.011876</td>\n",
       "      <td>0.002825</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.481214</td>\n",
       "      <td>0.389174</td>\n",
       "      <td>0.484396</td>\n",
       "      <td>0.487811</td>\n",
       "      <td>0.480011</td>\n",
       "      <td>0.464521</td>\n",
       "      <td>0.037771</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.085105</td>\n",
       "      <td>0.005821</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.712049</td>\n",
       "      <td>0.669077</td>\n",
       "      <td>0.755293</td>\n",
       "      <td>0.768021</td>\n",
       "      <td>0.762227</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.037688</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.051912</td>\n",
       "      <td>0.003537</td>\n",
       "      <td>0.003041</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.482260</td>\n",
       "      <td>0.389002</td>\n",
       "      <td>0.490726</td>\n",
       "      <td>0.491611</td>\n",
       "      <td>0.480476</td>\n",
       "      <td>0.466815</td>\n",
       "      <td>0.039158</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.070667</td>\n",
       "      <td>0.003917</td>\n",
       "      <td>0.002914</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.729478</td>\n",
       "      <td>0.673569</td>\n",
       "      <td>0.772763</td>\n",
       "      <td>0.786352</td>\n",
       "      <td>0.789676</td>\n",
       "      <td>0.750368</td>\n",
       "      <td>0.043991</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.116204</td>\n",
       "      <td>0.007194</td>\n",
       "      <td>0.003940</td>\n",
       "      <td>0.000434</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.689447</td>\n",
       "      <td>0.589260</td>\n",
       "      <td>0.669533</td>\n",
       "      <td>0.702254</td>\n",
       "      <td>0.693914</td>\n",
       "      <td>0.668882</td>\n",
       "      <td>0.041239</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.121444</td>\n",
       "      <td>0.009304</td>\n",
       "      <td>0.002821</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.710513</td>\n",
       "      <td>0.601182</td>\n",
       "      <td>0.689509</td>\n",
       "      <td>0.722044</td>\n",
       "      <td>0.714928</td>\n",
       "      <td>0.687635</td>\n",
       "      <td>0.044564</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.075617</td>\n",
       "      <td>0.007333</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.697655</td>\n",
       "      <td>0.611404</td>\n",
       "      <td>0.680533</td>\n",
       "      <td>0.703269</td>\n",
       "      <td>0.702248</td>\n",
       "      <td>0.679022</td>\n",
       "      <td>0.034782</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.097920</td>\n",
       "      <td>0.009052</td>\n",
       "      <td>0.002984</td>\n",
       "      <td>0.000438</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.719590</td>\n",
       "      <td>0.636887</td>\n",
       "      <td>0.698545</td>\n",
       "      <td>0.727786</td>\n",
       "      <td>0.730521</td>\n",
       "      <td>0.702666</td>\n",
       "      <td>0.034748</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.156426</td>\n",
       "      <td>0.014880</td>\n",
       "      <td>0.003656</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.696580</td>\n",
       "      <td>0.661092</td>\n",
       "      <td>0.751579</td>\n",
       "      <td>0.760174</td>\n",
       "      <td>0.752551</td>\n",
       "      <td>0.724395</td>\n",
       "      <td>0.038969</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.131049</td>\n",
       "      <td>0.006483</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.730261</td>\n",
       "      <td>0.704475</td>\n",
       "      <td>0.781394</td>\n",
       "      <td>0.790060</td>\n",
       "      <td>0.794047</td>\n",
       "      <td>0.760048</td>\n",
       "      <td>0.036022</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.075346</td>\n",
       "      <td>0.009158</td>\n",
       "      <td>0.003738</td>\n",
       "      <td>0.000396</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.712753</td>\n",
       "      <td>0.670191</td>\n",
       "      <td>0.757755</td>\n",
       "      <td>0.775327</td>\n",
       "      <td>0.772376</td>\n",
       "      <td>0.737680</td>\n",
       "      <td>0.040497</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.122189</td>\n",
       "      <td>0.012815</td>\n",
       "      <td>0.002940</td>\n",
       "      <td>0.000162</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.738102</td>\n",
       "      <td>0.700395</td>\n",
       "      <td>0.782271</td>\n",
       "      <td>0.794746</td>\n",
       "      <td>0.799211</td>\n",
       "      <td>0.762945</td>\n",
       "      <td>0.038025</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.274086</td>\n",
       "      <td>0.015564</td>\n",
       "      <td>0.004301</td>\n",
       "      <td>0.001495</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.767986</td>\n",
       "      <td>0.694454</td>\n",
       "      <td>0.771061</td>\n",
       "      <td>0.799118</td>\n",
       "      <td>0.797448</td>\n",
       "      <td>0.766013</td>\n",
       "      <td>0.038037</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.183225</td>\n",
       "      <td>0.017533</td>\n",
       "      <td>0.002849</td>\n",
       "      <td>0.000242</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.767967</td>\n",
       "      <td>0.684439</td>\n",
       "      <td>0.770808</td>\n",
       "      <td>0.798703</td>\n",
       "      <td>0.794681</td>\n",
       "      <td>0.763320</td>\n",
       "      <td>0.041317</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.116482</td>\n",
       "      <td>0.009587</td>\n",
       "      <td>0.003482</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.765871</td>\n",
       "      <td>0.701554</td>\n",
       "      <td>0.773465</td>\n",
       "      <td>0.795913</td>\n",
       "      <td>0.801740</td>\n",
       "      <td>0.767709</td>\n",
       "      <td>0.035683</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.147410</td>\n",
       "      <td>0.010926</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.765569</td>\n",
       "      <td>0.700428</td>\n",
       "      <td>0.769677</td>\n",
       "      <td>0.798990</td>\n",
       "      <td>0.800374</td>\n",
       "      <td>0.767008</td>\n",
       "      <td>0.036272</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.360930</td>\n",
       "      <td>0.050944</td>\n",
       "      <td>0.003906</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.733478</td>\n",
       "      <td>0.710972</td>\n",
       "      <td>0.776237</td>\n",
       "      <td>0.796143</td>\n",
       "      <td>0.799909</td>\n",
       "      <td>0.763348</td>\n",
       "      <td>0.035253</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.217883</td>\n",
       "      <td>0.010197</td>\n",
       "      <td>0.002909</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.741309</td>\n",
       "      <td>0.711564</td>\n",
       "      <td>0.780576</td>\n",
       "      <td>0.799511</td>\n",
       "      <td>0.801763</td>\n",
       "      <td>0.766945</td>\n",
       "      <td>0.035165</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.143203</td>\n",
       "      <td>0.010790</td>\n",
       "      <td>0.003532</td>\n",
       "      <td>0.000252</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.736546</td>\n",
       "      <td>0.711001</td>\n",
       "      <td>0.777663</td>\n",
       "      <td>0.797535</td>\n",
       "      <td>0.805213</td>\n",
       "      <td>0.765592</td>\n",
       "      <td>0.036221</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.191569</td>\n",
       "      <td>0.016733</td>\n",
       "      <td>0.003139</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.742097</td>\n",
       "      <td>0.712378</td>\n",
       "      <td>0.781467</td>\n",
       "      <td>0.799496</td>\n",
       "      <td>0.803146</td>\n",
       "      <td>0.767717</td>\n",
       "      <td>0.035137</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.536918</td>\n",
       "      <td>0.018426</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.000568</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.748822</td>\n",
       "      <td>0.692643</td>\n",
       "      <td>0.760700</td>\n",
       "      <td>0.786406</td>\n",
       "      <td>0.782894</td>\n",
       "      <td>0.754293</td>\n",
       "      <td>0.033826</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.283191</td>\n",
       "      <td>0.013816</td>\n",
       "      <td>0.002921</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.758831</td>\n",
       "      <td>0.705595</td>\n",
       "      <td>0.771304</td>\n",
       "      <td>0.795502</td>\n",
       "      <td>0.791842</td>\n",
       "      <td>0.764615</td>\n",
       "      <td>0.032425</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.178777</td>\n",
       "      <td>0.012223</td>\n",
       "      <td>0.003853</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.750614</td>\n",
       "      <td>0.696861</td>\n",
       "      <td>0.761875</td>\n",
       "      <td>0.789900</td>\n",
       "      <td>0.786886</td>\n",
       "      <td>0.757227</td>\n",
       "      <td>0.033635</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.268794</td>\n",
       "      <td>0.027746</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.758081</td>\n",
       "      <td>0.705580</td>\n",
       "      <td>0.772409</td>\n",
       "      <td>0.793400</td>\n",
       "      <td>0.793370</td>\n",
       "      <td>0.764568</td>\n",
       "      <td>0.032385</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.566356</td>\n",
       "      <td>0.028291</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.724418</td>\n",
       "      <td>0.690212</td>\n",
       "      <td>0.760686</td>\n",
       "      <td>0.778125</td>\n",
       "      <td>0.767933</td>\n",
       "      <td>0.744275</td>\n",
       "      <td>0.032533</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.367018</td>\n",
       "      <td>0.017780</td>\n",
       "      <td>0.002931</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.732482</td>\n",
       "      <td>0.701919</td>\n",
       "      <td>0.767154</td>\n",
       "      <td>0.786352</td>\n",
       "      <td>0.779577</td>\n",
       "      <td>0.753497</td>\n",
       "      <td>0.031774</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.214804</td>\n",
       "      <td>0.012414</td>\n",
       "      <td>0.004107</td>\n",
       "      <td>0.001319</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.724072</td>\n",
       "      <td>0.690047</td>\n",
       "      <td>0.761813</td>\n",
       "      <td>0.778861</td>\n",
       "      <td>0.767333</td>\n",
       "      <td>0.744425</td>\n",
       "      <td>0.032815</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.345410</td>\n",
       "      <td>0.026685</td>\n",
       "      <td>0.003089</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.732427</td>\n",
       "      <td>0.701676</td>\n",
       "      <td>0.767154</td>\n",
       "      <td>0.786089</td>\n",
       "      <td>0.779903</td>\n",
       "      <td>0.753450</td>\n",
       "      <td>0.031860</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.081772      0.007043         0.004382        0.001005    0.01   \n",
       "1        0.380659      0.600190         0.002845        0.000182    0.01   \n",
       "2        0.059086      0.006212         0.004066        0.000536    0.01   \n",
       "3        0.064297      0.003966         0.002806        0.000336    0.01   \n",
       "4        0.070071      0.011876         0.002825        0.000312    0.01   \n",
       "5        0.085105      0.005821         0.003011        0.000140    0.01   \n",
       "6        0.051912      0.003537         0.003041        0.000188    0.01   \n",
       "7        0.070667      0.003917         0.002914        0.000285    0.01   \n",
       "8        0.116204      0.007194         0.003940        0.000434     0.1   \n",
       "9        0.121444      0.009304         0.002821        0.000144     0.1   \n",
       "10       0.075617      0.007333         0.003552        0.000220     0.1   \n",
       "11       0.097920      0.009052         0.002984        0.000438     0.1   \n",
       "12       0.156426      0.014880         0.003656        0.000255     0.1   \n",
       "13       0.131049      0.006483         0.002902        0.000280     0.1   \n",
       "14       0.075346      0.009158         0.003738        0.000396     0.1   \n",
       "15       0.122189      0.012815         0.002940        0.000162     0.1   \n",
       "16       0.274086      0.015564         0.004301        0.001495       1   \n",
       "17       0.183225      0.017533         0.002849        0.000242       1   \n",
       "18       0.116482      0.009587         0.003482        0.000168       1   \n",
       "19       0.147410      0.010926         0.002973        0.000313       1   \n",
       "20       0.360930      0.050944         0.003906        0.000326       1   \n",
       "21       0.217883      0.010197         0.002909        0.000252       1   \n",
       "22       0.143203      0.010790         0.003532        0.000252       1   \n",
       "23       0.191569      0.016733         0.003139        0.000634       1   \n",
       "24       0.536918      0.018426         0.003920        0.000568      10   \n",
       "25       0.283191      0.013816         0.002921        0.000253      10   \n",
       "26       0.178777      0.012223         0.003853        0.000353      10   \n",
       "27       0.268794      0.027746         0.002824        0.000249      10   \n",
       "28       0.566356      0.028291         0.003655        0.000342      10   \n",
       "29       0.367018      0.017780         0.002931        0.000205      10   \n",
       "30       0.214804      0.012414         0.004107        0.001319      10   \n",
       "31       0.345410      0.026685         0.003089        0.000540      10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None               False            l1   \n",
       "3                None               False            l2   \n",
       "4            balanced                True            l1   \n",
       "5            balanced                True            l2   \n",
       "6            balanced               False            l1   \n",
       "7            balanced               False            l2   \n",
       "8                None                True            l1   \n",
       "9                None                True            l2   \n",
       "10               None               False            l1   \n",
       "11               None               False            l2   \n",
       "12           balanced                True            l1   \n",
       "13           balanced                True            l2   \n",
       "14           balanced               False            l1   \n",
       "15           balanced               False            l2   \n",
       "16               None                True            l1   \n",
       "17               None                True            l2   \n",
       "18               None               False            l1   \n",
       "19               None               False            l2   \n",
       "20           balanced                True            l1   \n",
       "21           balanced                True            l2   \n",
       "22           balanced               False            l1   \n",
       "23           balanced               False            l2   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None               False            l1   \n",
       "27               None               False            l2   \n",
       "28           balanced                True            l1   \n",
       "29           balanced                True            l2   \n",
       "30           balanced               False            l1   \n",
       "31           balanced               False            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.587992   \n",
       "1   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.587840   \n",
       "2   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.598415   \n",
       "3   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.598437   \n",
       "4   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.481214   \n",
       "5   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.712049   \n",
       "6   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.482260   \n",
       "7   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.729478   \n",
       "8   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.689447   \n",
       "9   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.710513   \n",
       "10  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.697655   \n",
       "11  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.719590   \n",
       "12  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.696580   \n",
       "13  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.730261   \n",
       "14  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.712753   \n",
       "15  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.738102   \n",
       "16  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.767986   \n",
       "17  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.767967   \n",
       "18  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.765871   \n",
       "19  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.765569   \n",
       "20  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.733478   \n",
       "21  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.741309   \n",
       "22  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.736546   \n",
       "23  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.742097   \n",
       "24  {'C': 10, 'class_weight': None, 'fit_intercept...           0.748822   \n",
       "25  {'C': 10, 'class_weight': None, 'fit_intercept...           0.758831   \n",
       "26  {'C': 10, 'class_weight': None, 'fit_intercept...           0.750614   \n",
       "27  {'C': 10, 'class_weight': None, 'fit_intercept...           0.758081   \n",
       "28  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.724418   \n",
       "29  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.732482   \n",
       "30  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.724072   \n",
       "31  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.732427   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.525875           0.590147           0.606684   \n",
       "1            0.526970           0.588144           0.607172   \n",
       "2            0.571461           0.592660           0.613658   \n",
       "3            0.544519           0.593506           0.616859   \n",
       "4            0.389174           0.484396           0.487811   \n",
       "5            0.669077           0.755293           0.768021   \n",
       "6            0.389002           0.490726           0.491611   \n",
       "7            0.673569           0.772763           0.786352   \n",
       "8            0.589260           0.669533           0.702254   \n",
       "9            0.601182           0.689509           0.722044   \n",
       "10           0.611404           0.680533           0.703269   \n",
       "11           0.636887           0.698545           0.727786   \n",
       "12           0.661092           0.751579           0.760174   \n",
       "13           0.704475           0.781394           0.790060   \n",
       "14           0.670191           0.757755           0.775327   \n",
       "15           0.700395           0.782271           0.794746   \n",
       "16           0.694454           0.771061           0.799118   \n",
       "17           0.684439           0.770808           0.798703   \n",
       "18           0.701554           0.773465           0.795913   \n",
       "19           0.700428           0.769677           0.798990   \n",
       "20           0.710972           0.776237           0.796143   \n",
       "21           0.711564           0.780576           0.799511   \n",
       "22           0.711001           0.777663           0.797535   \n",
       "23           0.712378           0.781467           0.799496   \n",
       "24           0.692643           0.760700           0.786406   \n",
       "25           0.705595           0.771304           0.795502   \n",
       "26           0.696861           0.761875           0.789900   \n",
       "27           0.705580           0.772409           0.793400   \n",
       "28           0.690212           0.760686           0.778125   \n",
       "29           0.701919           0.767154           0.786352   \n",
       "30           0.690047           0.761813           0.778861   \n",
       "31           0.701676           0.767154           0.786089   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.594970         0.581133        0.028376               30  \n",
       "1            0.595595         0.581144        0.027982               29  \n",
       "2            0.605990         0.596437        0.014351               27  \n",
       "3            0.607000         0.592064        0.025064               28  \n",
       "4            0.480011         0.464521        0.037771               32  \n",
       "5            0.762227         0.733333        0.037688               21  \n",
       "6            0.480476         0.466815        0.039158               31  \n",
       "7            0.789676         0.750368        0.043991               17  \n",
       "8            0.693914         0.668882        0.041239               26  \n",
       "9            0.714928         0.687635        0.044564               24  \n",
       "10           0.702248         0.679022        0.034782               25  \n",
       "11           0.730521         0.702666        0.034748               23  \n",
       "12           0.752551         0.724395        0.038969               22  \n",
       "13           0.794047         0.760048        0.036022               12  \n",
       "14           0.772376         0.737680        0.040497               20  \n",
       "15           0.799211         0.762945        0.038025               11  \n",
       "16           0.797448         0.766013        0.038037                5  \n",
       "17           0.794681         0.763320        0.041317               10  \n",
       "18           0.801740         0.767709        0.035683                2  \n",
       "19           0.800374         0.767008        0.036272                3  \n",
       "20           0.799909         0.763348        0.035253                9  \n",
       "21           0.801763         0.766945        0.035165                4  \n",
       "22           0.805213         0.765592        0.036221                6  \n",
       "23           0.803146         0.767717        0.035137                1  \n",
       "24           0.782894         0.754293        0.033826               14  \n",
       "25           0.791842         0.764615        0.032425                7  \n",
       "26           0.786886         0.757227        0.033635               13  \n",
       "27           0.793370         0.764568        0.032385                8  \n",
       "28           0.767933         0.744275        0.032533               19  \n",
       "29           0.779577         0.753497        0.031774               15  \n",
       "30           0.767333         0.744425        0.032815               18  \n",
       "31           0.779903         0.753450        0.031860               16  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(logReg_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Classifier with optimal hyperparameters had an average macro f1 score of 0.6034076518961486 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "perceptron = Perceptron(random_state=42)\n",
    "perceptron_params = {'penalty':['l1', 'l2', 'elasticnet'], 'alpha':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "perceptron_tuner = GridSearchCV(perceptron, perceptron_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "perceptron_tuner.fit(X_train, y_train)\n",
    "print('Perceptron Classifier with optimal hyperparameters had an average macro f1 score of '+str(perceptron_tuner.best_score_)+' using the following hyperparameters: '+str(perceptron_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051054</td>\n",
       "      <td>0.006289</td>\n",
       "      <td>0.003103</td>\n",
       "      <td>0.000617</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.037051</td>\n",
       "      <td>0.007355</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.607224</td>\n",
       "      <td>0.588255</td>\n",
       "      <td>0.599293</td>\n",
       "      <td>0.579904</td>\n",
       "      <td>0.362418</td>\n",
       "      <td>0.547419</td>\n",
       "      <td>0.092969</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062961</td>\n",
       "      <td>0.010108</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.593987</td>\n",
       "      <td>0.607967</td>\n",
       "      <td>0.596051</td>\n",
       "      <td>0.536861</td>\n",
       "      <td>0.076663</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046139</td>\n",
       "      <td>0.001654</td>\n",
       "      <td>0.002527</td>\n",
       "      <td>0.000204</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.384258</td>\n",
       "      <td>0.518628</td>\n",
       "      <td>0.361101</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.470161</td>\n",
       "      <td>0.419581</td>\n",
       "      <td>0.063486</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036538</td>\n",
       "      <td>0.003511</td>\n",
       "      <td>0.003176</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.591184</td>\n",
       "      <td>0.521479</td>\n",
       "      <td>0.515721</td>\n",
       "      <td>0.625128</td>\n",
       "      <td>0.310735</td>\n",
       "      <td>0.512849</td>\n",
       "      <td>0.109248</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.055296</td>\n",
       "      <td>0.012123</td>\n",
       "      <td>0.002718</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.614608</td>\n",
       "      <td>0.475460</td>\n",
       "      <td>0.532376</td>\n",
       "      <td>0.474807</td>\n",
       "      <td>0.624470</td>\n",
       "      <td>0.544344</td>\n",
       "      <td>0.064932</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.055330</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.002919</td>\n",
       "      <td>0.000386</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.528531</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.374789</td>\n",
       "      <td>0.446576</td>\n",
       "      <td>0.048794</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.060056</td>\n",
       "      <td>0.015403</td>\n",
       "      <td>0.002777</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.597255</td>\n",
       "      <td>0.554454</td>\n",
       "      <td>0.486245</td>\n",
       "      <td>0.527649</td>\n",
       "      <td>0.522534</td>\n",
       "      <td>0.537627</td>\n",
       "      <td>0.036895</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067927</td>\n",
       "      <td>0.012042</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.000268</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.619350</td>\n",
       "      <td>0.446897</td>\n",
       "      <td>0.393403</td>\n",
       "      <td>0.647231</td>\n",
       "      <td>0.595189</td>\n",
       "      <td>0.540414</td>\n",
       "      <td>0.100994</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.058657</td>\n",
       "      <td>0.004733</td>\n",
       "      <td>0.002734</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.299002</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.375323</td>\n",
       "      <td>0.275417</td>\n",
       "      <td>0.090309</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.060289</td>\n",
       "      <td>0.009098</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.552864</td>\n",
       "      <td>0.435021</td>\n",
       "      <td>0.633256</td>\n",
       "      <td>0.618435</td>\n",
       "      <td>0.661186</td>\n",
       "      <td>0.580152</td>\n",
       "      <td>0.080820</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.064203</td>\n",
       "      <td>0.010276</td>\n",
       "      <td>0.002898</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.607985</td>\n",
       "      <td>0.544704</td>\n",
       "      <td>0.600203</td>\n",
       "      <td>0.614562</td>\n",
       "      <td>0.649584</td>\n",
       "      <td>0.603408</td>\n",
       "      <td>0.033864</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.045481</td>\n",
       "      <td>0.003662</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.000685</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.278957</td>\n",
       "      <td>0.134081</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.042998</td>\n",
       "      <td>0.010820</td>\n",
       "      <td>0.002459</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.487045</td>\n",
       "      <td>0.490143</td>\n",
       "      <td>0.451026</td>\n",
       "      <td>0.183951</td>\n",
       "      <td>0.600127</td>\n",
       "      <td>0.442458</td>\n",
       "      <td>0.138579</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.047050</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.361101</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.301434</td>\n",
       "      <td>0.111644</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.001914</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.523420</td>\n",
       "      <td>0.511059</td>\n",
       "      <td>0.503321</td>\n",
       "      <td>0.495486</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.440550</td>\n",
       "      <td>0.135856</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.050261</td>\n",
       "      <td>0.010358</td>\n",
       "      <td>0.002752</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.550299</td>\n",
       "      <td>0.592796</td>\n",
       "      <td>0.460680</td>\n",
       "      <td>0.253850</td>\n",
       "      <td>0.612654</td>\n",
       "      <td>0.494056</td>\n",
       "      <td>0.130990</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.048311</td>\n",
       "      <td>0.005160</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.472601</td>\n",
       "      <td>0.299002</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.510487</td>\n",
       "      <td>0.363058</td>\n",
       "      <td>0.122740</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.048752</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>0.002778</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.052837</td>\n",
       "      <td>0.011006</td>\n",
       "      <td>0.002581</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.569293</td>\n",
       "      <td>0.591497</td>\n",
       "      <td>0.170040</td>\n",
       "      <td>0.178237</td>\n",
       "      <td>0.518118</td>\n",
       "      <td>0.405437</td>\n",
       "      <td>0.190366</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.054341</td>\n",
       "      <td>0.003766</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.333717</td>\n",
       "      <td>0.134073</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.050984</td>\n",
       "      <td>0.003622</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.047066</td>\n",
       "      <td>0.011089</td>\n",
       "      <td>0.002631</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.521145</td>\n",
       "      <td>0.449835</td>\n",
       "      <td>0.458835</td>\n",
       "      <td>0.610431</td>\n",
       "      <td>0.489967</td>\n",
       "      <td>0.506043</td>\n",
       "      <td>0.057916</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.059457</td>\n",
       "      <td>0.004260</td>\n",
       "      <td>0.002530</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.363758</td>\n",
       "      <td>0.375145</td>\n",
       "      <td>0.249492</td>\n",
       "      <td>0.098012</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.041915</td>\n",
       "      <td>0.001783</td>\n",
       "      <td>0.002482</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.061585</td>\n",
       "      <td>0.005621</td>\n",
       "      <td>0.002882</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.045110</td>\n",
       "      <td>0.001222</td>\n",
       "      <td>0.002337</td>\n",
       "      <td>0.000075</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.052883</td>\n",
       "      <td>0.005035</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.075458</td>\n",
       "      <td>0.019669</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.471825</td>\n",
       "      <td>0.463245</td>\n",
       "      <td>0.475266</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.349848</td>\n",
       "      <td>0.147344</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.051469</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.002523</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.510487</td>\n",
       "      <td>0.237697</td>\n",
       "      <td>0.136395</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.047489</td>\n",
       "      <td>0.003741</td>\n",
       "      <td>0.002792</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.071918</td>\n",
       "      <td>0.012075</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.461879</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.347195</td>\n",
       "      <td>0.145962</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.052510</td>\n",
       "      <td>0.001692</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.052524</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.002630</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.074862</td>\n",
       "      <td>0.016947</td>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.000237</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.471825</td>\n",
       "      <td>0.463245</td>\n",
       "      <td>0.475266</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.349848</td>\n",
       "      <td>0.147344</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.055926</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.041425</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.000778</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.062427</td>\n",
       "      <td>0.008434</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.069441</td>\n",
       "      <td>0.004770</td>\n",
       "      <td>0.002934</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.046110</td>\n",
       "      <td>0.001313</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.076498</td>\n",
       "      <td>0.019024</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.471825</td>\n",
       "      <td>0.463245</td>\n",
       "      <td>0.475266</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.349848</td>\n",
       "      <td>0.147344</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.073066</td>\n",
       "      <td>0.006386</td>\n",
       "      <td>0.002599</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.043931</td>\n",
       "      <td>0.002022</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.076277</td>\n",
       "      <td>0.015359</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.000469</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.492041</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.461879</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.347195</td>\n",
       "      <td>0.145962</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.068838</td>\n",
       "      <td>0.005555</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.000513</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.049454</td>\n",
       "      <td>0.002238</td>\n",
       "      <td>0.002549</td>\n",
       "      <td>0.000304</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.076967</td>\n",
       "      <td>0.017061</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.471825</td>\n",
       "      <td>0.463245</td>\n",
       "      <td>0.475266</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.349848</td>\n",
       "      <td>0.147344</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.073581</td>\n",
       "      <td>0.005447</td>\n",
       "      <td>0.002664</td>\n",
       "      <td>0.000317</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.169493</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.051054      0.006289         0.003103        0.000617        0.01   \n",
       "1        0.037051      0.007355         0.002581        0.000172        0.01   \n",
       "2        0.062961      0.010108         0.002631        0.000144        0.01   \n",
       "3        0.046139      0.001654         0.002527        0.000204        0.01   \n",
       "4        0.036538      0.003511         0.003176        0.000307        0.01   \n",
       "5        0.055296      0.012123         0.002718        0.000123        0.01   \n",
       "6        0.055330      0.002395         0.002919        0.000386        0.01   \n",
       "7        0.060056      0.015403         0.002777        0.000181        0.01   \n",
       "8        0.067927      0.012042         0.002661        0.000268        0.01   \n",
       "9        0.058657      0.004733         0.002734        0.000304        0.01   \n",
       "10       0.060289      0.009098         0.002715        0.000075        0.01   \n",
       "11       0.064203      0.010276         0.002898        0.000281        0.01   \n",
       "12       0.045481      0.003662         0.002856        0.000685         0.1   \n",
       "13       0.042998      0.010820         0.002459        0.000179         0.1   \n",
       "14       0.047050      0.004285         0.002649        0.000194         0.1   \n",
       "15       0.052036      0.001914         0.002536        0.000186         0.1   \n",
       "16       0.050261      0.010358         0.002752        0.000288         0.1   \n",
       "17       0.048311      0.005160         0.002543        0.000250         0.1   \n",
       "18       0.048752      0.003386         0.002778        0.000307         0.1   \n",
       "19       0.052837      0.011006         0.002581        0.000222         0.1   \n",
       "20       0.054341      0.003766         0.002498        0.000196         0.1   \n",
       "21       0.050984      0.003622         0.002659        0.000231         0.1   \n",
       "22       0.047066      0.011089         0.002631        0.000311         0.1   \n",
       "23       0.059457      0.004260         0.002530        0.000218         0.1   \n",
       "24       0.041915      0.001783         0.002482        0.000266           1   \n",
       "25       0.061585      0.005621         0.002882        0.000494           1   \n",
       "26       0.045110      0.001222         0.002337        0.000075           1   \n",
       "27       0.052883      0.005035         0.002600        0.000315           1   \n",
       "28       0.075458      0.019669         0.002569        0.000226           1   \n",
       "29       0.051469      0.002376         0.002523        0.000144           1   \n",
       "30       0.047489      0.003741         0.002792        0.000280           1   \n",
       "31       0.071918      0.012075         0.002488        0.000140           1   \n",
       "32       0.052510      0.001692         0.002751        0.000219           1   \n",
       "33       0.052524      0.002630         0.002630        0.000410           1   \n",
       "34       0.074862      0.016947         0.002656        0.000237           1   \n",
       "35       0.055926      0.003220         0.002754        0.000516           1   \n",
       "36       0.041425      0.001649         0.002726        0.000778          10   \n",
       "37       0.062427      0.008434         0.002717        0.000211          10   \n",
       "38       0.069441      0.004770         0.002934        0.000288          10   \n",
       "39       0.046110      0.001313         0.002543        0.000067          10   \n",
       "40       0.076498      0.019024         0.002572        0.000205          10   \n",
       "41       0.073066      0.006386         0.002599        0.000247          10   \n",
       "42       0.043931      0.002022         0.002345        0.000074          10   \n",
       "43       0.076277      0.015359         0.002699        0.000469          10   \n",
       "44       0.068838      0.005555         0.002738        0.000513          10   \n",
       "45       0.049454      0.002238         0.002549        0.000304          10   \n",
       "46       0.076967      0.017061         0.002552        0.000243          10   \n",
       "47       0.073581      0.005447         0.002664        0.000317          10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None                True    elasticnet   \n",
       "3                None               False            l1   \n",
       "4                None               False            l2   \n",
       "5                None               False    elasticnet   \n",
       "6            balanced                True            l1   \n",
       "7            balanced                True            l2   \n",
       "8            balanced                True    elasticnet   \n",
       "9            balanced               False            l1   \n",
       "10           balanced               False            l2   \n",
       "11           balanced               False    elasticnet   \n",
       "12               None                True            l1   \n",
       "13               None                True            l2   \n",
       "14               None                True    elasticnet   \n",
       "15               None               False            l1   \n",
       "16               None               False            l2   \n",
       "17               None               False    elasticnet   \n",
       "18           balanced                True            l1   \n",
       "19           balanced                True            l2   \n",
       "20           balanced                True    elasticnet   \n",
       "21           balanced               False            l1   \n",
       "22           balanced               False            l2   \n",
       "23           balanced               False    elasticnet   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None                True    elasticnet   \n",
       "27               None               False            l1   \n",
       "28               None               False            l2   \n",
       "29               None               False    elasticnet   \n",
       "30           balanced                True            l1   \n",
       "31           balanced                True            l2   \n",
       "32           balanced                True    elasticnet   \n",
       "33           balanced               False            l1   \n",
       "34           balanced               False            l2   \n",
       "35           balanced               False    elasticnet   \n",
       "36               None                True            l1   \n",
       "37               None                True            l2   \n",
       "38               None                True    elasticnet   \n",
       "39               None               False            l1   \n",
       "40               None               False            l2   \n",
       "41               None               False    elasticnet   \n",
       "42           balanced                True            l1   \n",
       "43           balanced                True            l2   \n",
       "44           balanced                True    elasticnet   \n",
       "45           balanced               False            l1   \n",
       "46           balanced               False            l2   \n",
       "47           balanced               False    elasticnet   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.443151   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.607224   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.443151   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.384258   \n",
       "4   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.591184   \n",
       "5   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.614608   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.443151   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.597255   \n",
       "8   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.619350   \n",
       "9   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.169559   \n",
       "10  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.552864   \n",
       "11  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.607985   \n",
       "12  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.443151   \n",
       "13  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.487045   \n",
       "14  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.169559   \n",
       "15  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.523420   \n",
       "16  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.550299   \n",
       "17  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.472601   \n",
       "18  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.169559   \n",
       "19  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.569293   \n",
       "20  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.443151   \n",
       "21  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.169559   \n",
       "22  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.521145   \n",
       "23  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.169559   \n",
       "24  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.169559   \n",
       "25  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.443151   \n",
       "26  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.169559   \n",
       "27  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.169559   \n",
       "28  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.471825   \n",
       "29  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.169559   \n",
       "30  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.169559   \n",
       "31  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.492041   \n",
       "32  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.169559   \n",
       "33  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.169559   \n",
       "34  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.471825   \n",
       "35  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.169559   \n",
       "36  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.169559   \n",
       "37  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.443151   \n",
       "38  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.169559   \n",
       "39  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.169559   \n",
       "40  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.471825   \n",
       "41  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.169559   \n",
       "42  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.169559   \n",
       "43  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.492041   \n",
       "44  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.169559   \n",
       "45  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.169559   \n",
       "46  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.471825   \n",
       "47  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.169559   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.443151           0.443205           0.443205   \n",
       "1            0.588255           0.599293           0.579904   \n",
       "2            0.443151           0.593987           0.607967   \n",
       "3            0.518628           0.361101           0.363758   \n",
       "4            0.521479           0.515721           0.625128   \n",
       "5            0.475460           0.532376           0.474807   \n",
       "6            0.528531           0.443205           0.443205   \n",
       "7            0.554454           0.486245           0.527649   \n",
       "8            0.446897           0.393403           0.647231   \n",
       "9            0.299002           0.169441           0.363758   \n",
       "10           0.435021           0.633256           0.618435   \n",
       "11           0.544704           0.600203           0.614562   \n",
       "12           0.169559           0.169441           0.169441   \n",
       "13           0.490143           0.451026           0.183951   \n",
       "14           0.169559           0.361101           0.363758   \n",
       "15           0.511059           0.503321           0.495486   \n",
       "16           0.592796           0.460680           0.253850   \n",
       "17           0.299002           0.169441           0.363758   \n",
       "18           0.169559           0.169441           0.169441   \n",
       "19           0.591497           0.170040           0.178237   \n",
       "20           0.169559           0.443205           0.443205   \n",
       "21           0.169559           0.169441           0.169441   \n",
       "22           0.449835           0.458835           0.610431   \n",
       "23           0.169559           0.169441           0.363758   \n",
       "24           0.169559           0.169441           0.169441   \n",
       "25           0.443151           0.443205           0.443205   \n",
       "26           0.169559           0.169441           0.169441   \n",
       "27           0.169559           0.169441           0.169441   \n",
       "28           0.463245           0.475266           0.169441   \n",
       "29           0.169559           0.169441           0.169441   \n",
       "30           0.169559           0.169441           0.169441   \n",
       "31           0.443151           0.169441           0.461879   \n",
       "32           0.169559           0.169441           0.169441   \n",
       "33           0.169559           0.169441           0.169441   \n",
       "34           0.463245           0.475266           0.169441   \n",
       "35           0.169559           0.169441           0.169441   \n",
       "36           0.169559           0.169441           0.169441   \n",
       "37           0.443151           0.443205           0.443205   \n",
       "38           0.169559           0.169441           0.169441   \n",
       "39           0.169559           0.169441           0.169441   \n",
       "40           0.463245           0.475266           0.169441   \n",
       "41           0.169559           0.169441           0.169441   \n",
       "42           0.169559           0.169441           0.169441   \n",
       "43           0.443151           0.169441           0.461879   \n",
       "44           0.169559           0.169441           0.169441   \n",
       "45           0.169559           0.169441           0.169441   \n",
       "46           0.463245           0.475266           0.169441   \n",
       "47           0.169559           0.169441           0.169441   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.443194         0.443181        0.000025               12  \n",
       "1            0.362418         0.547419        0.092969                3  \n",
       "2            0.596051         0.536861        0.076663                7  \n",
       "3            0.470161         0.419581        0.063486               17  \n",
       "4            0.310735         0.512849        0.109248                8  \n",
       "5            0.624470         0.544344        0.064932                4  \n",
       "6            0.374789         0.446576        0.048794               11  \n",
       "7            0.522534         0.537627        0.036895                6  \n",
       "8            0.595189         0.540414        0.100994                5  \n",
       "9            0.375323         0.275417        0.090309               29  \n",
       "10           0.661186         0.580152        0.080820                2  \n",
       "11           0.649584         0.603408        0.033864                1  \n",
       "12           0.443194         0.278957        0.134081               28  \n",
       "13           0.600127         0.442458        0.138579               15  \n",
       "14           0.443194         0.301434        0.111644               27  \n",
       "15           0.169465         0.440550        0.135856               16  \n",
       "16           0.612654         0.494056        0.130990               10  \n",
       "17           0.510487         0.363058        0.122740               19  \n",
       "18           0.443194         0.224239        0.109478               32  \n",
       "19           0.518118         0.405437        0.190366               18  \n",
       "20           0.169465         0.333717        0.134073               26  \n",
       "21           0.169465         0.169493        0.000055               41  \n",
       "22           0.489967         0.506043        0.057916                9  \n",
       "23           0.375145         0.249492        0.098012               30  \n",
       "24           0.443194         0.224239        0.109478               32  \n",
       "25           0.443194         0.443181        0.000025               12  \n",
       "26           0.443194         0.224239        0.109478               32  \n",
       "27           0.169465         0.169493        0.000055               41  \n",
       "28           0.169465         0.349848        0.147344               20  \n",
       "29           0.510487         0.237697        0.136395               31  \n",
       "30           0.443194         0.224239        0.109478               32  \n",
       "31           0.169465         0.347195        0.145962               24  \n",
       "32           0.443194         0.224239        0.109478               32  \n",
       "33           0.169465         0.169493        0.000055               41  \n",
       "34           0.169465         0.349848        0.147344               20  \n",
       "35           0.169465         0.169493        0.000055               41  \n",
       "36           0.443194         0.224239        0.109478               32  \n",
       "37           0.443194         0.443181        0.000025               12  \n",
       "38           0.443194         0.224239        0.109478               32  \n",
       "39           0.169465         0.169493        0.000055               41  \n",
       "40           0.169465         0.349848        0.147344               20  \n",
       "41           0.169465         0.169493        0.000055               41  \n",
       "42           0.443194         0.224239        0.109478               32  \n",
       "43           0.169465         0.347195        0.145962               24  \n",
       "44           0.443194         0.224239        0.109478               32  \n",
       "45           0.169465         0.169493        0.000055               41  \n",
       "46           0.169465         0.349848        0.147344               20  \n",
       "47           0.169465         0.169493        0.000055               41  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(perceptron_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier with optimal hyperparameters had an average macro f1 score of 0.7519699013399526 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd_params = {'penalty':['l1', 'l2'], 'alpha':[0.01, 0.1, 1], 'class_weight': [None,'balanced'], 'loss':['hinge', 'modified_huber']}\n",
    "sgd_tuner = GridSearchCV(sgd, sgd_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "sgd_tuner.fit(X_train, y_train)\n",
    "print('SGD Classifier with optimal hyperparameters had an average macro f1 score of '+str(sgd_tuner.best_score_)+' using the following hyperparameters: '+str(sgd_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.100236</td>\n",
       "      <td>0.010364</td>\n",
       "      <td>0.002716</td>\n",
       "      <td>0.000515</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.587323</td>\n",
       "      <td>0.527379</td>\n",
       "      <td>0.589480</td>\n",
       "      <td>0.606684</td>\n",
       "      <td>0.595282</td>\n",
       "      <td>0.581230</td>\n",
       "      <td>0.027751</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.047571</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.002738</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.586502</td>\n",
       "      <td>0.525462</td>\n",
       "      <td>0.588813</td>\n",
       "      <td>0.607009</td>\n",
       "      <td>0.595595</td>\n",
       "      <td>0.580676</td>\n",
       "      <td>0.028512</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056481</td>\n",
       "      <td>0.004196</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.588660</td>\n",
       "      <td>0.528014</td>\n",
       "      <td>0.590147</td>\n",
       "      <td>0.606684</td>\n",
       "      <td>0.595471</td>\n",
       "      <td>0.581795</td>\n",
       "      <td>0.027625</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.052280</td>\n",
       "      <td>0.004076</td>\n",
       "      <td>0.002655</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.641985</td>\n",
       "      <td>0.549243</td>\n",
       "      <td>0.624319</td>\n",
       "      <td>0.658107</td>\n",
       "      <td>0.639720</td>\n",
       "      <td>0.622675</td>\n",
       "      <td>0.038246</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.049299</td>\n",
       "      <td>0.002305</td>\n",
       "      <td>0.002715</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.435456</td>\n",
       "      <td>0.388656</td>\n",
       "      <td>0.421442</td>\n",
       "      <td>0.433249</td>\n",
       "      <td>0.446291</td>\n",
       "      <td>0.425019</td>\n",
       "      <td>0.019820</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.067127</td>\n",
       "      <td>0.015766</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.716938</td>\n",
       "      <td>0.661494</td>\n",
       "      <td>0.763723</td>\n",
       "      <td>0.770570</td>\n",
       "      <td>0.778461</td>\n",
       "      <td>0.738237</td>\n",
       "      <td>0.043945</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.104494</td>\n",
       "      <td>0.021013</td>\n",
       "      <td>0.002845</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.526395</td>\n",
       "      <td>0.465355</td>\n",
       "      <td>0.651021</td>\n",
       "      <td>0.658153</td>\n",
       "      <td>0.651605</td>\n",
       "      <td>0.590506</td>\n",
       "      <td>0.079680</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.073796</td>\n",
       "      <td>0.010734</td>\n",
       "      <td>0.002877</td>\n",
       "      <td>0.000526</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.709193</td>\n",
       "      <td>0.692253</td>\n",
       "      <td>0.781016</td>\n",
       "      <td>0.786108</td>\n",
       "      <td>0.791280</td>\n",
       "      <td>0.751970</td>\n",
       "      <td>0.042309</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.060074</td>\n",
       "      <td>0.006882</td>\n",
       "      <td>0.002601</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.042667</td>\n",
       "      <td>0.003775</td>\n",
       "      <td>0.002461</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.452761</td>\n",
       "      <td>0.451894</td>\n",
       "      <td>0.446721</td>\n",
       "      <td>0.453687</td>\n",
       "      <td>0.450204</td>\n",
       "      <td>0.451054</td>\n",
       "      <td>0.002452</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.074559</td>\n",
       "      <td>0.012982</td>\n",
       "      <td>0.002564</td>\n",
       "      <td>0.000065</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.043233</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002509</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.582615</td>\n",
       "      <td>0.526217</td>\n",
       "      <td>0.584939</td>\n",
       "      <td>0.600199</td>\n",
       "      <td>0.592287</td>\n",
       "      <td>0.577252</td>\n",
       "      <td>0.026249</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.052105</td>\n",
       "      <td>0.003408</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000209</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169465</td>\n",
       "      <td>0.278964</td>\n",
       "      <td>0.134080</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.054808</td>\n",
       "      <td>0.012756</td>\n",
       "      <td>0.002764</td>\n",
       "      <td>0.000481</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.642804</td>\n",
       "      <td>0.670933</td>\n",
       "      <td>0.641270</td>\n",
       "      <td>0.639518</td>\n",
       "      <td>0.660518</td>\n",
       "      <td>0.651008</td>\n",
       "      <td>0.012503</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.068749</td>\n",
       "      <td>0.034544</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.528531</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.608444</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.438586</td>\n",
       "      <td>0.147892</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.062949</td>\n",
       "      <td>0.013815</td>\n",
       "      <td>0.002727</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.716820</td>\n",
       "      <td>0.667395</td>\n",
       "      <td>0.755168</td>\n",
       "      <td>0.750109</td>\n",
       "      <td>0.762453</td>\n",
       "      <td>0.730389</td>\n",
       "      <td>0.035166</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.069577</td>\n",
       "      <td>0.005965</td>\n",
       "      <td>0.002648</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.057497</td>\n",
       "      <td>0.003617</td>\n",
       "      <td>0.002754</td>\n",
       "      <td>0.000585</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.106533</td>\n",
       "      <td>0.001758</td>\n",
       "      <td>0.002540</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443151</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443205</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.443181</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.047364</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.002595</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.449286</td>\n",
       "      <td>0.451894</td>\n",
       "      <td>0.445844</td>\n",
       "      <td>0.451954</td>\n",
       "      <td>0.444955</td>\n",
       "      <td>0.448787</td>\n",
       "      <td>0.002942</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.047292</td>\n",
       "      <td>0.001673</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.000068</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.043427</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>0.003088</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.605981</td>\n",
       "      <td>0.515005</td>\n",
       "      <td>0.601008</td>\n",
       "      <td>0.607865</td>\n",
       "      <td>0.602655</td>\n",
       "      <td>0.586503</td>\n",
       "      <td>0.035830</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.050496</td>\n",
       "      <td>0.003674</td>\n",
       "      <td>0.002366</td>\n",
       "      <td>0.000074</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169559</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.169441</td>\n",
       "      <td>0.443194</td>\n",
       "      <td>0.224239</td>\n",
       "      <td>0.109478</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.054792</td>\n",
       "      <td>0.009973</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000587</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.656036</td>\n",
       "      <td>0.531867</td>\n",
       "      <td>0.634707</td>\n",
       "      <td>0.683774</td>\n",
       "      <td>0.668894</td>\n",
       "      <td>0.635056</td>\n",
       "      <td>0.054049</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.100236      0.010364         0.002716        0.000515        0.01   \n",
       "1        0.047571      0.002522         0.002738        0.000149        0.01   \n",
       "2        0.056481      0.004196         0.002483        0.000115        0.01   \n",
       "3        0.052280      0.004076         0.002655        0.000271        0.01   \n",
       "4        0.049299      0.002305         0.002715        0.000175        0.01   \n",
       "5        0.067127      0.015766         0.002812        0.000384        0.01   \n",
       "6        0.104494      0.021013         0.002845        0.000219        0.01   \n",
       "7        0.073796      0.010734         0.002877        0.000526        0.01   \n",
       "8        0.060074      0.006882         0.002601        0.000326         0.1   \n",
       "9        0.042667      0.003775         0.002461        0.000157         0.1   \n",
       "10       0.074559      0.012982         0.002564        0.000065         0.1   \n",
       "11       0.043233      0.002420         0.002509        0.000167         0.1   \n",
       "12       0.052105      0.003408         0.002600        0.000209         0.1   \n",
       "13       0.054808      0.012756         0.002764        0.000481         0.1   \n",
       "14       0.068749      0.034544         0.002682        0.000345         0.1   \n",
       "15       0.062949      0.013815         0.002727        0.000221         0.1   \n",
       "16       0.069577      0.005965         0.002648        0.000109           1   \n",
       "17       0.057497      0.003617         0.002754        0.000585           1   \n",
       "18       0.106533      0.001758         0.002540        0.000226           1   \n",
       "19       0.047364      0.002902         0.002595        0.000184           1   \n",
       "20       0.047292      0.001673         0.002338        0.000068           1   \n",
       "21       0.043427      0.003012         0.003088        0.000563           1   \n",
       "22       0.050496      0.003674         0.002366        0.000074           1   \n",
       "23       0.054792      0.009973         0.003008        0.000587           1   \n",
       "\n",
       "   param_class_weight      param_loss param_penalty  \\\n",
       "0                None           hinge            l1   \n",
       "1                None           hinge            l2   \n",
       "2                None  modified_huber            l1   \n",
       "3                None  modified_huber            l2   \n",
       "4            balanced           hinge            l1   \n",
       "5            balanced           hinge            l2   \n",
       "6            balanced  modified_huber            l1   \n",
       "7            balanced  modified_huber            l2   \n",
       "8                None           hinge            l1   \n",
       "9                None           hinge            l2   \n",
       "10               None  modified_huber            l1   \n",
       "11               None  modified_huber            l2   \n",
       "12           balanced           hinge            l1   \n",
       "13           balanced           hinge            l2   \n",
       "14           balanced  modified_huber            l1   \n",
       "15           balanced  modified_huber            l2   \n",
       "16               None           hinge            l1   \n",
       "17               None           hinge            l2   \n",
       "18               None  modified_huber            l1   \n",
       "19               None  modified_huber            l2   \n",
       "20           balanced           hinge            l1   \n",
       "21           balanced           hinge            l2   \n",
       "22           balanced  modified_huber            l1   \n",
       "23           balanced  modified_huber            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.587323   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.586502   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.588660   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.641985   \n",
       "4   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.435456   \n",
       "5   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.716938   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.526395   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.709193   \n",
       "8   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.443151   \n",
       "9   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.452761   \n",
       "10  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.443151   \n",
       "11  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.582615   \n",
       "12  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.169559   \n",
       "13  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.642804   \n",
       "14  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.169559   \n",
       "15  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.716820   \n",
       "16  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.443151   \n",
       "17  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.443151   \n",
       "18  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.443151   \n",
       "19  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.449286   \n",
       "20  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.169559   \n",
       "21  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.605981   \n",
       "22  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.169559   \n",
       "23  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.656036   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.527379           0.589480           0.606684   \n",
       "1            0.525462           0.588813           0.607009   \n",
       "2            0.528014           0.590147           0.606684   \n",
       "3            0.549243           0.624319           0.658107   \n",
       "4            0.388656           0.421442           0.433249   \n",
       "5            0.661494           0.763723           0.770570   \n",
       "6            0.465355           0.651021           0.658153   \n",
       "7            0.692253           0.781016           0.786108   \n",
       "8            0.443151           0.443205           0.443205   \n",
       "9            0.451894           0.446721           0.453687   \n",
       "10           0.443151           0.443205           0.443205   \n",
       "11           0.526217           0.584939           0.600199   \n",
       "12           0.443151           0.443205           0.169441   \n",
       "13           0.670933           0.641270           0.639518   \n",
       "14           0.528531           0.443205           0.608444   \n",
       "15           0.667395           0.755168           0.750109   \n",
       "16           0.443151           0.443205           0.443205   \n",
       "17           0.443151           0.443205           0.443205   \n",
       "18           0.443151           0.443205           0.443205   \n",
       "19           0.451894           0.445844           0.451954   \n",
       "20           0.169559           0.169441           0.169441   \n",
       "21           0.515005           0.601008           0.607865   \n",
       "22           0.169559           0.169441           0.169441   \n",
       "23           0.531867           0.634707           0.683774   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.595282         0.581230        0.027751               10  \n",
       "1            0.595595         0.580676        0.028512               11  \n",
       "2            0.595471         0.581795        0.027625                9  \n",
       "3            0.639720         0.622675        0.038246                6  \n",
       "4            0.446291         0.425019        0.019820               21  \n",
       "5            0.778461         0.738237        0.043945                2  \n",
       "6            0.651605         0.590506        0.079680                7  \n",
       "7            0.791280         0.751970        0.042309                1  \n",
       "8            0.443194         0.443181        0.000025               15  \n",
       "9            0.450204         0.451054        0.002452               13  \n",
       "10           0.443194         0.443181        0.000025               15  \n",
       "11           0.592287         0.577252        0.026249               12  \n",
       "12           0.169465         0.278964        0.134080               22  \n",
       "13           0.660518         0.651008        0.012503                4  \n",
       "14           0.443194         0.438586        0.147892               20  \n",
       "15           0.762453         0.730389        0.035166                3  \n",
       "16           0.443194         0.443181        0.000025               15  \n",
       "17           0.443194         0.443181        0.000025               15  \n",
       "18           0.443194         0.443181        0.000025               15  \n",
       "19           0.444955         0.448787        0.002942               14  \n",
       "20           0.443194         0.224239        0.109478               23  \n",
       "21           0.602655         0.586503        0.035830                8  \n",
       "22           0.443194         0.224239        0.109478               23  \n",
       "23           0.668894         0.635056        0.054049                5  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(sgd_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV Metrics: Cutoff 1\n",
      "\n",
      "Tuned Logistic Regression Model:\n",
      "Accuracy Average: 0.7292860696635672\n",
      "Precision Average: 0.6736275645065177\n",
      "F1 Score Average: 0.6673847134781905\n",
      "ROC AUC Score Average: 0.7129709422647212\n",
      "Confusion Matrix Average:\n",
      "[775.2 416.2]\n",
      "[1164.2 3482.2]\n",
      "\n",
      "\n",
      "Tuned Perceptron Model:\n",
      "Accuracy Average: 0.6080014658822882\n",
      "Precision Average: 0.6187957368904804\n",
      "F1 Score Average: 0.5698461268398727\n",
      "ROC AUC Score Average: 0.6856480219461065\n",
      "Confusion Matrix Average:\n",
      "[950.  241.4]\n",
      "[2047.  2599.4]\n",
      "\n",
      "\n",
      "Tuned SGD Classifier:\n",
      "Accuracy Average: 0.7027691476618749\n",
      "Precision Average: 0.6565055174503138\n",
      "F1 Score Average: 0.6468991696186892\n",
      "ROC AUC Score Average: 0.7136902529532769\n",
      "Confusion Matrix Average:\n",
      "[827.8 363.6]\n",
      "[1371.6 3274.8]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print average k-fold CV metrics for optimally tuned models\n",
    "cutoff = 1\n",
    "\n",
    "print(f\"5-Fold CV Metrics: Cutoff {cutoff}\\n\")\n",
    "\n",
    "print(\"Tuned Logistic Regression Model:\")\n",
    "logReg.set_params(**logReg_tuner.best_params_)\n",
    "predictions = cv_metrics(logReg, 2)\n",
    "\n",
    "print(\"Tuned Perceptron Model:\")\n",
    "perceptron.set_params(**perceptron_tuner.best_params_)\n",
    "predictions = cv_metrics(perceptron, 2)\n",
    "\n",
    "print(\"Tuned SGD Classifier:\")\n",
    "sgd.set_params(**sgd_tuner.best_params_)\n",
    "predictions = cv_metrics(sgd, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Testing\n",
    "Since the tuned Logistic Regression seems to have the best average scores, I will use this model to predict the test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save test predictions\n",
    "y_test_hat_1 = logReg.predict(X_test)\n",
    "out_results(y_test_hat_1, \"binary\", 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a macro f1 score of 0.79046 on the test set on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set binary cutoff to 2\n",
    "y_train = construct_labels(df_train, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression with optimal hyperparameters had an average macro f1 score of 0.8196854013287439 using the following hyperparameters: {'C': 1, 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "logReg = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)\n",
    "logReg_params = {'penalty':['l1', 'l2'], 'C':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "logReg_tuner = GridSearchCV(logReg, logReg_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "logReg_tuner.fit(X_train, y_train)\n",
    "print('Logisitic Regression with optimal hyperparameters had an average macro f1 score of '+str(logReg_tuner.best_score_)+' using the following hyperparameters: '+str(logReg_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.071967</td>\n",
       "      <td>0.003559</td>\n",
       "      <td>0.003184</td>\n",
       "      <td>0.000562</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.601520</td>\n",
       "      <td>0.528687</td>\n",
       "      <td>0.584971</td>\n",
       "      <td>0.586637</td>\n",
       "      <td>0.586652</td>\n",
       "      <td>0.577693</td>\n",
       "      <td>0.025229</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.070457</td>\n",
       "      <td>0.005243</td>\n",
       "      <td>0.002896</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.731435</td>\n",
       "      <td>0.649051</td>\n",
       "      <td>0.725773</td>\n",
       "      <td>0.705347</td>\n",
       "      <td>0.727019</td>\n",
       "      <td>0.707725</td>\n",
       "      <td>0.030687</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.057268</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.002783</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.648688</td>\n",
       "      <td>0.651623</td>\n",
       "      <td>0.616282</td>\n",
       "      <td>0.610118</td>\n",
       "      <td>0.627772</td>\n",
       "      <td>0.630897</td>\n",
       "      <td>0.016741</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073682</td>\n",
       "      <td>0.006416</td>\n",
       "      <td>0.003182</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.736377</td>\n",
       "      <td>0.676549</td>\n",
       "      <td>0.726495</td>\n",
       "      <td>0.705095</td>\n",
       "      <td>0.727104</td>\n",
       "      <td>0.714324</td>\n",
       "      <td>0.021494</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.077053</td>\n",
       "      <td>0.007073</td>\n",
       "      <td>0.003279</td>\n",
       "      <td>0.000377</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.643589</td>\n",
       "      <td>0.566472</td>\n",
       "      <td>0.627175</td>\n",
       "      <td>0.685184</td>\n",
       "      <td>0.619922</td>\n",
       "      <td>0.628468</td>\n",
       "      <td>0.038376</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.079752</td>\n",
       "      <td>0.010255</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.784952</td>\n",
       "      <td>0.697811</td>\n",
       "      <td>0.810970</td>\n",
       "      <td>0.804413</td>\n",
       "      <td>0.812895</td>\n",
       "      <td>0.782208</td>\n",
       "      <td>0.043342</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.059146</td>\n",
       "      <td>0.004424</td>\n",
       "      <td>0.002920</td>\n",
       "      <td>0.000278</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.645728</td>\n",
       "      <td>0.578113</td>\n",
       "      <td>0.627559</td>\n",
       "      <td>0.685130</td>\n",
       "      <td>0.646879</td>\n",
       "      <td>0.636682</td>\n",
       "      <td>0.034775</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.077356</td>\n",
       "      <td>0.007839</td>\n",
       "      <td>0.002968</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.786117</td>\n",
       "      <td>0.717886</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.817482</td>\n",
       "      <td>0.828632</td>\n",
       "      <td>0.795206</td>\n",
       "      <td>0.041515</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.131317</td>\n",
       "      <td>0.010306</td>\n",
       "      <td>0.004075</td>\n",
       "      <td>0.000701</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.792615</td>\n",
       "      <td>0.723218</td>\n",
       "      <td>0.801146</td>\n",
       "      <td>0.788400</td>\n",
       "      <td>0.806153</td>\n",
       "      <td>0.782306</td>\n",
       "      <td>0.030194</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.110842</td>\n",
       "      <td>0.007339</td>\n",
       "      <td>0.003013</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.829024</td>\n",
       "      <td>0.741346</td>\n",
       "      <td>0.822489</td>\n",
       "      <td>0.820538</td>\n",
       "      <td>0.838752</td>\n",
       "      <td>0.810430</td>\n",
       "      <td>0.035123</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.074936</td>\n",
       "      <td>0.006303</td>\n",
       "      <td>0.003596</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.792984</td>\n",
       "      <td>0.716726</td>\n",
       "      <td>0.799774</td>\n",
       "      <td>0.788385</td>\n",
       "      <td>0.803780</td>\n",
       "      <td>0.780330</td>\n",
       "      <td>0.032244</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.106732</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>0.003102</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.740087</td>\n",
       "      <td>0.822476</td>\n",
       "      <td>0.819936</td>\n",
       "      <td>0.836482</td>\n",
       "      <td>0.809196</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.148869</td>\n",
       "      <td>0.017158</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.775515</td>\n",
       "      <td>0.716517</td>\n",
       "      <td>0.804078</td>\n",
       "      <td>0.801234</td>\n",
       "      <td>0.799151</td>\n",
       "      <td>0.779299</td>\n",
       "      <td>0.033000</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.114819</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.002844</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.814278</td>\n",
       "      <td>0.752359</td>\n",
       "      <td>0.832087</td>\n",
       "      <td>0.830021</td>\n",
       "      <td>0.843836</td>\n",
       "      <td>0.814516</td>\n",
       "      <td>0.032473</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.083543</td>\n",
       "      <td>0.013341</td>\n",
       "      <td>0.003721</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.779990</td>\n",
       "      <td>0.719683</td>\n",
       "      <td>0.812575</td>\n",
       "      <td>0.806590</td>\n",
       "      <td>0.808866</td>\n",
       "      <td>0.785541</td>\n",
       "      <td>0.034888</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.115281</td>\n",
       "      <td>0.010035</td>\n",
       "      <td>0.002806</td>\n",
       "      <td>0.000324</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.812711</td>\n",
       "      <td>0.749143</td>\n",
       "      <td>0.833799</td>\n",
       "      <td>0.831837</td>\n",
       "      <td>0.848585</td>\n",
       "      <td>0.815215</td>\n",
       "      <td>0.034948</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.317746</td>\n",
       "      <td>0.021776</td>\n",
       "      <td>0.004085</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.832866</td>\n",
       "      <td>0.754248</td>\n",
       "      <td>0.819481</td>\n",
       "      <td>0.832034</td>\n",
       "      <td>0.850081</td>\n",
       "      <td>0.817742</td>\n",
       "      <td>0.033206</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.178512</td>\n",
       "      <td>0.018248</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.833180</td>\n",
       "      <td>0.750919</td>\n",
       "      <td>0.827368</td>\n",
       "      <td>0.833420</td>\n",
       "      <td>0.847177</td>\n",
       "      <td>0.818413</td>\n",
       "      <td>0.034369</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.114205</td>\n",
       "      <td>0.004777</td>\n",
       "      <td>0.003758</td>\n",
       "      <td>0.000288</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.831919</td>\n",
       "      <td>0.753961</td>\n",
       "      <td>0.820721</td>\n",
       "      <td>0.831004</td>\n",
       "      <td>0.849717</td>\n",
       "      <td>0.817464</td>\n",
       "      <td>0.033093</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.180087</td>\n",
       "      <td>0.016945</td>\n",
       "      <td>0.002959</td>\n",
       "      <td>0.000238</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.834933</td>\n",
       "      <td>0.749267</td>\n",
       "      <td>0.825980</td>\n",
       "      <td>0.833840</td>\n",
       "      <td>0.847101</td>\n",
       "      <td>0.818224</td>\n",
       "      <td>0.035135</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.394659</td>\n",
       "      <td>0.012919</td>\n",
       "      <td>0.003724</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.825184</td>\n",
       "      <td>0.756751</td>\n",
       "      <td>0.818956</td>\n",
       "      <td>0.833722</td>\n",
       "      <td>0.855423</td>\n",
       "      <td>0.818007</td>\n",
       "      <td>0.033020</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.219618</td>\n",
       "      <td>0.010533</td>\n",
       "      <td>0.002993</td>\n",
       "      <td>0.000344</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.826824</td>\n",
       "      <td>0.759055</td>\n",
       "      <td>0.822033</td>\n",
       "      <td>0.835103</td>\n",
       "      <td>0.853075</td>\n",
       "      <td>0.819218</td>\n",
       "      <td>0.031888</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.113723</td>\n",
       "      <td>0.006631</td>\n",
       "      <td>0.003607</td>\n",
       "      <td>0.000326</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.827557</td>\n",
       "      <td>0.756262</td>\n",
       "      <td>0.820280</td>\n",
       "      <td>0.836633</td>\n",
       "      <td>0.855854</td>\n",
       "      <td>0.819317</td>\n",
       "      <td>0.033703</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.190125</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.828295</td>\n",
       "      <td>0.757788</td>\n",
       "      <td>0.823506</td>\n",
       "      <td>0.837143</td>\n",
       "      <td>0.851695</td>\n",
       "      <td>0.819685</td>\n",
       "      <td>0.032402</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.527777</td>\n",
       "      <td>0.012178</td>\n",
       "      <td>0.003572</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.814176</td>\n",
       "      <td>0.736262</td>\n",
       "      <td>0.798206</td>\n",
       "      <td>0.817442</td>\n",
       "      <td>0.823222</td>\n",
       "      <td>0.797862</td>\n",
       "      <td>0.031898</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.299632</td>\n",
       "      <td>0.032239</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.818354</td>\n",
       "      <td>0.744089</td>\n",
       "      <td>0.806078</td>\n",
       "      <td>0.822575</td>\n",
       "      <td>0.833385</td>\n",
       "      <td>0.804896</td>\n",
       "      <td>0.031636</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.174184</td>\n",
       "      <td>0.010600</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000142</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.814321</td>\n",
       "      <td>0.735658</td>\n",
       "      <td>0.798399</td>\n",
       "      <td>0.816533</td>\n",
       "      <td>0.823249</td>\n",
       "      <td>0.797632</td>\n",
       "      <td>0.032042</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.274437</td>\n",
       "      <td>0.023963</td>\n",
       "      <td>0.003052</td>\n",
       "      <td>0.000348</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.816887</td>\n",
       "      <td>0.744600</td>\n",
       "      <td>0.806078</td>\n",
       "      <td>0.821665</td>\n",
       "      <td>0.834001</td>\n",
       "      <td>0.804646</td>\n",
       "      <td>0.031333</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.636943</td>\n",
       "      <td>0.019591</td>\n",
       "      <td>0.003793</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.808997</td>\n",
       "      <td>0.739148</td>\n",
       "      <td>0.797109</td>\n",
       "      <td>0.813588</td>\n",
       "      <td>0.829871</td>\n",
       "      <td>0.797743</td>\n",
       "      <td>0.031125</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.399032</td>\n",
       "      <td>0.032470</td>\n",
       "      <td>0.003143</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.815586</td>\n",
       "      <td>0.748489</td>\n",
       "      <td>0.805553</td>\n",
       "      <td>0.821502</td>\n",
       "      <td>0.836454</td>\n",
       "      <td>0.805517</td>\n",
       "      <td>0.030220</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.212077</td>\n",
       "      <td>0.043309</td>\n",
       "      <td>0.003771</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.808802</td>\n",
       "      <td>0.738153</td>\n",
       "      <td>0.799062</td>\n",
       "      <td>0.815429</td>\n",
       "      <td>0.828306</td>\n",
       "      <td>0.797950</td>\n",
       "      <td>0.031374</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.350308</td>\n",
       "      <td>0.032234</td>\n",
       "      <td>0.002841</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.817137</td>\n",
       "      <td>0.746196</td>\n",
       "      <td>0.806848</td>\n",
       "      <td>0.820865</td>\n",
       "      <td>0.836534</td>\n",
       "      <td>0.805516</td>\n",
       "      <td>0.031156</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.071967      0.003559         0.003184        0.000562    0.01   \n",
       "1        0.070457      0.005243         0.002896        0.000248    0.01   \n",
       "2        0.057268      0.003252         0.002783        0.000263    0.01   \n",
       "3        0.073682      0.006416         0.003182        0.000281    0.01   \n",
       "4        0.077053      0.007073         0.003279        0.000377    0.01   \n",
       "5        0.079752      0.010255         0.002973        0.000380    0.01   \n",
       "6        0.059146      0.004424         0.002920        0.000278    0.01   \n",
       "7        0.077356      0.007839         0.002968        0.000324    0.01   \n",
       "8        0.131317      0.010306         0.004075        0.000701     0.1   \n",
       "9        0.110842      0.007339         0.003013        0.000155     0.1   \n",
       "10       0.074936      0.006303         0.003596        0.000210     0.1   \n",
       "11       0.106732      0.009201         0.003102        0.000271     0.1   \n",
       "12       0.148869      0.017158         0.003908        0.000569     0.1   \n",
       "13       0.114819      0.006381         0.002844        0.000207     0.1   \n",
       "14       0.083543      0.013341         0.003721        0.000342     0.1   \n",
       "15       0.115281      0.010035         0.002806        0.000324     0.1   \n",
       "16       0.317746      0.021776         0.004085        0.000567       1   \n",
       "17       0.178512      0.018248         0.002875        0.000175       1   \n",
       "18       0.114205      0.004777         0.003758        0.000288       1   \n",
       "19       0.180087      0.016945         0.002959        0.000238       1   \n",
       "20       0.394659      0.012919         0.003724        0.000435       1   \n",
       "21       0.219618      0.010533         0.002993        0.000344       1   \n",
       "22       0.113723      0.006631         0.003607        0.000326       1   \n",
       "23       0.190125      0.009214         0.002863        0.000219       1   \n",
       "24       0.527777      0.012178         0.003572        0.000150      10   \n",
       "25       0.299632      0.032239         0.003069        0.000125      10   \n",
       "26       0.174184      0.010600         0.003552        0.000142      10   \n",
       "27       0.274437      0.023963         0.003052        0.000348      10   \n",
       "28       0.636943      0.019591         0.003793        0.000150      10   \n",
       "29       0.399032      0.032470         0.003143        0.000318      10   \n",
       "30       0.212077      0.043309         0.003771        0.000211      10   \n",
       "31       0.350308      0.032234         0.002841        0.000156      10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None               False            l1   \n",
       "3                None               False            l2   \n",
       "4            balanced                True            l1   \n",
       "5            balanced                True            l2   \n",
       "6            balanced               False            l1   \n",
       "7            balanced               False            l2   \n",
       "8                None                True            l1   \n",
       "9                None                True            l2   \n",
       "10               None               False            l1   \n",
       "11               None               False            l2   \n",
       "12           balanced                True            l1   \n",
       "13           balanced                True            l2   \n",
       "14           balanced               False            l1   \n",
       "15           balanced               False            l2   \n",
       "16               None                True            l1   \n",
       "17               None                True            l2   \n",
       "18               None               False            l1   \n",
       "19               None               False            l2   \n",
       "20           balanced                True            l1   \n",
       "21           balanced                True            l2   \n",
       "22           balanced               False            l1   \n",
       "23           balanced               False            l2   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None               False            l1   \n",
       "27               None               False            l2   \n",
       "28           balanced                True            l1   \n",
       "29           balanced                True            l2   \n",
       "30           balanced               False            l1   \n",
       "31           balanced               False            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.601520   \n",
       "1   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.731435   \n",
       "2   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.648688   \n",
       "3   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.736377   \n",
       "4   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.643589   \n",
       "5   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.784952   \n",
       "6   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.645728   \n",
       "7   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.786117   \n",
       "8   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.792615   \n",
       "9   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.829024   \n",
       "10  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.792984   \n",
       "11  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.827000   \n",
       "12  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.775515   \n",
       "13  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.814278   \n",
       "14  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.779990   \n",
       "15  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.812711   \n",
       "16  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.832866   \n",
       "17  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.833180   \n",
       "18  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.831919   \n",
       "19  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.834933   \n",
       "20  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.825184   \n",
       "21  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.826824   \n",
       "22  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.827557   \n",
       "23  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.828295   \n",
       "24  {'C': 10, 'class_weight': None, 'fit_intercept...           0.814176   \n",
       "25  {'C': 10, 'class_weight': None, 'fit_intercept...           0.818354   \n",
       "26  {'C': 10, 'class_weight': None, 'fit_intercept...           0.814321   \n",
       "27  {'C': 10, 'class_weight': None, 'fit_intercept...           0.816887   \n",
       "28  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.808997   \n",
       "29  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.815586   \n",
       "30  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.808802   \n",
       "31  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.817137   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.528687           0.584971           0.586637   \n",
       "1            0.649051           0.725773           0.705347   \n",
       "2            0.651623           0.616282           0.610118   \n",
       "3            0.676549           0.726495           0.705095   \n",
       "4            0.566472           0.627175           0.685184   \n",
       "5            0.697811           0.810970           0.804413   \n",
       "6            0.578113           0.627559           0.685130   \n",
       "7            0.717886           0.825911           0.817482   \n",
       "8            0.723218           0.801146           0.788400   \n",
       "9            0.741346           0.822489           0.820538   \n",
       "10           0.716726           0.799774           0.788385   \n",
       "11           0.740087           0.822476           0.819936   \n",
       "12           0.716517           0.804078           0.801234   \n",
       "13           0.752359           0.832087           0.830021   \n",
       "14           0.719683           0.812575           0.806590   \n",
       "15           0.749143           0.833799           0.831837   \n",
       "16           0.754248           0.819481           0.832034   \n",
       "17           0.750919           0.827368           0.833420   \n",
       "18           0.753961           0.820721           0.831004   \n",
       "19           0.749267           0.825980           0.833840   \n",
       "20           0.756751           0.818956           0.833722   \n",
       "21           0.759055           0.822033           0.835103   \n",
       "22           0.756262           0.820280           0.836633   \n",
       "23           0.757788           0.823506           0.837143   \n",
       "24           0.736262           0.798206           0.817442   \n",
       "25           0.744089           0.806078           0.822575   \n",
       "26           0.735658           0.798399           0.816533   \n",
       "27           0.744600           0.806078           0.821665   \n",
       "28           0.739148           0.797109           0.813588   \n",
       "29           0.748489           0.805553           0.821502   \n",
       "30           0.738153           0.799062           0.815429   \n",
       "31           0.746196           0.806848           0.820865   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.586652         0.577693        0.025229               32  \n",
       "1            0.727019         0.707725        0.030687               28  \n",
       "2            0.627772         0.630897        0.016741               30  \n",
       "3            0.727104         0.714324        0.021494               27  \n",
       "4            0.619922         0.628468        0.038376               31  \n",
       "5            0.812895         0.782208        0.043342               24  \n",
       "6            0.646879         0.636682        0.034775               29  \n",
       "7            0.828632         0.795206        0.041515               21  \n",
       "8            0.806153         0.782306        0.030194               23  \n",
       "9            0.838752         0.810430        0.035123               11  \n",
       "10           0.803780         0.780330        0.032244               25  \n",
       "11           0.836482         0.809196        0.035012               12  \n",
       "12           0.799151         0.779299        0.033000               26  \n",
       "13           0.843836         0.814516        0.032473               10  \n",
       "14           0.808866         0.785541        0.034888               22  \n",
       "15           0.848585         0.815215        0.034948                9  \n",
       "16           0.850081         0.817742        0.033206                7  \n",
       "17           0.847177         0.818413        0.034369                4  \n",
       "18           0.849717         0.817464        0.033093                8  \n",
       "19           0.847101         0.818224        0.035135                5  \n",
       "20           0.855423         0.818007        0.033020                6  \n",
       "21           0.853075         0.819218        0.031888                3  \n",
       "22           0.855854         0.819317        0.033703                2  \n",
       "23           0.851695         0.819685        0.032402                1  \n",
       "24           0.823222         0.797862        0.031898               18  \n",
       "25           0.833385         0.804896        0.031636               15  \n",
       "26           0.823249         0.797632        0.032042               20  \n",
       "27           0.834001         0.804646        0.031333               16  \n",
       "28           0.829871         0.797743        0.031125               19  \n",
       "29           0.836454         0.805517        0.030220               13  \n",
       "30           0.828306         0.797950        0.031374               17  \n",
       "31           0.836534         0.805516        0.031156               14  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(logReg_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Classifier with optimal hyperparameters had an average macro f1 score of 0.6375152004092205 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "perceptron = Perceptron(random_state=42)\n",
    "perceptron_params = {'penalty':['l1', 'l2', 'elasticnet'], 'alpha':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "perceptron_tuner = GridSearchCV(perceptron, perceptron_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "perceptron_tuner.fit(X_train, y_train)\n",
    "print('Perceptron Classifier with optimal hyperparameters had an average macro f1 score of '+str(perceptron_tuner.best_score_)+' using the following hyperparameters: '+str(perceptron_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.060363</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.000248</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.458690</td>\n",
       "      <td>0.394467</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.380765</td>\n",
       "      <td>0.078616</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043088</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.002822</td>\n",
       "      <td>0.000271</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.517246</td>\n",
       "      <td>0.539202</td>\n",
       "      <td>0.520275</td>\n",
       "      <td>0.583660</td>\n",
       "      <td>0.340087</td>\n",
       "      <td>0.500094</td>\n",
       "      <td>0.083446</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.078907</td>\n",
       "      <td>0.019420</td>\n",
       "      <td>0.002842</td>\n",
       "      <td>0.000144</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.643590</td>\n",
       "      <td>0.575818</td>\n",
       "      <td>0.632068</td>\n",
       "      <td>0.530684</td>\n",
       "      <td>0.574858</td>\n",
       "      <td>0.591403</td>\n",
       "      <td>0.041426</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.068245</td>\n",
       "      <td>0.013887</td>\n",
       "      <td>0.002603</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.558937</td>\n",
       "      <td>0.501286</td>\n",
       "      <td>0.466316</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.474605</td>\n",
       "      <td>0.458202</td>\n",
       "      <td>0.090194</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.037010</td>\n",
       "      <td>0.003577</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.681923</td>\n",
       "      <td>0.568750</td>\n",
       "      <td>0.656447</td>\n",
       "      <td>0.588073</td>\n",
       "      <td>0.613632</td>\n",
       "      <td>0.621765</td>\n",
       "      <td>0.042033</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.060195</td>\n",
       "      <td>0.006698</td>\n",
       "      <td>0.002741</td>\n",
       "      <td>0.000167</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.613422</td>\n",
       "      <td>0.623027</td>\n",
       "      <td>0.441810</td>\n",
       "      <td>0.675532</td>\n",
       "      <td>0.644155</td>\n",
       "      <td>0.599589</td>\n",
       "      <td>0.081717</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.075216</td>\n",
       "      <td>0.022913</td>\n",
       "      <td>0.002742</td>\n",
       "      <td>0.000471</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.463727</td>\n",
       "      <td>0.394467</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.444833</td>\n",
       "      <td>0.392936</td>\n",
       "      <td>0.061282</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.040537</td>\n",
       "      <td>0.008256</td>\n",
       "      <td>0.002639</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.608711</td>\n",
       "      <td>0.626382</td>\n",
       "      <td>0.680312</td>\n",
       "      <td>0.608701</td>\n",
       "      <td>0.601418</td>\n",
       "      <td>0.625105</td>\n",
       "      <td>0.028804</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.067238</td>\n",
       "      <td>0.012080</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.562623</td>\n",
       "      <td>0.516721</td>\n",
       "      <td>0.541699</td>\n",
       "      <td>0.659542</td>\n",
       "      <td>0.595807</td>\n",
       "      <td>0.575278</td>\n",
       "      <td>0.049475</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.059100</td>\n",
       "      <td>0.005211</td>\n",
       "      <td>0.003104</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.575011</td>\n",
       "      <td>0.358107</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.466351</td>\n",
       "      <td>0.511681</td>\n",
       "      <td>0.440203</td>\n",
       "      <td>0.103253</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.037707</td>\n",
       "      <td>0.008622</td>\n",
       "      <td>0.002514</td>\n",
       "      <td>0.000085</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.585290</td>\n",
       "      <td>0.641619</td>\n",
       "      <td>0.668286</td>\n",
       "      <td>0.587601</td>\n",
       "      <td>0.704781</td>\n",
       "      <td>0.637515</td>\n",
       "      <td>0.046276</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.068521</td>\n",
       "      <td>0.015520</td>\n",
       "      <td>0.002811</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.643363</td>\n",
       "      <td>0.561535</td>\n",
       "      <td>0.643931</td>\n",
       "      <td>0.620507</td>\n",
       "      <td>0.631597</td>\n",
       "      <td>0.620187</td>\n",
       "      <td>0.030565</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.045298</td>\n",
       "      <td>0.002852</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.322646</td>\n",
       "      <td>0.040111</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.044468</td>\n",
       "      <td>0.009910</td>\n",
       "      <td>0.002786</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.409678</td>\n",
       "      <td>0.553664</td>\n",
       "      <td>0.495391</td>\n",
       "      <td>0.302735</td>\n",
       "      <td>0.403472</td>\n",
       "      <td>0.432988</td>\n",
       "      <td>0.085834</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.062218</td>\n",
       "      <td>0.014639</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.000166</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.355383</td>\n",
       "      <td>0.032758</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.052067</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>0.002543</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.497111</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.445776</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.362505</td>\n",
       "      <td>0.090417</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.043244</td>\n",
       "      <td>0.011562</td>\n",
       "      <td>0.002726</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.423157</td>\n",
       "      <td>0.559877</td>\n",
       "      <td>0.495744</td>\n",
       "      <td>0.375994</td>\n",
       "      <td>0.413272</td>\n",
       "      <td>0.453609</td>\n",
       "      <td>0.065798</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.053229</td>\n",
       "      <td>0.005718</td>\n",
       "      <td>0.002529</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.497111</td>\n",
       "      <td>0.339982</td>\n",
       "      <td>0.364091</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.474831</td>\n",
       "      <td>0.393176</td>\n",
       "      <td>0.079772</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.048284</td>\n",
       "      <td>0.004366</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.355395</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.051705</td>\n",
       "      <td>0.013056</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000123</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.392857</td>\n",
       "      <td>0.538610</td>\n",
       "      <td>0.521350</td>\n",
       "      <td>0.461959</td>\n",
       "      <td>0.557587</td>\n",
       "      <td>0.494472</td>\n",
       "      <td>0.060061</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.053383</td>\n",
       "      <td>0.007192</td>\n",
       "      <td>0.002932</td>\n",
       "      <td>0.000710</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.394467</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.343548</td>\n",
       "      <td>0.044594</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.047966</td>\n",
       "      <td>0.001678</td>\n",
       "      <td>0.002457</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.045542</td>\n",
       "      <td>0.005070</td>\n",
       "      <td>0.002900</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.392915</td>\n",
       "      <td>0.301739</td>\n",
       "      <td>0.478895</td>\n",
       "      <td>0.452240</td>\n",
       "      <td>0.479152</td>\n",
       "      <td>0.420988</td>\n",
       "      <td>0.067411</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.053883</td>\n",
       "      <td>0.003881</td>\n",
       "      <td>0.002398</td>\n",
       "      <td>0.000159</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.470900</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.326098</td>\n",
       "      <td>0.072401</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.051476</td>\n",
       "      <td>0.004664</td>\n",
       "      <td>0.004011</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.306263</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.080863</td>\n",
       "      <td>0.024670</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.344279</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.049366</td>\n",
       "      <td>0.002417</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.306263</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.053342</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.078322</td>\n",
       "      <td>0.023932</td>\n",
       "      <td>0.002493</td>\n",
       "      <td>0.000086</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.399483</td>\n",
       "      <td>0.431362</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.361748</td>\n",
       "      <td>0.059869</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.052468</td>\n",
       "      <td>0.002345</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.049178</td>\n",
       "      <td>0.003978</td>\n",
       "      <td>0.002573</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.355395</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.070761</td>\n",
       "      <td>0.010749</td>\n",
       "      <td>0.002847</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.360663</td>\n",
       "      <td>0.036823</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.050629</td>\n",
       "      <td>0.003282</td>\n",
       "      <td>0.002608</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.355395</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.052508</td>\n",
       "      <td>0.004092</td>\n",
       "      <td>0.003027</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.077439</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.002483</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.399483</td>\n",
       "      <td>0.431362</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.361748</td>\n",
       "      <td>0.059869</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.056048</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.046826</td>\n",
       "      <td>0.003709</td>\n",
       "      <td>0.002724</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.306263</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.078778</td>\n",
       "      <td>0.017114</td>\n",
       "      <td>0.002619</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.344279</td>\n",
       "      <td>0.045444</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.069425</td>\n",
       "      <td>0.003444</td>\n",
       "      <td>0.002570</td>\n",
       "      <td>0.000323</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.306263</td>\n",
       "      <td>0.032747</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.052036</td>\n",
       "      <td>0.003394</td>\n",
       "      <td>0.002593</td>\n",
       "      <td>0.000296</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.076355</td>\n",
       "      <td>0.019239</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.399483</td>\n",
       "      <td>0.431362</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.361748</td>\n",
       "      <td>0.059869</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.072322</td>\n",
       "      <td>0.004643</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.048403</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.002677</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.355395</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.072209</td>\n",
       "      <td>0.009650</td>\n",
       "      <td>0.002536</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.360663</td>\n",
       "      <td>0.036823</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.067771</td>\n",
       "      <td>0.003873</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.000564</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.355395</td>\n",
       "      <td>0.032746</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.052230</td>\n",
       "      <td>0.004251</td>\n",
       "      <td>0.002687</td>\n",
       "      <td>0.000415</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.077442</td>\n",
       "      <td>0.020346</td>\n",
       "      <td>0.002471</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.399483</td>\n",
       "      <td>0.431362</td>\n",
       "      <td>0.398122</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.361748</td>\n",
       "      <td>0.059869</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.071553</td>\n",
       "      <td>0.003794</td>\n",
       "      <td>0.002488</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289903</td>\n",
       "      <td>0.289892</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.060363      0.014635         0.002632        0.000248        0.01   \n",
       "1        0.043088      0.006369         0.002822        0.000271        0.01   \n",
       "2        0.078907      0.019420         0.002842        0.000144        0.01   \n",
       "3        0.068245      0.013887         0.002603        0.000230        0.01   \n",
       "4        0.037010      0.003577         0.002908        0.000345        0.01   \n",
       "5        0.060195      0.006698         0.002741        0.000167        0.01   \n",
       "6        0.075216      0.022913         0.002742        0.000471        0.01   \n",
       "7        0.040537      0.008256         0.002639        0.000211        0.01   \n",
       "8        0.067238      0.012080         0.002725        0.000253        0.01   \n",
       "9        0.059100      0.005211         0.003104        0.000384        0.01   \n",
       "10       0.037707      0.008622         0.002514        0.000085        0.01   \n",
       "11       0.068521      0.015520         0.002811        0.000217        0.01   \n",
       "12       0.045298      0.002852         0.002404        0.000172         0.1   \n",
       "13       0.044468      0.009910         0.002786        0.000379         0.1   \n",
       "14       0.062218      0.014639         0.002593        0.000166         0.1   \n",
       "15       0.052067      0.007060         0.002543        0.000275         0.1   \n",
       "16       0.043244      0.011562         0.002726        0.000443         0.1   \n",
       "17       0.053229      0.005718         0.002529        0.000174         0.1   \n",
       "18       0.048284      0.004366         0.002553        0.000205         0.1   \n",
       "19       0.051705      0.013056         0.002553        0.000123         0.1   \n",
       "20       0.053383      0.007192         0.002932        0.000710         0.1   \n",
       "21       0.047966      0.001678         0.002457        0.000219         0.1   \n",
       "22       0.045542      0.005070         0.002900        0.000351         0.1   \n",
       "23       0.053883      0.003881         0.002398        0.000159         0.1   \n",
       "24       0.051476      0.004664         0.004011        0.002835           1   \n",
       "25       0.080863      0.024670         0.002446        0.000095           1   \n",
       "26       0.049366      0.002417         0.002384        0.000116           1   \n",
       "27       0.053342      0.002879         0.002795        0.000416           1   \n",
       "28       0.078322      0.023932         0.002493        0.000086           1   \n",
       "29       0.052468      0.002345         0.002483        0.000140           1   \n",
       "30       0.049178      0.003978         0.002573        0.000025           1   \n",
       "31       0.070761      0.010749         0.002847        0.000345           1   \n",
       "32       0.050629      0.003282         0.002608        0.000140           1   \n",
       "33       0.052508      0.004092         0.003027        0.000670           1   \n",
       "34       0.077439      0.019743         0.002483        0.000195           1   \n",
       "35       0.056048      0.003838         0.002526        0.000211           1   \n",
       "36       0.046826      0.003709         0.002724        0.000603          10   \n",
       "37       0.078778      0.017114         0.002619        0.000311          10   \n",
       "38       0.069425      0.003444         0.002570        0.000323          10   \n",
       "39       0.052036      0.003394         0.002593        0.000296          10   \n",
       "40       0.076355      0.019239         0.002693        0.000281          10   \n",
       "41       0.072322      0.004643         0.002560        0.000384          10   \n",
       "42       0.048403      0.003972         0.002677        0.000359          10   \n",
       "43       0.072209      0.009650         0.002536        0.000173          10   \n",
       "44       0.067771      0.003873         0.002658        0.000564          10   \n",
       "45       0.052230      0.004251         0.002687        0.000415          10   \n",
       "46       0.077442      0.020346         0.002471        0.000122          10   \n",
       "47       0.071553      0.003794         0.002488        0.000191          10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None                True    elasticnet   \n",
       "3                None               False            l1   \n",
       "4                None               False            l2   \n",
       "5                None               False    elasticnet   \n",
       "6            balanced                True            l1   \n",
       "7            balanced                True            l2   \n",
       "8            balanced                True    elasticnet   \n",
       "9            balanced               False            l1   \n",
       "10           balanced               False            l2   \n",
       "11           balanced               False    elasticnet   \n",
       "12               None                True            l1   \n",
       "13               None                True            l2   \n",
       "14               None                True    elasticnet   \n",
       "15               None               False            l1   \n",
       "16               None               False            l2   \n",
       "17               None               False    elasticnet   \n",
       "18           balanced                True            l1   \n",
       "19           balanced                True            l2   \n",
       "20           balanced                True    elasticnet   \n",
       "21           balanced               False            l1   \n",
       "22           balanced               False            l2   \n",
       "23           balanced               False    elasticnet   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None                True    elasticnet   \n",
       "27               None               False            l1   \n",
       "28               None               False            l2   \n",
       "29               None               False    elasticnet   \n",
       "30           balanced                True            l1   \n",
       "31           balanced                True            l2   \n",
       "32           balanced                True    elasticnet   \n",
       "33           balanced               False            l1   \n",
       "34           balanced               False            l2   \n",
       "35           balanced               False    elasticnet   \n",
       "36               None                True            l1   \n",
       "37               None                True            l2   \n",
       "38               None                True    elasticnet   \n",
       "39               None               False            l1   \n",
       "40               None               False            l2   \n",
       "41               None               False    elasticnet   \n",
       "42           balanced                True            l1   \n",
       "43           balanced                True            l2   \n",
       "44           balanced                True    elasticnet   \n",
       "45           balanced               False            l1   \n",
       "46           balanced               False            l2   \n",
       "47           balanced               False    elasticnet   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.458690   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.517246   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.643590   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.558937   \n",
       "4   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.681923   \n",
       "5   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.613422   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.463727   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.608711   \n",
       "8   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.562623   \n",
       "9   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.575011   \n",
       "10  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.585290   \n",
       "11  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.643363   \n",
       "12  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.289954   \n",
       "13  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.409678   \n",
       "14  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.371718   \n",
       "15  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.497111   \n",
       "16  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.423157   \n",
       "17  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.497111   \n",
       "18  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.371718   \n",
       "19  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.392857   \n",
       "20  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.371718   \n",
       "21  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.289954   \n",
       "22  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.392915   \n",
       "23  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.289954   \n",
       "24  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.289954   \n",
       "25  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.371718   \n",
       "26  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.289954   \n",
       "27  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.289954   \n",
       "28  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.399483   \n",
       "29  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.289954   \n",
       "30  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.371718   \n",
       "31  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.371718   \n",
       "32  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.371718   \n",
       "33  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.289954   \n",
       "34  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.399483   \n",
       "35  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.289954   \n",
       "36  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.289954   \n",
       "37  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.371718   \n",
       "38  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.289954   \n",
       "39  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.289954   \n",
       "40  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.399483   \n",
       "41  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.289954   \n",
       "42  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.371718   \n",
       "43  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.371718   \n",
       "44  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.371718   \n",
       "45  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.289954   \n",
       "46  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.399483   \n",
       "47  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.289954   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.394467           0.470900           0.289867   \n",
       "1            0.539202           0.520275           0.583660   \n",
       "2            0.575818           0.632068           0.530684   \n",
       "3            0.501286           0.466316           0.289867   \n",
       "4            0.568750           0.656447           0.588073   \n",
       "5            0.623027           0.441810           0.675532   \n",
       "6            0.394467           0.371785           0.289867   \n",
       "7            0.626382           0.680312           0.608701   \n",
       "8            0.516721           0.541699           0.659542   \n",
       "9            0.358107           0.289867           0.466351   \n",
       "10           0.641619           0.668286           0.587601   \n",
       "11           0.561535           0.643931           0.620507   \n",
       "12           0.371785           0.289867           0.289867   \n",
       "13           0.553664           0.495391           0.302735   \n",
       "14           0.371785           0.371785           0.289867   \n",
       "15           0.289867           0.289867           0.445776   \n",
       "16           0.559877           0.495744           0.375994   \n",
       "17           0.339982           0.364091           0.289867   \n",
       "18           0.371785           0.371785           0.371785   \n",
       "19           0.538610           0.521350           0.461959   \n",
       "20           0.394467           0.371785           0.289867   \n",
       "21           0.289867           0.289867           0.289867   \n",
       "22           0.301739           0.478895           0.452240   \n",
       "23           0.289867           0.470900           0.289867   \n",
       "24           0.289867           0.289867           0.289867   \n",
       "25           0.371785           0.398122           0.289867   \n",
       "26           0.289867           0.289867           0.289867   \n",
       "27           0.289867           0.289867           0.289867   \n",
       "28           0.431362           0.398122           0.289867   \n",
       "29           0.289867           0.289867           0.289867   \n",
       "30           0.371785           0.371785           0.371785   \n",
       "31           0.371785           0.398122           0.371785   \n",
       "32           0.371785           0.371785           0.371785   \n",
       "33           0.289867           0.289867           0.289867   \n",
       "34           0.431362           0.398122           0.289867   \n",
       "35           0.289867           0.289867           0.289867   \n",
       "36           0.289867           0.289867           0.289867   \n",
       "37           0.371785           0.398122           0.289867   \n",
       "38           0.289867           0.289867           0.289867   \n",
       "39           0.289867           0.289867           0.289867   \n",
       "40           0.431362           0.398122           0.289867   \n",
       "41           0.289867           0.289867           0.289867   \n",
       "42           0.371785           0.371785           0.371785   \n",
       "43           0.371785           0.398122           0.371785   \n",
       "44           0.371785           0.371785           0.371785   \n",
       "45           0.289867           0.289867           0.289867   \n",
       "46           0.431362           0.398122           0.289867   \n",
       "47           0.289867           0.289867           0.289867   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.289903         0.380765        0.078616               17  \n",
       "1            0.340087         0.500094        0.083446                8  \n",
       "2            0.574858         0.591403        0.041426                6  \n",
       "3            0.474605         0.458202        0.090194               10  \n",
       "4            0.613632         0.621765        0.042033                3  \n",
       "5            0.644155         0.599589        0.081717                5  \n",
       "6            0.444833         0.392936        0.061282               16  \n",
       "7            0.601418         0.625105        0.028804                2  \n",
       "8            0.595807         0.575278        0.049475                7  \n",
       "9            0.511681         0.440203        0.103253               12  \n",
       "10           0.704781         0.637515        0.046276                1  \n",
       "11           0.631597         0.620187        0.030565                4  \n",
       "12           0.371758         0.322646        0.040111               35  \n",
       "13           0.403472         0.432988        0.085834               13  \n",
       "14           0.371758         0.355383        0.032758               30  \n",
       "15           0.289903         0.362505        0.090417               18  \n",
       "16           0.413272         0.453609        0.065798               11  \n",
       "17           0.474831         0.393176        0.079772               15  \n",
       "18           0.289903         0.355395        0.032746               25  \n",
       "19           0.557587         0.494472        0.060061                9  \n",
       "20           0.289903         0.343548        0.044594               33  \n",
       "21           0.289903         0.289892        0.000034               40  \n",
       "22           0.479152         0.420988        0.067411               14  \n",
       "23           0.289903         0.326098        0.072401               34  \n",
       "24           0.371758         0.306263        0.032747               36  \n",
       "25           0.289903         0.344279        0.045444               31  \n",
       "26           0.371758         0.306263        0.032747               36  \n",
       "27           0.289903         0.289892        0.000034               40  \n",
       "28           0.289903         0.361748        0.059869               19  \n",
       "29           0.289903         0.289892        0.000034               40  \n",
       "30           0.289903         0.355395        0.032746               25  \n",
       "31           0.289903         0.360663        0.036823               23  \n",
       "32           0.289903         0.355395        0.032746               25  \n",
       "33           0.289903         0.289892        0.000034               40  \n",
       "34           0.289903         0.361748        0.059869               19  \n",
       "35           0.289903         0.289892        0.000034               40  \n",
       "36           0.371758         0.306263        0.032747               36  \n",
       "37           0.289903         0.344279        0.045444               31  \n",
       "38           0.371758         0.306263        0.032747               36  \n",
       "39           0.289903         0.289892        0.000034               40  \n",
       "40           0.289903         0.361748        0.059869               19  \n",
       "41           0.289903         0.289892        0.000034               40  \n",
       "42           0.289903         0.355395        0.032746               25  \n",
       "43           0.289903         0.360663        0.036823               23  \n",
       "44           0.289903         0.355395        0.032746               25  \n",
       "45           0.289903         0.289892        0.000034               40  \n",
       "46           0.289903         0.361748        0.059869               19  \n",
       "47           0.289903         0.289892        0.000034               40  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(perceptron_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier with optimal hyperparameters had an average macro f1 score of 0.8089098035639168 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd_params = {'penalty':['l1', 'l2'], 'alpha':[0.01, 0.1, 1], 'class_weight': [None,'balanced'], 'loss':['hinge', 'modified_huber']}\n",
    "sgd_tuner = GridSearchCV(sgd, sgd_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "sgd_tuner.fit(X_train, y_train)\n",
    "print('SGD Classifier with optimal hyperparameters had an average macro f1 score of '+str(sgd_tuner.best_score_)+' using the following hyperparameters: '+str(sgd_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062684</td>\n",
       "      <td>0.007264</td>\n",
       "      <td>0.002614</td>\n",
       "      <td>0.000221</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.548090</td>\n",
       "      <td>0.500054</td>\n",
       "      <td>0.534194</td>\n",
       "      <td>0.529863</td>\n",
       "      <td>0.530428</td>\n",
       "      <td>0.528526</td>\n",
       "      <td>0.015690</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.048157</td>\n",
       "      <td>0.004786</td>\n",
       "      <td>0.002684</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.590791</td>\n",
       "      <td>0.504272</td>\n",
       "      <td>0.567645</td>\n",
       "      <td>0.558162</td>\n",
       "      <td>0.564232</td>\n",
       "      <td>0.557020</td>\n",
       "      <td>0.028597</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.059015</td>\n",
       "      <td>0.008668</td>\n",
       "      <td>0.002552</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.629827</td>\n",
       "      <td>0.548766</td>\n",
       "      <td>0.627992</td>\n",
       "      <td>0.616857</td>\n",
       "      <td>0.622636</td>\n",
       "      <td>0.609216</td>\n",
       "      <td>0.030561</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.004688</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.819043</td>\n",
       "      <td>0.724860</td>\n",
       "      <td>0.816532</td>\n",
       "      <td>0.807346</td>\n",
       "      <td>0.818780</td>\n",
       "      <td>0.797312</td>\n",
       "      <td>0.036476</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.073343</td>\n",
       "      <td>0.017363</td>\n",
       "      <td>0.002658</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.593536</td>\n",
       "      <td>0.533930</td>\n",
       "      <td>0.621412</td>\n",
       "      <td>0.612666</td>\n",
       "      <td>0.613893</td>\n",
       "      <td>0.595087</td>\n",
       "      <td>0.031932</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.056935</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.002560</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.709341</td>\n",
       "      <td>0.611654</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.772717</td>\n",
       "      <td>0.741990</td>\n",
       "      <td>0.717645</td>\n",
       "      <td>0.056825</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.070803</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.003112</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.666666</td>\n",
       "      <td>0.593020</td>\n",
       "      <td>0.666032</td>\n",
       "      <td>0.688481</td>\n",
       "      <td>0.660235</td>\n",
       "      <td>0.654887</td>\n",
       "      <td>0.032396</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.066567</td>\n",
       "      <td>0.007976</td>\n",
       "      <td>0.003064</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.801565</td>\n",
       "      <td>0.748692</td>\n",
       "      <td>0.832707</td>\n",
       "      <td>0.825582</td>\n",
       "      <td>0.836003</td>\n",
       "      <td>0.808910</td>\n",
       "      <td>0.032429</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.054301</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.002430</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.371766</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.046307</td>\n",
       "      <td>0.003748</td>\n",
       "      <td>0.002686</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.381291</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.384522</td>\n",
       "      <td>0.383170</td>\n",
       "      <td>0.378159</td>\n",
       "      <td>0.381324</td>\n",
       "      <td>0.002326</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.059162</td>\n",
       "      <td>0.004153</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.000152</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.371766</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.045699</td>\n",
       "      <td>0.003319</td>\n",
       "      <td>0.002667</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.593061</td>\n",
       "      <td>0.532761</td>\n",
       "      <td>0.574893</td>\n",
       "      <td>0.559398</td>\n",
       "      <td>0.585792</td>\n",
       "      <td>0.569181</td>\n",
       "      <td>0.021452</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.049781</td>\n",
       "      <td>0.003980</td>\n",
       "      <td>0.002404</td>\n",
       "      <td>0.000132</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.371766</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.056752</td>\n",
       "      <td>0.008511</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.000225</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.563585</td>\n",
       "      <td>0.638900</td>\n",
       "      <td>0.549669</td>\n",
       "      <td>0.509105</td>\n",
       "      <td>0.537241</td>\n",
       "      <td>0.559700</td>\n",
       "      <td>0.043480</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.054597</td>\n",
       "      <td>0.004665</td>\n",
       "      <td>0.002604</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.289954</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.355413</td>\n",
       "      <td>0.032730</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.055776</td>\n",
       "      <td>0.006381</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.774448</td>\n",
       "      <td>0.676508</td>\n",
       "      <td>0.809745</td>\n",
       "      <td>0.806708</td>\n",
       "      <td>0.810274</td>\n",
       "      <td>0.775536</td>\n",
       "      <td>0.051296</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.052113</td>\n",
       "      <td>0.003569</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.000453</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.371766</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.038097</td>\n",
       "      <td>0.002060</td>\n",
       "      <td>0.002376</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.377207</td>\n",
       "      <td>0.376365</td>\n",
       "      <td>0.374079</td>\n",
       "      <td>0.377732</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.375428</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.058942</td>\n",
       "      <td>0.006338</td>\n",
       "      <td>0.002951</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.371766</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038259</td>\n",
       "      <td>0.002157</td>\n",
       "      <td>0.002385</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.380839</td>\n",
       "      <td>0.381149</td>\n",
       "      <td>0.375908</td>\n",
       "      <td>0.379479</td>\n",
       "      <td>0.374967</td>\n",
       "      <td>0.378468</td>\n",
       "      <td>0.002555</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.053619</td>\n",
       "      <td>0.002962</td>\n",
       "      <td>0.002771</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.338999</td>\n",
       "      <td>0.040116</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.037721</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000229</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.559847</td>\n",
       "      <td>0.637340</td>\n",
       "      <td>0.549758</td>\n",
       "      <td>0.507031</td>\n",
       "      <td>0.376337</td>\n",
       "      <td>0.526063</td>\n",
       "      <td>0.085867</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.054142</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.002950</td>\n",
       "      <td>0.000686</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.371718</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.371785</td>\n",
       "      <td>0.289867</td>\n",
       "      <td>0.371758</td>\n",
       "      <td>0.355383</td>\n",
       "      <td>0.032758</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.039844</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.002567</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.701617</td>\n",
       "      <td>0.662620</td>\n",
       "      <td>0.623389</td>\n",
       "      <td>0.586324</td>\n",
       "      <td>0.503665</td>\n",
       "      <td>0.615523</td>\n",
       "      <td>0.067908</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.062684      0.007264         0.002614        0.000221        0.01   \n",
       "1        0.048157      0.004786         0.002684        0.000182        0.01   \n",
       "2        0.059015      0.008668         0.002552        0.000111        0.01   \n",
       "3        0.054307      0.004688         0.002751        0.000190        0.01   \n",
       "4        0.073343      0.017363         0.002658        0.000128        0.01   \n",
       "5        0.056935      0.003779         0.002560        0.000092        0.01   \n",
       "6        0.070803      0.008756         0.003112        0.000285        0.01   \n",
       "7        0.066567      0.007976         0.003064        0.000267        0.01   \n",
       "8        0.054301      0.002220         0.002430        0.000150         0.1   \n",
       "9        0.046307      0.003748         0.002686        0.000231         0.1   \n",
       "10       0.059162      0.004153         0.002526        0.000152         0.1   \n",
       "11       0.045699      0.003319         0.002667        0.000265         0.1   \n",
       "12       0.049781      0.003980         0.002404        0.000132         0.1   \n",
       "13       0.056752      0.008511         0.002580        0.000225         0.1   \n",
       "14       0.054597      0.004665         0.002604        0.000186         0.1   \n",
       "15       0.055776      0.006381         0.002632        0.000133         0.1   \n",
       "16       0.052113      0.003569         0.002911        0.000453           1   \n",
       "17       0.038097      0.002060         0.002376        0.000151           1   \n",
       "18       0.058942      0.006338         0.002951        0.000379           1   \n",
       "19       0.038259      0.002157         0.002385        0.000207           1   \n",
       "20       0.053619      0.002962         0.002771        0.000373           1   \n",
       "21       0.037721      0.001649         0.002515        0.000229           1   \n",
       "22       0.054142      0.004379         0.002950        0.000686           1   \n",
       "23       0.039844      0.002469         0.002567        0.000172           1   \n",
       "\n",
       "   param_class_weight      param_loss param_penalty  \\\n",
       "0                None           hinge            l1   \n",
       "1                None           hinge            l2   \n",
       "2                None  modified_huber            l1   \n",
       "3                None  modified_huber            l2   \n",
       "4            balanced           hinge            l1   \n",
       "5            balanced           hinge            l2   \n",
       "6            balanced  modified_huber            l1   \n",
       "7            balanced  modified_huber            l2   \n",
       "8                None           hinge            l1   \n",
       "9                None           hinge            l2   \n",
       "10               None  modified_huber            l1   \n",
       "11               None  modified_huber            l2   \n",
       "12           balanced           hinge            l1   \n",
       "13           balanced           hinge            l2   \n",
       "14           balanced  modified_huber            l1   \n",
       "15           balanced  modified_huber            l2   \n",
       "16               None           hinge            l1   \n",
       "17               None           hinge            l2   \n",
       "18               None  modified_huber            l1   \n",
       "19               None  modified_huber            l2   \n",
       "20           balanced           hinge            l1   \n",
       "21           balanced           hinge            l2   \n",
       "22           balanced  modified_huber            l1   \n",
       "23           balanced  modified_huber            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.548090   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.590791   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.629827   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.819043   \n",
       "4   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.593536   \n",
       "5   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.709341   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.666666   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.801565   \n",
       "8   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.371718   \n",
       "9   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.381291   \n",
       "10  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.371718   \n",
       "11  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.593061   \n",
       "12  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.371718   \n",
       "13  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.563585   \n",
       "14  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.289954   \n",
       "15  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.774448   \n",
       "16  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.371718   \n",
       "17  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.377207   \n",
       "18  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.371718   \n",
       "19  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.380839   \n",
       "20  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.371718   \n",
       "21  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.559847   \n",
       "22  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.371718   \n",
       "23  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.701617   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.500054           0.534194           0.529863   \n",
       "1            0.504272           0.567645           0.558162   \n",
       "2            0.548766           0.627992           0.616857   \n",
       "3            0.724860           0.816532           0.807346   \n",
       "4            0.533930           0.621412           0.612666   \n",
       "5            0.611654           0.752525           0.772717   \n",
       "6            0.593020           0.666032           0.688481   \n",
       "7            0.748692           0.832707           0.825582   \n",
       "8            0.371785           0.371785           0.371785   \n",
       "9            0.379479           0.384522           0.383170   \n",
       "10           0.371785           0.371785           0.371785   \n",
       "11           0.532761           0.574893           0.559398   \n",
       "12           0.371785           0.371785           0.371785   \n",
       "13           0.638900           0.549669           0.509105   \n",
       "14           0.371785           0.371785           0.371785   \n",
       "15           0.676508           0.809745           0.806708   \n",
       "16           0.371785           0.371785           0.371785   \n",
       "17           0.376365           0.374079           0.377732   \n",
       "18           0.371785           0.371785           0.371785   \n",
       "19           0.381149           0.375908           0.379479   \n",
       "20           0.371785           0.289867           0.289867   \n",
       "21           0.637340           0.549758           0.507031   \n",
       "22           0.371785           0.371785           0.289867   \n",
       "23           0.662620           0.623389           0.586324   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.530428         0.528526        0.015690               12  \n",
       "1            0.564232         0.557020        0.028597               11  \n",
       "2            0.622636         0.609216        0.030561                7  \n",
       "3            0.818780         0.797312        0.036476                2  \n",
       "4            0.613893         0.595087        0.031932                8  \n",
       "5            0.741990         0.717645        0.056825                4  \n",
       "6            0.660235         0.654887        0.032396                5  \n",
       "7            0.836003         0.808910        0.032429                1  \n",
       "8            0.371758         0.371766        0.000027               17  \n",
       "9            0.378159         0.381324        0.002326               14  \n",
       "10           0.371758         0.371766        0.000027               17  \n",
       "11           0.585792         0.569181        0.021452                9  \n",
       "12           0.371758         0.371766        0.000027               17  \n",
       "13           0.537241         0.559700        0.043480               10  \n",
       "14           0.371758         0.355413        0.032730               22  \n",
       "15           0.810274         0.775536        0.051296                3  \n",
       "16           0.371758         0.371766        0.000027               17  \n",
       "17           0.371758         0.375428        0.002220               16  \n",
       "18           0.371758         0.371766        0.000027               17  \n",
       "19           0.374967         0.378468        0.002555               15  \n",
       "20           0.371758         0.338999        0.040116               24  \n",
       "21           0.376337         0.526063        0.085867               13  \n",
       "22           0.371758         0.355383        0.032758               23  \n",
       "23           0.503665         0.615523        0.067908                6  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(sgd_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV Metrics: Cutoff 2\n",
      "\n",
      "Tuned Logistic Regression Model:\n",
      "Accuracy Average: 0.7278818018543387\n",
      "Precision Average: 0.7191493301977945\n",
      "F1 Score Average: 0.717409166940258\n",
      "ROC AUC Score Average: 0.72778479438654\n",
      "Confusion Matrix Average:\n",
      "[1814.6  568.6]\n",
      "[1020.  2434.6]\n",
      "\n",
      "\n",
      "Tuned Perceptron Model:\n",
      "Accuracy Average: 0.6223564832511974\n",
      "Precision Average: 0.6407491264162853\n",
      "F1 Score Average: 0.5241438161578353\n",
      "ROC AUC Score Average: 0.5855012899281438\n",
      "Confusion Matrix Average:\n",
      "[ 778.  1605.2]\n",
      "[ 599.4 2855.2]\n",
      "\n",
      "\n",
      "Tuned SGD Classifier:\n",
      "Accuracy Average: 0.7269217299500422\n",
      "Precision Average: 0.7200863189890578\n",
      "F1 Score Average: 0.7158564110232619\n",
      "ROC AUC Score Average: 0.7316296021692464\n",
      "Confusion Matrix Average:\n",
      "[1895.2  488. ]\n",
      "[1106.2 2348.4]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print average k-fold CV metrics for optimally tuned models\n",
    "cutoff = 2\n",
    "\n",
    "print(f\"5-Fold CV Metrics: Cutoff {cutoff}\\n\")\n",
    "\n",
    "print(\"Tuned Logistic Regression Model:\")\n",
    "logReg.set_params(**logReg_tuner.best_params_)\n",
    "predictions = cv_metrics(logReg, 2)\n",
    "\n",
    "print(\"Tuned Perceptron Model:\")\n",
    "perceptron.set_params(**perceptron_tuner.best_params_)\n",
    "predictions = cv_metrics(perceptron, 2)\n",
    "\n",
    "print(\"Tuned SGD Classifier:\")\n",
    "sgd.set_params(**sgd_tuner.best_params_)\n",
    "predictions = cv_metrics(sgd, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Testing\n",
    "Again, the tuned Logistic Regression seems to have the best average scores, I will use this model to predict the test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save test predictions\n",
    "y_test_hat_2 = logReg.predict(X_test)\n",
    "out_results(y_test_hat_2, \"binary\", 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a macro f1 score of 0.83634 on the test set on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set binary cutoff to 3\n",
    "y_train = construct_labels(df_train, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression with optimal hyperparameters had an average macro f1 score of 0.8417391261909515 using the following hyperparameters: {'C': 1, 'class_weight': None, 'fit_intercept': True, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "logReg = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)\n",
    "logReg_params = {'penalty':['l1', 'l2'], 'C':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "logReg_tuner = GridSearchCV(logReg, logReg_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "logReg_tuner.fit(X_train, y_train)\n",
    "print('Logisitic Regression with optimal hyperparameters had an average macro f1 score of '+str(logReg_tuner.best_score_)+' using the following hyperparameters: '+str(logReg_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.062113</td>\n",
       "      <td>0.004756</td>\n",
       "      <td>0.003655</td>\n",
       "      <td>0.000517</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.666543</td>\n",
       "      <td>0.578193</td>\n",
       "      <td>0.652785</td>\n",
       "      <td>0.655240</td>\n",
       "      <td>0.670710</td>\n",
       "      <td>0.644694</td>\n",
       "      <td>0.033921</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.077555</td>\n",
       "      <td>0.002338</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000359</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.701800</td>\n",
       "      <td>0.603753</td>\n",
       "      <td>0.700925</td>\n",
       "      <td>0.707313</td>\n",
       "      <td>0.703285</td>\n",
       "      <td>0.683415</td>\n",
       "      <td>0.039892</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.061300</td>\n",
       "      <td>0.003734</td>\n",
       "      <td>0.003471</td>\n",
       "      <td>0.000203</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.668533</td>\n",
       "      <td>0.596384</td>\n",
       "      <td>0.657270</td>\n",
       "      <td>0.658517</td>\n",
       "      <td>0.678671</td>\n",
       "      <td>0.651875</td>\n",
       "      <td>0.028803</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071949</td>\n",
       "      <td>0.006926</td>\n",
       "      <td>0.003334</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.713861</td>\n",
       "      <td>0.641480</td>\n",
       "      <td>0.720014</td>\n",
       "      <td>0.728784</td>\n",
       "      <td>0.724967</td>\n",
       "      <td>0.705821</td>\n",
       "      <td>0.032557</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.062452</td>\n",
       "      <td>0.002916</td>\n",
       "      <td>0.004109</td>\n",
       "      <td>0.000250</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.735259</td>\n",
       "      <td>0.659845</td>\n",
       "      <td>0.721388</td>\n",
       "      <td>0.725401</td>\n",
       "      <td>0.720301</td>\n",
       "      <td>0.712439</td>\n",
       "      <td>0.026821</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.077777</td>\n",
       "      <td>0.008833</td>\n",
       "      <td>0.002879</td>\n",
       "      <td>0.000246</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.814462</td>\n",
       "      <td>0.749707</td>\n",
       "      <td>0.836449</td>\n",
       "      <td>0.827464</td>\n",
       "      <td>0.834747</td>\n",
       "      <td>0.812566</td>\n",
       "      <td>0.032370</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.057279</td>\n",
       "      <td>0.006768</td>\n",
       "      <td>0.003791</td>\n",
       "      <td>0.000133</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.736067</td>\n",
       "      <td>0.665466</td>\n",
       "      <td>0.723365</td>\n",
       "      <td>0.725974</td>\n",
       "      <td>0.725082</td>\n",
       "      <td>0.715191</td>\n",
       "      <td>0.025256</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.077144</td>\n",
       "      <td>0.005087</td>\n",
       "      <td>0.003075</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.815504</td>\n",
       "      <td>0.752410</td>\n",
       "      <td>0.843314</td>\n",
       "      <td>0.831337</td>\n",
       "      <td>0.842596</td>\n",
       "      <td>0.817032</td>\n",
       "      <td>0.033844</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.130682</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.795524</td>\n",
       "      <td>0.722473</td>\n",
       "      <td>0.810298</td>\n",
       "      <td>0.813611</td>\n",
       "      <td>0.805726</td>\n",
       "      <td>0.789526</td>\n",
       "      <td>0.034077</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.105266</td>\n",
       "      <td>0.004149</td>\n",
       "      <td>0.003521</td>\n",
       "      <td>0.000783</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.814140</td>\n",
       "      <td>0.762610</td>\n",
       "      <td>0.840680</td>\n",
       "      <td>0.840160</td>\n",
       "      <td>0.848055</td>\n",
       "      <td>0.821129</td>\n",
       "      <td>0.031441</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.072047</td>\n",
       "      <td>0.004649</td>\n",
       "      <td>0.004088</td>\n",
       "      <td>0.000849</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.796061</td>\n",
       "      <td>0.731086</td>\n",
       "      <td>0.818077</td>\n",
       "      <td>0.816908</td>\n",
       "      <td>0.814624</td>\n",
       "      <td>0.795351</td>\n",
       "      <td>0.033116</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.105850</td>\n",
       "      <td>0.008756</td>\n",
       "      <td>0.003011</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.813734</td>\n",
       "      <td>0.767261</td>\n",
       "      <td>0.845437</td>\n",
       "      <td>0.843634</td>\n",
       "      <td>0.852713</td>\n",
       "      <td>0.824556</td>\n",
       "      <td>0.031599</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.144566</td>\n",
       "      <td>0.011314</td>\n",
       "      <td>0.003780</td>\n",
       "      <td>0.000217</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.817364</td>\n",
       "      <td>0.749857</td>\n",
       "      <td>0.834309</td>\n",
       "      <td>0.820345</td>\n",
       "      <td>0.828344</td>\n",
       "      <td>0.810044</td>\n",
       "      <td>0.030679</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.127923</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.002928</td>\n",
       "      <td>0.000266</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.849891</td>\n",
       "      <td>0.778536</td>\n",
       "      <td>0.860269</td>\n",
       "      <td>0.846453</td>\n",
       "      <td>0.857854</td>\n",
       "      <td>0.838601</td>\n",
       "      <td>0.030454</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.076408</td>\n",
       "      <td>0.004035</td>\n",
       "      <td>0.004272</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.816439</td>\n",
       "      <td>0.735866</td>\n",
       "      <td>0.833249</td>\n",
       "      <td>0.817833</td>\n",
       "      <td>0.830865</td>\n",
       "      <td>0.806850</td>\n",
       "      <td>0.036125</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.118107</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>0.002873</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.846980</td>\n",
       "      <td>0.770538</td>\n",
       "      <td>0.860019</td>\n",
       "      <td>0.847724</td>\n",
       "      <td>0.857291</td>\n",
       "      <td>0.836510</td>\n",
       "      <td>0.033383</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.365975</td>\n",
       "      <td>0.018738</td>\n",
       "      <td>0.003821</td>\n",
       "      <td>0.000497</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.848302</td>\n",
       "      <td>0.785587</td>\n",
       "      <td>0.851463</td>\n",
       "      <td>0.852406</td>\n",
       "      <td>0.863332</td>\n",
       "      <td>0.840218</td>\n",
       "      <td>0.027782</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.172786</td>\n",
       "      <td>0.016093</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.848783</td>\n",
       "      <td>0.785088</td>\n",
       "      <td>0.855216</td>\n",
       "      <td>0.853417</td>\n",
       "      <td>0.866191</td>\n",
       "      <td>0.841739</td>\n",
       "      <td>0.028896</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.103303</td>\n",
       "      <td>0.005485</td>\n",
       "      <td>0.004235</td>\n",
       "      <td>0.000983</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.845681</td>\n",
       "      <td>0.783100</td>\n",
       "      <td>0.851917</td>\n",
       "      <td>0.852709</td>\n",
       "      <td>0.863210</td>\n",
       "      <td>0.839323</td>\n",
       "      <td>0.028670</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.169223</td>\n",
       "      <td>0.013183</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.845723</td>\n",
       "      <td>0.780439</td>\n",
       "      <td>0.856930</td>\n",
       "      <td>0.854669</td>\n",
       "      <td>0.868053</td>\n",
       "      <td>0.841163</td>\n",
       "      <td>0.031184</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.370553</td>\n",
       "      <td>0.006714</td>\n",
       "      <td>0.003594</td>\n",
       "      <td>0.000284</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.852069</td>\n",
       "      <td>0.770468</td>\n",
       "      <td>0.858036</td>\n",
       "      <td>0.847185</td>\n",
       "      <td>0.858945</td>\n",
       "      <td>0.837341</td>\n",
       "      <td>0.033707</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.213653</td>\n",
       "      <td>0.015031</td>\n",
       "      <td>0.003348</td>\n",
       "      <td>0.000829</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.854737</td>\n",
       "      <td>0.772218</td>\n",
       "      <td>0.859322</td>\n",
       "      <td>0.850296</td>\n",
       "      <td>0.861475</td>\n",
       "      <td>0.839610</td>\n",
       "      <td>0.033916</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.112187</td>\n",
       "      <td>0.008268</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.000603</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.850073</td>\n",
       "      <td>0.767398</td>\n",
       "      <td>0.857502</td>\n",
       "      <td>0.847697</td>\n",
       "      <td>0.859613</td>\n",
       "      <td>0.836457</td>\n",
       "      <td>0.034814</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.195606</td>\n",
       "      <td>0.013422</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.851901</td>\n",
       "      <td>0.770364</td>\n",
       "      <td>0.856774</td>\n",
       "      <td>0.849902</td>\n",
       "      <td>0.861698</td>\n",
       "      <td>0.838128</td>\n",
       "      <td>0.034128</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.652137</td>\n",
       "      <td>0.022622</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.000146</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.826480</td>\n",
       "      <td>0.761135</td>\n",
       "      <td>0.835726</td>\n",
       "      <td>0.834083</td>\n",
       "      <td>0.845092</td>\n",
       "      <td>0.820503</td>\n",
       "      <td>0.030269</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.295316</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>0.002889</td>\n",
       "      <td>0.000187</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.833946</td>\n",
       "      <td>0.771174</td>\n",
       "      <td>0.844975</td>\n",
       "      <td>0.839157</td>\n",
       "      <td>0.856330</td>\n",
       "      <td>0.829116</td>\n",
       "      <td>0.029912</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.160573</td>\n",
       "      <td>0.023078</td>\n",
       "      <td>0.003585</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.824054</td>\n",
       "      <td>0.760517</td>\n",
       "      <td>0.835517</td>\n",
       "      <td>0.835467</td>\n",
       "      <td>0.843727</td>\n",
       "      <td>0.819856</td>\n",
       "      <td>0.030324</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.274051</td>\n",
       "      <td>0.012092</td>\n",
       "      <td>0.003087</td>\n",
       "      <td>0.000395</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.835798</td>\n",
       "      <td>0.768666</td>\n",
       "      <td>0.842907</td>\n",
       "      <td>0.840993</td>\n",
       "      <td>0.857053</td>\n",
       "      <td>0.829083</td>\n",
       "      <td>0.031018</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.682156</td>\n",
       "      <td>0.024879</td>\n",
       "      <td>0.003764</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.830022</td>\n",
       "      <td>0.757246</td>\n",
       "      <td>0.835457</td>\n",
       "      <td>0.828871</td>\n",
       "      <td>0.837496</td>\n",
       "      <td>0.817818</td>\n",
       "      <td>0.030458</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.372495</td>\n",
       "      <td>0.041912</td>\n",
       "      <td>0.002827</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.837319</td>\n",
       "      <td>0.766293</td>\n",
       "      <td>0.841897</td>\n",
       "      <td>0.835579</td>\n",
       "      <td>0.847547</td>\n",
       "      <td>0.825727</td>\n",
       "      <td>0.030005</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.202956</td>\n",
       "      <td>0.052527</td>\n",
       "      <td>0.003442</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.829559</td>\n",
       "      <td>0.756462</td>\n",
       "      <td>0.834786</td>\n",
       "      <td>0.830187</td>\n",
       "      <td>0.837916</td>\n",
       "      <td>0.817782</td>\n",
       "      <td>0.030813</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.323208</td>\n",
       "      <td>0.039463</td>\n",
       "      <td>0.002835</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.835213</td>\n",
       "      <td>0.764521</td>\n",
       "      <td>0.842197</td>\n",
       "      <td>0.835887</td>\n",
       "      <td>0.848089</td>\n",
       "      <td>0.825181</td>\n",
       "      <td>0.030689</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.062113      0.004756         0.003655        0.000517    0.01   \n",
       "1        0.077555      0.002338         0.002863        0.000359    0.01   \n",
       "2        0.061300      0.003734         0.003471        0.000203    0.01   \n",
       "3        0.071949      0.006926         0.003334        0.000586    0.01   \n",
       "4        0.062452      0.002916         0.004109        0.000250    0.01   \n",
       "5        0.077777      0.008833         0.002879        0.000246    0.01   \n",
       "6        0.057279      0.006768         0.003791        0.000133    0.01   \n",
       "7        0.077144      0.005087         0.003075        0.000284    0.01   \n",
       "8        0.130682      0.013912         0.003921        0.000466     0.1   \n",
       "9        0.105266      0.004149         0.003521        0.000783     0.1   \n",
       "10       0.072047      0.004649         0.004088        0.000849     0.1   \n",
       "11       0.105850      0.008756         0.003011        0.000254     0.1   \n",
       "12       0.144566      0.011314         0.003780        0.000217     0.1   \n",
       "13       0.127923      0.008911         0.002928        0.000266     0.1   \n",
       "14       0.076408      0.004035         0.004272        0.000275     0.1   \n",
       "15       0.118107      0.010118         0.002873        0.000196     0.1   \n",
       "16       0.365975      0.018738         0.003821        0.000497       1   \n",
       "17       0.172786      0.016093         0.002887        0.000196       1   \n",
       "18       0.103303      0.005485         0.004235        0.000983       1   \n",
       "19       0.169223      0.013183         0.002863        0.000234       1   \n",
       "20       0.370553      0.006714         0.003594        0.000284       1   \n",
       "21       0.213653      0.015031         0.003348        0.000829       1   \n",
       "22       0.112187      0.008268         0.003960        0.000603       1   \n",
       "23       0.195606      0.013422         0.002936        0.000353       1   \n",
       "24       0.652137      0.022622         0.003567        0.000146      10   \n",
       "25       0.295316      0.026966         0.002889        0.000187      10   \n",
       "26       0.160573      0.023078         0.003585        0.000256      10   \n",
       "27       0.274051      0.012092         0.003087        0.000395      10   \n",
       "28       0.682156      0.024879         0.003764        0.000261      10   \n",
       "29       0.372495      0.041912         0.002827        0.000193      10   \n",
       "30       0.202956      0.052527         0.003442        0.000143      10   \n",
       "31       0.323208      0.039463         0.002835        0.000233      10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None               False            l1   \n",
       "3                None               False            l2   \n",
       "4            balanced                True            l1   \n",
       "5            balanced                True            l2   \n",
       "6            balanced               False            l1   \n",
       "7            balanced               False            l2   \n",
       "8                None                True            l1   \n",
       "9                None                True            l2   \n",
       "10               None               False            l1   \n",
       "11               None               False            l2   \n",
       "12           balanced                True            l1   \n",
       "13           balanced                True            l2   \n",
       "14           balanced               False            l1   \n",
       "15           balanced               False            l2   \n",
       "16               None                True            l1   \n",
       "17               None                True            l2   \n",
       "18               None               False            l1   \n",
       "19               None               False            l2   \n",
       "20           balanced                True            l1   \n",
       "21           balanced                True            l2   \n",
       "22           balanced               False            l1   \n",
       "23           balanced               False            l2   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None               False            l1   \n",
       "27               None               False            l2   \n",
       "28           balanced                True            l1   \n",
       "29           balanced                True            l2   \n",
       "30           balanced               False            l1   \n",
       "31           balanced               False            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.666543   \n",
       "1   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.701800   \n",
       "2   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.668533   \n",
       "3   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.713861   \n",
       "4   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.735259   \n",
       "5   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.814462   \n",
       "6   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.736067   \n",
       "7   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.815504   \n",
       "8   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.795524   \n",
       "9   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.814140   \n",
       "10  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.796061   \n",
       "11  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.813734   \n",
       "12  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.817364   \n",
       "13  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.849891   \n",
       "14  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.816439   \n",
       "15  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.846980   \n",
       "16  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.848302   \n",
       "17  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.848783   \n",
       "18  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.845681   \n",
       "19  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.845723   \n",
       "20  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.852069   \n",
       "21  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.854737   \n",
       "22  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.850073   \n",
       "23  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.851901   \n",
       "24  {'C': 10, 'class_weight': None, 'fit_intercept...           0.826480   \n",
       "25  {'C': 10, 'class_weight': None, 'fit_intercept...           0.833946   \n",
       "26  {'C': 10, 'class_weight': None, 'fit_intercept...           0.824054   \n",
       "27  {'C': 10, 'class_weight': None, 'fit_intercept...           0.835798   \n",
       "28  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.830022   \n",
       "29  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.837319   \n",
       "30  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.829559   \n",
       "31  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.835213   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.578193           0.652785           0.655240   \n",
       "1            0.603753           0.700925           0.707313   \n",
       "2            0.596384           0.657270           0.658517   \n",
       "3            0.641480           0.720014           0.728784   \n",
       "4            0.659845           0.721388           0.725401   \n",
       "5            0.749707           0.836449           0.827464   \n",
       "6            0.665466           0.723365           0.725974   \n",
       "7            0.752410           0.843314           0.831337   \n",
       "8            0.722473           0.810298           0.813611   \n",
       "9            0.762610           0.840680           0.840160   \n",
       "10           0.731086           0.818077           0.816908   \n",
       "11           0.767261           0.845437           0.843634   \n",
       "12           0.749857           0.834309           0.820345   \n",
       "13           0.778536           0.860269           0.846453   \n",
       "14           0.735866           0.833249           0.817833   \n",
       "15           0.770538           0.860019           0.847724   \n",
       "16           0.785587           0.851463           0.852406   \n",
       "17           0.785088           0.855216           0.853417   \n",
       "18           0.783100           0.851917           0.852709   \n",
       "19           0.780439           0.856930           0.854669   \n",
       "20           0.770468           0.858036           0.847185   \n",
       "21           0.772218           0.859322           0.850296   \n",
       "22           0.767398           0.857502           0.847697   \n",
       "23           0.770364           0.856774           0.849902   \n",
       "24           0.761135           0.835726           0.834083   \n",
       "25           0.771174           0.844975           0.839157   \n",
       "26           0.760517           0.835517           0.835467   \n",
       "27           0.768666           0.842907           0.840993   \n",
       "28           0.757246           0.835457           0.828871   \n",
       "29           0.766293           0.841897           0.835579   \n",
       "30           0.756462           0.834786           0.830187   \n",
       "31           0.764521           0.842197           0.835887   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.670710         0.644694        0.033921               32  \n",
       "1            0.703285         0.683415        0.039892               30  \n",
       "2            0.678671         0.651875        0.028803               31  \n",
       "3            0.724967         0.705821        0.032557               29  \n",
       "4            0.720301         0.712439        0.026821               28  \n",
       "5            0.834747         0.812566        0.032370               22  \n",
       "6            0.725082         0.715191        0.025256               27  \n",
       "7            0.842596         0.817032        0.033844               21  \n",
       "8            0.805726         0.789526        0.034077               26  \n",
       "9            0.848055         0.821129        0.031441               16  \n",
       "10           0.814624         0.795351        0.033116               25  \n",
       "11           0.852713         0.824556        0.031599               15  \n",
       "12           0.828344         0.810044        0.030679               23  \n",
       "13           0.857854         0.838601        0.030454                6  \n",
       "14           0.830865         0.806850        0.036125               24  \n",
       "15           0.857291         0.836510        0.033383                9  \n",
       "16           0.863332         0.840218        0.027782                3  \n",
       "17           0.866191         0.841739        0.028896                1  \n",
       "18           0.863210         0.839323        0.028670                5  \n",
       "19           0.868053         0.841163        0.031184                2  \n",
       "20           0.858945         0.837341        0.033707                8  \n",
       "21           0.861475         0.839610        0.033916                4  \n",
       "22           0.859613         0.836457        0.034814               10  \n",
       "23           0.861698         0.838128        0.034128                7  \n",
       "24           0.845092         0.820503        0.030269               17  \n",
       "25           0.856330         0.829116        0.029912               11  \n",
       "26           0.843727         0.819856        0.030324               18  \n",
       "27           0.857053         0.829083        0.031018               12  \n",
       "28           0.837496         0.817818        0.030458               19  \n",
       "29           0.847547         0.825727        0.030005               13  \n",
       "30           0.837916         0.817782        0.030813               20  \n",
       "31           0.848089         0.825181        0.030689               14  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(logReg_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Classifier with optimal hyperparameters had an average macro f1 score of 0.6779819664555472 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'fit_intercept': False, 'penalty': 'elasticnet'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "perceptron = Perceptron(random_state=42)\n",
    "perceptron_params = {'penalty':['l1', 'l2', 'elasticnet'], 'alpha':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "perceptron_tuner = GridSearchCV(perceptron, perceptron_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "perceptron_tuner.fit(X_train, y_train)\n",
    "print('Perceptron Classifier with optimal hyperparameters had an average macro f1 score of '+str(perceptron_tuner.best_score_)+' using the following hyperparameters: '+str(perceptron_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.052801</td>\n",
       "      <td>0.006407</td>\n",
       "      <td>0.002628</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.041580</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000079</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.479613</td>\n",
       "      <td>0.618554</td>\n",
       "      <td>0.663474</td>\n",
       "      <td>0.656330</td>\n",
       "      <td>0.487840</td>\n",
       "      <td>0.581162</td>\n",
       "      <td>0.081049</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074975</td>\n",
       "      <td>0.016713</td>\n",
       "      <td>0.002671</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.596220</td>\n",
       "      <td>0.679336</td>\n",
       "      <td>0.650046</td>\n",
       "      <td>0.526007</td>\n",
       "      <td>0.577223</td>\n",
       "      <td>0.605766</td>\n",
       "      <td>0.054112</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.073247</td>\n",
       "      <td>0.014540</td>\n",
       "      <td>0.002747</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.513540</td>\n",
       "      <td>0.527423</td>\n",
       "      <td>0.653020</td>\n",
       "      <td>0.584163</td>\n",
       "      <td>0.463311</td>\n",
       "      <td>0.548292</td>\n",
       "      <td>0.064992</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.034382</td>\n",
       "      <td>0.002840</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.000224</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.523768</td>\n",
       "      <td>0.548116</td>\n",
       "      <td>0.505975</td>\n",
       "      <td>0.457923</td>\n",
       "      <td>0.676792</td>\n",
       "      <td>0.542515</td>\n",
       "      <td>0.073354</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059259</td>\n",
       "      <td>0.005683</td>\n",
       "      <td>0.003077</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.694465</td>\n",
       "      <td>0.623058</td>\n",
       "      <td>0.708092</td>\n",
       "      <td>0.724168</td>\n",
       "      <td>0.560393</td>\n",
       "      <td>0.662035</td>\n",
       "      <td>0.061455</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.049575</td>\n",
       "      <td>0.004030</td>\n",
       "      <td>0.002451</td>\n",
       "      <td>0.000174</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.041684</td>\n",
       "      <td>0.005312</td>\n",
       "      <td>0.002693</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.686762</td>\n",
       "      <td>0.546630</td>\n",
       "      <td>0.367407</td>\n",
       "      <td>0.332931</td>\n",
       "      <td>0.640176</td>\n",
       "      <td>0.514781</td>\n",
       "      <td>0.142200</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.071435</td>\n",
       "      <td>0.010762</td>\n",
       "      <td>0.002881</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.711351</td>\n",
       "      <td>0.600861</td>\n",
       "      <td>0.577590</td>\n",
       "      <td>0.628688</td>\n",
       "      <td>0.611608</td>\n",
       "      <td>0.626020</td>\n",
       "      <td>0.045770</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.063822</td>\n",
       "      <td>0.010798</td>\n",
       "      <td>0.002776</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.675150</td>\n",
       "      <td>0.520487</td>\n",
       "      <td>0.500688</td>\n",
       "      <td>0.559163</td>\n",
       "      <td>0.600098</td>\n",
       "      <td>0.571117</td>\n",
       "      <td>0.062176</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.039806</td>\n",
       "      <td>0.004031</td>\n",
       "      <td>0.002736</td>\n",
       "      <td>0.000294</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.690616</td>\n",
       "      <td>0.665504</td>\n",
       "      <td>0.337675</td>\n",
       "      <td>0.658928</td>\n",
       "      <td>0.468625</td>\n",
       "      <td>0.564270</td>\n",
       "      <td>0.138322</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.066708</td>\n",
       "      <td>0.013127</td>\n",
       "      <td>0.002831</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.677216</td>\n",
       "      <td>0.629543</td>\n",
       "      <td>0.691975</td>\n",
       "      <td>0.732942</td>\n",
       "      <td>0.658234</td>\n",
       "      <td>0.677982</td>\n",
       "      <td>0.034506</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.050472</td>\n",
       "      <td>0.003046</td>\n",
       "      <td>0.002584</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.359020</td>\n",
       "      <td>0.038993</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.042545</td>\n",
       "      <td>0.007663</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.383912</td>\n",
       "      <td>0.487612</td>\n",
       "      <td>0.396185</td>\n",
       "      <td>0.388155</td>\n",
       "      <td>0.449168</td>\n",
       "      <td>0.421006</td>\n",
       "      <td>0.040745</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.049808</td>\n",
       "      <td>0.004652</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.457598</td>\n",
       "      <td>0.500688</td>\n",
       "      <td>0.459592</td>\n",
       "      <td>0.534050</td>\n",
       "      <td>0.466093</td>\n",
       "      <td>0.052144</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.051523</td>\n",
       "      <td>0.003707</td>\n",
       "      <td>0.002349</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.046212</td>\n",
       "      <td>0.010103</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.388855</td>\n",
       "      <td>0.504274</td>\n",
       "      <td>0.405408</td>\n",
       "      <td>0.405380</td>\n",
       "      <td>0.450251</td>\n",
       "      <td>0.430833</td>\n",
       "      <td>0.042017</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.055760</td>\n",
       "      <td>0.006823</td>\n",
       "      <td>0.002580</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.513540</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.584558</td>\n",
       "      <td>0.519764</td>\n",
       "      <td>0.382737</td>\n",
       "      <td>0.475828</td>\n",
       "      <td>0.081616</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.049072</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.002884</td>\n",
       "      <td>0.000450</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.041768</td>\n",
       "      <td>0.007909</td>\n",
       "      <td>0.002526</td>\n",
       "      <td>0.000121</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.326202</td>\n",
       "      <td>0.320880</td>\n",
       "      <td>0.430507</td>\n",
       "      <td>0.402454</td>\n",
       "      <td>0.451436</td>\n",
       "      <td>0.386296</td>\n",
       "      <td>0.053571</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.052760</td>\n",
       "      <td>0.004379</td>\n",
       "      <td>0.002788</td>\n",
       "      <td>0.000367</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.050610</td>\n",
       "      <td>0.001126</td>\n",
       "      <td>0.002710</td>\n",
       "      <td>0.000329</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.046179</td>\n",
       "      <td>0.011433</td>\n",
       "      <td>0.002682</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.359269</td>\n",
       "      <td>0.477070</td>\n",
       "      <td>0.320235</td>\n",
       "      <td>0.402905</td>\n",
       "      <td>0.452275</td>\n",
       "      <td>0.402351</td>\n",
       "      <td>0.057749</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.062786</td>\n",
       "      <td>0.005796</td>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.479355</td>\n",
       "      <td>0.457598</td>\n",
       "      <td>0.480408</td>\n",
       "      <td>0.459592</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.451093</td>\n",
       "      <td>0.037524</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.046359</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.002435</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.068625</td>\n",
       "      <td>0.020390</td>\n",
       "      <td>0.002528</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.302660</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.329588</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.048104</td>\n",
       "      <td>0.001994</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.051249</td>\n",
       "      <td>0.003797</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.000274</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.069667</td>\n",
       "      <td>0.016523</td>\n",
       "      <td>0.002824</td>\n",
       "      <td>0.000507</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.364265</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.053777</td>\n",
       "      <td>0.003435</td>\n",
       "      <td>0.002458</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.047730</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.002766</td>\n",
       "      <td>0.000435</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.085259</td>\n",
       "      <td>0.016561</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.000083</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.320030</td>\n",
       "      <td>0.047746</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.049245</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.053691</td>\n",
       "      <td>0.003384</td>\n",
       "      <td>0.002649</td>\n",
       "      <td>0.000257</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.069241</td>\n",
       "      <td>0.015038</td>\n",
       "      <td>0.002369</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.364265</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.056571</td>\n",
       "      <td>0.002751</td>\n",
       "      <td>0.002542</td>\n",
       "      <td>0.000157</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.045782</td>\n",
       "      <td>0.002853</td>\n",
       "      <td>0.002569</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.069511</td>\n",
       "      <td>0.015670</td>\n",
       "      <td>0.002534</td>\n",
       "      <td>0.000150</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.302660</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.329588</td>\n",
       "      <td>0.040901</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.071549</td>\n",
       "      <td>0.005441</td>\n",
       "      <td>0.002469</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.047601</td>\n",
       "      <td>0.002814</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000233</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.070200</td>\n",
       "      <td>0.013727</td>\n",
       "      <td>0.002390</td>\n",
       "      <td>0.000163</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.364265</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.073919</td>\n",
       "      <td>0.004958</td>\n",
       "      <td>0.002611</td>\n",
       "      <td>0.000411</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.046801</td>\n",
       "      <td>0.002973</td>\n",
       "      <td>0.002437</td>\n",
       "      <td>0.000141</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.085683</td>\n",
       "      <td>0.011868</td>\n",
       "      <td>0.002632</td>\n",
       "      <td>0.000168</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.320030</td>\n",
       "      <td>0.047746</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.069405</td>\n",
       "      <td>0.004228</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.300548</td>\n",
       "      <td>0.038983</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.052159</td>\n",
       "      <td>0.004599</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000254</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.069967</td>\n",
       "      <td>0.014521</td>\n",
       "      <td>0.002505</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.307260</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.364265</td>\n",
       "      <td>0.028503</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.078005</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>0.002572</td>\n",
       "      <td>0.000305</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.052801      0.006407         0.002628        0.000212        0.01   \n",
       "1        0.041580      0.007272         0.002863        0.000079        0.01   \n",
       "2        0.074975      0.016713         0.002671        0.000276        0.01   \n",
       "3        0.073247      0.014540         0.002747        0.000346        0.01   \n",
       "4        0.034382      0.002840         0.002763        0.000224        0.01   \n",
       "5        0.059259      0.005683         0.003077        0.000410        0.01   \n",
       "6        0.049575      0.004030         0.002451        0.000174        0.01   \n",
       "7        0.041684      0.005312         0.002693        0.000158        0.01   \n",
       "8        0.071435      0.010762         0.002881        0.000451        0.01   \n",
       "9        0.063822      0.010798         0.002776        0.000572        0.01   \n",
       "10       0.039806      0.004031         0.002736        0.000294        0.01   \n",
       "11       0.066708      0.013127         0.002831        0.000392        0.01   \n",
       "12       0.050472      0.003046         0.002584        0.000084         0.1   \n",
       "13       0.042545      0.007663         0.002478        0.000136         0.1   \n",
       "14       0.049808      0.004652         0.002576        0.000149         0.1   \n",
       "15       0.051523      0.003707         0.002349        0.000111         0.1   \n",
       "16       0.046212      0.010103         0.002710        0.000435         0.1   \n",
       "17       0.055760      0.006823         0.002580        0.000253         0.1   \n",
       "18       0.049072      0.003494         0.002884        0.000450         0.1   \n",
       "19       0.041768      0.007909         0.002526        0.000121         0.1   \n",
       "20       0.052760      0.004379         0.002788        0.000367         0.1   \n",
       "21       0.050610      0.001126         0.002710        0.000329         0.1   \n",
       "22       0.046179      0.011433         0.002682        0.000311         0.1   \n",
       "23       0.062786      0.005796         0.002576        0.000160         0.1   \n",
       "24       0.046359      0.002258         0.002435        0.000179           1   \n",
       "25       0.068625      0.020390         0.002528        0.000265           1   \n",
       "26       0.048104      0.001994         0.002437        0.000125           1   \n",
       "27       0.051249      0.003797         0.002585        0.000274           1   \n",
       "28       0.069667      0.016523         0.002824        0.000507           1   \n",
       "29       0.053777      0.003435         0.002458        0.000116           1   \n",
       "30       0.047730      0.003846         0.002766        0.000435           1   \n",
       "31       0.085259      0.016561         0.002613        0.000083           1   \n",
       "32       0.049245      0.002357         0.002511        0.000254           1   \n",
       "33       0.053691      0.003384         0.002649        0.000257           1   \n",
       "34       0.069241      0.015038         0.002369        0.000126           1   \n",
       "35       0.056571      0.002751         0.002542        0.000157           1   \n",
       "36       0.045782      0.002853         0.002569        0.000273          10   \n",
       "37       0.069511      0.015670         0.002534        0.000150          10   \n",
       "38       0.071549      0.005441         0.002469        0.000185          10   \n",
       "39       0.047601      0.002814         0.002415        0.000233          10   \n",
       "40       0.070200      0.013727         0.002390        0.000163          10   \n",
       "41       0.073919      0.004958         0.002611        0.000411          10   \n",
       "42       0.046801      0.002973         0.002437        0.000141          10   \n",
       "43       0.085683      0.011868         0.002632        0.000168          10   \n",
       "44       0.069405      0.004228         0.002553        0.000379          10   \n",
       "45       0.052159      0.004599         0.002515        0.000254          10   \n",
       "46       0.069967      0.014521         0.002505        0.000125          10   \n",
       "47       0.078005      0.005892         0.002572        0.000305          10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None                True    elasticnet   \n",
       "3                None               False            l1   \n",
       "4                None               False            l2   \n",
       "5                None               False    elasticnet   \n",
       "6            balanced                True            l1   \n",
       "7            balanced                True            l2   \n",
       "8            balanced                True    elasticnet   \n",
       "9            balanced               False            l1   \n",
       "10           balanced               False            l2   \n",
       "11           balanced               False    elasticnet   \n",
       "12               None                True            l1   \n",
       "13               None                True            l2   \n",
       "14               None                True    elasticnet   \n",
       "15               None               False            l1   \n",
       "16               None               False            l2   \n",
       "17               None               False    elasticnet   \n",
       "18           balanced                True            l1   \n",
       "19           balanced                True            l2   \n",
       "20           balanced                True    elasticnet   \n",
       "21           balanced               False            l1   \n",
       "22           balanced               False            l2   \n",
       "23           balanced               False    elasticnet   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None                True    elasticnet   \n",
       "27               None               False            l1   \n",
       "28               None               False            l2   \n",
       "29               None               False    elasticnet   \n",
       "30           balanced                True            l1   \n",
       "31           balanced                True            l2   \n",
       "32           balanced                True    elasticnet   \n",
       "33           balanced               False            l1   \n",
       "34           balanced               False            l2   \n",
       "35           balanced               False    elasticnet   \n",
       "36               None                True            l1   \n",
       "37               None                True            l2   \n",
       "38               None                True    elasticnet   \n",
       "39               None               False            l1   \n",
       "40               None               False            l2   \n",
       "41               None               False    elasticnet   \n",
       "42           balanced                True            l1   \n",
       "43           balanced                True            l2   \n",
       "44           balanced                True    elasticnet   \n",
       "45           balanced               False            l1   \n",
       "46           balanced               False            l2   \n",
       "47           balanced               False    elasticnet   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.281034   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.479613   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.596220   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.513540   \n",
       "4   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.523768   \n",
       "5   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.694465   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.281034   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.686762   \n",
       "8   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.711351   \n",
       "9   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.675150   \n",
       "10  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.690616   \n",
       "11  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.677216   \n",
       "12  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.281034   \n",
       "13  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.383912   \n",
       "14  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.378539   \n",
       "15  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.378539   \n",
       "16  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.388855   \n",
       "17  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.513540   \n",
       "18  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.281034   \n",
       "19  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.326202   \n",
       "20  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.281034   \n",
       "21  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.378539   \n",
       "22  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.359269   \n",
       "23  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.479355   \n",
       "24  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.378539   \n",
       "25  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.307260   \n",
       "26  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.378539   \n",
       "27  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.378539   \n",
       "28  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.307260   \n",
       "29  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.378539   \n",
       "30  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.281034   \n",
       "31  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.281034   \n",
       "32  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.281034   \n",
       "33  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.378539   \n",
       "34  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.307260   \n",
       "35  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.378539   \n",
       "36  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.378539   \n",
       "37  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.307260   \n",
       "38  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.378539   \n",
       "39  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.378539   \n",
       "40  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.307260   \n",
       "41  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.378539   \n",
       "42  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.281034   \n",
       "43  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.281034   \n",
       "44  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.281034   \n",
       "45  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.378539   \n",
       "46  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.307260   \n",
       "47  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.378539   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.281034           0.281034           0.281123   \n",
       "1            0.618554           0.663474           0.656330   \n",
       "2            0.679336           0.650046           0.526007   \n",
       "3            0.527423           0.653020           0.584163   \n",
       "4            0.548116           0.505975           0.457923   \n",
       "5            0.623058           0.708092           0.724168   \n",
       "6            0.281034           0.281034           0.281123   \n",
       "7            0.546630           0.367407           0.332931   \n",
       "8            0.600861           0.577590           0.628688   \n",
       "9            0.520487           0.500688           0.559163   \n",
       "10           0.665504           0.337675           0.658928   \n",
       "11           0.629543           0.691975           0.732942   \n",
       "12           0.378539           0.378539           0.378473   \n",
       "13           0.487612           0.396185           0.388155   \n",
       "14           0.457598           0.500688           0.459592   \n",
       "15           0.378539           0.378539           0.378473   \n",
       "16           0.504274           0.405408           0.405380   \n",
       "17           0.378539           0.584558           0.519764   \n",
       "18           0.281034           0.281034           0.281123   \n",
       "19           0.320880           0.430507           0.402454   \n",
       "20           0.281034           0.281034           0.281123   \n",
       "21           0.378539           0.378539           0.378473   \n",
       "22           0.477070           0.320235           0.402905   \n",
       "23           0.457598           0.480408           0.459592   \n",
       "24           0.378539           0.378539           0.378473   \n",
       "25           0.281034           0.302660           0.378473   \n",
       "26           0.378539           0.378539           0.378473   \n",
       "27           0.378539           0.378539           0.378473   \n",
       "28           0.378539           0.378539           0.378473   \n",
       "29           0.378539           0.378539           0.378473   \n",
       "30           0.281034           0.281034           0.281123   \n",
       "31           0.281034           0.378539           0.378473   \n",
       "32           0.281034           0.281034           0.281123   \n",
       "33           0.378539           0.378539           0.378473   \n",
       "34           0.378539           0.378539           0.378473   \n",
       "35           0.378539           0.378539           0.378473   \n",
       "36           0.378539           0.378539           0.378473   \n",
       "37           0.281034           0.302660           0.378473   \n",
       "38           0.378539           0.378539           0.378473   \n",
       "39           0.378539           0.378539           0.378473   \n",
       "40           0.378539           0.378539           0.378473   \n",
       "41           0.378539           0.378539           0.378473   \n",
       "42           0.281034           0.281034           0.281123   \n",
       "43           0.281034           0.378539           0.378473   \n",
       "44           0.281034           0.281034           0.281123   \n",
       "45           0.378539           0.378539           0.378473   \n",
       "46           0.378539           0.378539           0.378473   \n",
       "47           0.378539           0.378539           0.378473   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.378514         0.300548        0.038983               41  \n",
       "1            0.487840         0.581162        0.081049                5  \n",
       "2            0.577223         0.605766        0.054112                4  \n",
       "3            0.463311         0.548292        0.064992                8  \n",
       "4            0.676792         0.542515        0.073354                9  \n",
       "5            0.560393         0.662035        0.061455                2  \n",
       "6            0.378514         0.300548        0.038983               41  \n",
       "7            0.640176         0.514781        0.142200               10  \n",
       "8            0.611608         0.626020        0.045770                3  \n",
       "9            0.600098         0.571117        0.062176                6  \n",
       "10           0.468625         0.564270        0.138322                7  \n",
       "11           0.658234         0.677982        0.034506                1  \n",
       "12           0.378514         0.359020        0.038993               36  \n",
       "13           0.449168         0.421006        0.040745               15  \n",
       "14           0.534050         0.466093        0.052144               12  \n",
       "15           0.378514         0.378521        0.000026               18  \n",
       "16           0.450251         0.430833        0.042017               14  \n",
       "17           0.382737         0.475828        0.081616               11  \n",
       "18           0.378514         0.300548        0.038983               41  \n",
       "19           0.451436         0.386296        0.053571               17  \n",
       "20           0.378514         0.300548        0.038983               41  \n",
       "21           0.378514         0.378521        0.000026               18  \n",
       "22           0.452275         0.402351        0.057749               16  \n",
       "23           0.378514         0.451093        0.037524               13  \n",
       "24           0.378514         0.378521        0.000026               18  \n",
       "25           0.378514         0.329588        0.040901               37  \n",
       "26           0.378514         0.378521        0.000026               18  \n",
       "27           0.378514         0.378521        0.000026               18  \n",
       "28           0.378514         0.364265        0.028503               32  \n",
       "29           0.378514         0.378521        0.000026               18  \n",
       "30           0.378514         0.300548        0.038983               41  \n",
       "31           0.281069         0.320030        0.047746               39  \n",
       "32           0.378514         0.300548        0.038983               41  \n",
       "33           0.378514         0.378521        0.000026               18  \n",
       "34           0.378514         0.364265        0.028503               32  \n",
       "35           0.378514         0.378521        0.000026               18  \n",
       "36           0.378514         0.378521        0.000026               18  \n",
       "37           0.378514         0.329588        0.040901               37  \n",
       "38           0.378514         0.378521        0.000026               18  \n",
       "39           0.378514         0.378521        0.000026               18  \n",
       "40           0.378514         0.364265        0.028503               32  \n",
       "41           0.378514         0.378521        0.000026               18  \n",
       "42           0.378514         0.300548        0.038983               41  \n",
       "43           0.281069         0.320030        0.047746               39  \n",
       "44           0.378514         0.300548        0.038983               41  \n",
       "45           0.378514         0.378521        0.000026               18  \n",
       "46           0.378514         0.364265        0.028503               32  \n",
       "47           0.378514         0.378521        0.000026               18  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(perceptron_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier with optimal hyperparameters had an average macro f1 score of 0.830437932064393 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd_params = {'penalty':['l1', 'l2'], 'alpha':[0.01, 0.1, 1], 'class_weight': [None,'balanced'], 'loss':['hinge', 'modified_huber']}\n",
    "sgd_tuner = GridSearchCV(sgd, sgd_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "sgd_tuner.fit(X_train, y_train)\n",
    "print('SGD Classifier with optimal hyperparameters had an average macro f1 score of '+str(sgd_tuner.best_score_)+' using the following hyperparameters: '+str(sgd_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.092384</td>\n",
       "      <td>0.015685</td>\n",
       "      <td>0.002739</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.632245</td>\n",
       "      <td>0.553436</td>\n",
       "      <td>0.608511</td>\n",
       "      <td>0.610659</td>\n",
       "      <td>0.619080</td>\n",
       "      <td>0.604786</td>\n",
       "      <td>0.026994</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.045627</td>\n",
       "      <td>0.002084</td>\n",
       "      <td>0.002695</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.643954</td>\n",
       "      <td>0.556944</td>\n",
       "      <td>0.624272</td>\n",
       "      <td>0.629942</td>\n",
       "      <td>0.634391</td>\n",
       "      <td>0.617901</td>\n",
       "      <td>0.031151</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.067646</td>\n",
       "      <td>0.005377</td>\n",
       "      <td>0.003033</td>\n",
       "      <td>0.000325</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.691495</td>\n",
       "      <td>0.609414</td>\n",
       "      <td>0.681806</td>\n",
       "      <td>0.685452</td>\n",
       "      <td>0.689103</td>\n",
       "      <td>0.671454</td>\n",
       "      <td>0.031194</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054012</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.002722</td>\n",
       "      <td>0.000346</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.771420</td>\n",
       "      <td>0.707480</td>\n",
       "      <td>0.802125</td>\n",
       "      <td>0.818488</td>\n",
       "      <td>0.800516</td>\n",
       "      <td>0.780006</td>\n",
       "      <td>0.039305</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.093222</td>\n",
       "      <td>0.009428</td>\n",
       "      <td>0.002688</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.675418</td>\n",
       "      <td>0.593876</td>\n",
       "      <td>0.670467</td>\n",
       "      <td>0.662969</td>\n",
       "      <td>0.689929</td>\n",
       "      <td>0.658532</td>\n",
       "      <td>0.033507</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.065449</td>\n",
       "      <td>0.012728</td>\n",
       "      <td>0.002681</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.740441</td>\n",
       "      <td>0.657882</td>\n",
       "      <td>0.755341</td>\n",
       "      <td>0.769652</td>\n",
       "      <td>0.752796</td>\n",
       "      <td>0.735222</td>\n",
       "      <td>0.039769</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.077657</td>\n",
       "      <td>0.009763</td>\n",
       "      <td>0.003022</td>\n",
       "      <td>0.000490</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.741436</td>\n",
       "      <td>0.675705</td>\n",
       "      <td>0.725794</td>\n",
       "      <td>0.680793</td>\n",
       "      <td>0.728468</td>\n",
       "      <td>0.710439</td>\n",
       "      <td>0.026859</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.061355</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.002557</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.830805</td>\n",
       "      <td>0.770102</td>\n",
       "      <td>0.855544</td>\n",
       "      <td>0.840245</td>\n",
       "      <td>0.855493</td>\n",
       "      <td>0.830438</td>\n",
       "      <td>0.031606</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.059757</td>\n",
       "      <td>0.005049</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.000241</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.038045</td>\n",
       "      <td>0.003180</td>\n",
       "      <td>0.002793</td>\n",
       "      <td>0.000670</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.385675</td>\n",
       "      <td>0.389846</td>\n",
       "      <td>0.389447</td>\n",
       "      <td>0.387965</td>\n",
       "      <td>0.389891</td>\n",
       "      <td>0.388565</td>\n",
       "      <td>0.001605</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.070235</td>\n",
       "      <td>0.007466</td>\n",
       "      <td>0.003552</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.052312</td>\n",
       "      <td>0.003696</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.000175</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.638778</td>\n",
       "      <td>0.557597</td>\n",
       "      <td>0.626601</td>\n",
       "      <td>0.627179</td>\n",
       "      <td>0.624956</td>\n",
       "      <td>0.615022</td>\n",
       "      <td>0.029129</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.049282</td>\n",
       "      <td>0.002062</td>\n",
       "      <td>0.002429</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.320030</td>\n",
       "      <td>0.047746</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.050045</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.487467</td>\n",
       "      <td>0.618060</td>\n",
       "      <td>0.429996</td>\n",
       "      <td>0.406829</td>\n",
       "      <td>0.453181</td>\n",
       "      <td>0.479106</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.058200</td>\n",
       "      <td>0.005337</td>\n",
       "      <td>0.002731</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.513654</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.347053</td>\n",
       "      <td>0.091448</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.059655</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.787531</td>\n",
       "      <td>0.712896</td>\n",
       "      <td>0.821832</td>\n",
       "      <td>0.813928</td>\n",
       "      <td>0.825057</td>\n",
       "      <td>0.792249</td>\n",
       "      <td>0.041811</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.049925</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.002498</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.046492</td>\n",
       "      <td>0.003226</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000540</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.382831</td>\n",
       "      <td>0.386148</td>\n",
       "      <td>0.387564</td>\n",
       "      <td>0.386551</td>\n",
       "      <td>0.389891</td>\n",
       "      <td>0.386597</td>\n",
       "      <td>0.002288</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.061900</td>\n",
       "      <td>0.002518</td>\n",
       "      <td>0.002843</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378539</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.378514</td>\n",
       "      <td>0.378521</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.038595</td>\n",
       "      <td>0.002122</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.385675</td>\n",
       "      <td>0.390315</td>\n",
       "      <td>0.390784</td>\n",
       "      <td>0.387965</td>\n",
       "      <td>0.392702</td>\n",
       "      <td>0.389488</td>\n",
       "      <td>0.002431</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.054158</td>\n",
       "      <td>0.003602</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000136</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281123</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.281059</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.040936</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.002544</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.484418</td>\n",
       "      <td>0.631886</td>\n",
       "      <td>0.423027</td>\n",
       "      <td>0.407280</td>\n",
       "      <td>0.283277</td>\n",
       "      <td>0.445978</td>\n",
       "      <td>0.113609</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.053281</td>\n",
       "      <td>0.004983</td>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.000313</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.281034</td>\n",
       "      <td>0.378473</td>\n",
       "      <td>0.281069</td>\n",
       "      <td>0.300529</td>\n",
       "      <td>0.038972</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.040904</td>\n",
       "      <td>0.002721</td>\n",
       "      <td>0.002566</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.776290</td>\n",
       "      <td>0.714834</td>\n",
       "      <td>0.664940</td>\n",
       "      <td>0.739287</td>\n",
       "      <td>0.547848</td>\n",
       "      <td>0.688640</td>\n",
       "      <td>0.079143</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.092384      0.015685         0.002739        0.000387        0.01   \n",
       "1        0.045627      0.002084         0.002695        0.000101        0.01   \n",
       "2        0.067646      0.005377         0.003033        0.000325        0.01   \n",
       "3        0.054012      0.002713         0.002722        0.000346        0.01   \n",
       "4        0.093222      0.009428         0.002688        0.000158        0.01   \n",
       "5        0.065449      0.012728         0.002681        0.000201        0.01   \n",
       "6        0.077657      0.009763         0.003022        0.000490        0.01   \n",
       "7        0.061355      0.008565         0.002557        0.000228        0.01   \n",
       "8        0.059757      0.005049         0.002500        0.000241         0.1   \n",
       "9        0.038045      0.003180         0.002793        0.000670         0.1   \n",
       "10       0.070235      0.007466         0.003552        0.000319         0.1   \n",
       "11       0.052312      0.003696         0.002828        0.000175         0.1   \n",
       "12       0.049282      0.002062         0.002429        0.000145         0.1   \n",
       "13       0.050045      0.003069         0.002863        0.000201         0.1   \n",
       "14       0.058200      0.005337         0.002731        0.000385         0.1   \n",
       "15       0.059655      0.002446         0.002839        0.000458         0.1   \n",
       "16       0.049925      0.003679         0.002498        0.000244           1   \n",
       "17       0.046492      0.003226         0.002830        0.000540           1   \n",
       "18       0.061900      0.002518         0.002843        0.000244           1   \n",
       "19       0.038595      0.002122         0.002413        0.000179           1   \n",
       "20       0.054158      0.003602         0.002594        0.000136           1   \n",
       "21       0.040936      0.002342         0.002544        0.000181           1   \n",
       "22       0.053281      0.004983         0.002673        0.000313           1   \n",
       "23       0.040904      0.002721         0.002566        0.000088           1   \n",
       "\n",
       "   param_class_weight      param_loss param_penalty  \\\n",
       "0                None           hinge            l1   \n",
       "1                None           hinge            l2   \n",
       "2                None  modified_huber            l1   \n",
       "3                None  modified_huber            l2   \n",
       "4            balanced           hinge            l1   \n",
       "5            balanced           hinge            l2   \n",
       "6            balanced  modified_huber            l1   \n",
       "7            balanced  modified_huber            l2   \n",
       "8                None           hinge            l1   \n",
       "9                None           hinge            l2   \n",
       "10               None  modified_huber            l1   \n",
       "11               None  modified_huber            l2   \n",
       "12           balanced           hinge            l1   \n",
       "13           balanced           hinge            l2   \n",
       "14           balanced  modified_huber            l1   \n",
       "15           balanced  modified_huber            l2   \n",
       "16               None           hinge            l1   \n",
       "17               None           hinge            l2   \n",
       "18               None  modified_huber            l1   \n",
       "19               None  modified_huber            l2   \n",
       "20           balanced           hinge            l1   \n",
       "21           balanced           hinge            l2   \n",
       "22           balanced  modified_huber            l1   \n",
       "23           balanced  modified_huber            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.632245   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.643954   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.691495   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.771420   \n",
       "4   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.675418   \n",
       "5   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.740441   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.741436   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.830805   \n",
       "8   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.378539   \n",
       "9   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.385675   \n",
       "10  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.378539   \n",
       "11  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.638778   \n",
       "12  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.378539   \n",
       "13  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.487467   \n",
       "14  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.513654   \n",
       "15  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.787531   \n",
       "16  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.378539   \n",
       "17  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.382831   \n",
       "18  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.378539   \n",
       "19  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.385675   \n",
       "20  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.281034   \n",
       "21  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.484418   \n",
       "22  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.281034   \n",
       "23  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.776290   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.553436           0.608511           0.610659   \n",
       "1            0.556944           0.624272           0.629942   \n",
       "2            0.609414           0.681806           0.685452   \n",
       "3            0.707480           0.802125           0.818488   \n",
       "4            0.593876           0.670467           0.662969   \n",
       "5            0.657882           0.755341           0.769652   \n",
       "6            0.675705           0.725794           0.680793   \n",
       "7            0.770102           0.855544           0.840245   \n",
       "8            0.378539           0.378539           0.378473   \n",
       "9            0.389846           0.389447           0.387965   \n",
       "10           0.378539           0.378539           0.378473   \n",
       "11           0.557597           0.626601           0.627179   \n",
       "12           0.281034           0.281034           0.378473   \n",
       "13           0.618060           0.429996           0.406829   \n",
       "14           0.281034           0.281034           0.378473   \n",
       "15           0.712896           0.821832           0.813928   \n",
       "16           0.378539           0.378539           0.378473   \n",
       "17           0.386148           0.387564           0.386551   \n",
       "18           0.378539           0.378539           0.378473   \n",
       "19           0.390315           0.390784           0.387965   \n",
       "20           0.281034           0.281034           0.281123   \n",
       "21           0.631886           0.423027           0.407280   \n",
       "22           0.281034           0.281034           0.378473   \n",
       "23           0.714834           0.664940           0.739287   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.619080         0.604786        0.026994               11  \n",
       "1            0.634391         0.617901        0.031151                9  \n",
       "2            0.689103         0.671454        0.031194                7  \n",
       "3            0.800516         0.780006        0.039305                3  \n",
       "4            0.689929         0.658532        0.033507                8  \n",
       "5            0.752796         0.735222        0.039769                4  \n",
       "6            0.728468         0.710439        0.026859                5  \n",
       "7            0.855493         0.830438        0.031606                1  \n",
       "8            0.378514         0.378521        0.000026               17  \n",
       "9            0.389891         0.388565        0.001605               15  \n",
       "10           0.378514         0.378521        0.000026               17  \n",
       "11           0.624956         0.615022        0.029129               10  \n",
       "12           0.281069         0.320030        0.047746               22  \n",
       "13           0.453181         0.479106        0.074412               12  \n",
       "14           0.281069         0.347053        0.091448               21  \n",
       "15           0.825057         0.792249        0.041811                2  \n",
       "16           0.378514         0.378521        0.000026               17  \n",
       "17           0.389891         0.386597        0.002288               16  \n",
       "18           0.378514         0.378521        0.000026               17  \n",
       "19           0.392702         0.389488        0.002431               14  \n",
       "20           0.281069         0.281059        0.000035               24  \n",
       "21           0.283277         0.445978        0.113609               13  \n",
       "22           0.281069         0.300529        0.038972               23  \n",
       "23           0.547848         0.688640        0.079143                6  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(sgd_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV Metrics: Cutoff 3\n",
      "\n",
      "Tuned Logistic Regression Model:\n",
      "Accuracy Average: 0.7843394987135675\n",
      "Precision Average: 0.7789214178227241\n",
      "F1 Score Average: 0.7507601271350177\n",
      "ROC AUC Score Average: 0.7491883051532648\n",
      "Confusion Matrix Average:\n",
      "[3171.2  384.4]\n",
      "[ 874.6 1407.6]\n",
      "\n",
      "\n",
      "Tuned Perceptron Model:\n",
      "Accuracy Average: 0.6956741036598754\n",
      "Precision Average: 0.6926011697787191\n",
      "F1 Score Average: 0.6633149455227205\n",
      "ROC AUC Score Average: 0.6696649104989973\n",
      "Confusion Matrix Average:\n",
      "[2896.2  659.4]\n",
      "[1117.2 1165. ]\n",
      "\n",
      "\n",
      "Tuned SGD Classifier:\n",
      "Accuracy Average: 0.7834146065755878\n",
      "Precision Average: 0.7708093956382838\n",
      "F1 Score Average: 0.7542861838666738\n",
      "ROC AUC Score Average: 0.7532737712719495\n",
      "Confusion Matrix Average:\n",
      "[3087.4  468.2]\n",
      "[ 796.2 1486. ]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print average k-fold CV metrics for optimally tuned models\n",
    "cutoff = 3\n",
    "\n",
    "print(f\"5-Fold CV Metrics: Cutoff {cutoff}\\n\")\n",
    "\n",
    "print(\"Tuned Logistic Regression Model:\")\n",
    "logReg.set_params(**logReg_tuner.best_params_)\n",
    "predictions = cv_metrics(logReg, 2)\n",
    "\n",
    "print(\"Tuned Perceptron Model:\")\n",
    "perceptron.set_params(**perceptron_tuner.best_params_)\n",
    "predictions = cv_metrics(perceptron, 2)\n",
    "\n",
    "print(\"Tuned SGD Classifier:\")\n",
    "sgd.set_params(**sgd_tuner.best_params_)\n",
    "predictions = cv_metrics(sgd, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Testing\n",
    "The tuned SGD Regression seems to have the best average scores (slightly better than the tuned Logistic Regression), I will use this model to predict the test labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save test predictions\n",
    "y_test_hat_3 = sgd.predict(X_test)\n",
    "out_results(y_test_hat_3, \"binary\", 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a macro f1 score of 0.86970 on the test set on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "## set binary cutoff to 4\n",
    "y_train = construct_labels(df_train, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: Logisitic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logisitic Regression with optimal hyperparameters had an average macro f1 score of 0.8116139799234577 using the following hyperparameters: {'C': 0.1, 'class_weight': 'balanced', 'fit_intercept': True, 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "logReg = LogisticRegression(max_iter=200, solver='liblinear', random_state=42)\n",
    "logReg_params = {'penalty':['l1', 'l2'], 'C':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "logReg_tuner = GridSearchCV(logReg, logReg_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "logReg_tuner.fit(X_train, y_train)\n",
    "print('Logisitic Regression with optimal hyperparameters had an average macro f1 score of '+str(logReg_tuner.best_score_)+' using the following hyperparameters: '+str(logReg_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.069818</td>\n",
       "      <td>0.006295</td>\n",
       "      <td>0.003921</td>\n",
       "      <td>0.000327</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.691393</td>\n",
       "      <td>0.620713</td>\n",
       "      <td>0.659239</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.683607</td>\n",
       "      <td>0.663852</td>\n",
       "      <td>0.024622</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.078660</td>\n",
       "      <td>0.006576</td>\n",
       "      <td>0.002795</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.692737</td>\n",
       "      <td>0.623044</td>\n",
       "      <td>0.660652</td>\n",
       "      <td>0.666703</td>\n",
       "      <td>0.684559</td>\n",
       "      <td>0.665539</td>\n",
       "      <td>0.024218</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.062631</td>\n",
       "      <td>0.004946</td>\n",
       "      <td>0.003359</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.691542</td>\n",
       "      <td>0.622935</td>\n",
       "      <td>0.662098</td>\n",
       "      <td>0.665514</td>\n",
       "      <td>0.687291</td>\n",
       "      <td>0.665876</td>\n",
       "      <td>0.024395</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.071163</td>\n",
       "      <td>0.006025</td>\n",
       "      <td>0.002876</td>\n",
       "      <td>0.000416</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': None, 'fit_interce...</td>\n",
       "      <td>0.696126</td>\n",
       "      <td>0.629097</td>\n",
       "      <td>0.667299</td>\n",
       "      <td>0.672810</td>\n",
       "      <td>0.687861</td>\n",
       "      <td>0.670639</td>\n",
       "      <td>0.023185</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.084816</td>\n",
       "      <td>0.010311</td>\n",
       "      <td>0.004229</td>\n",
       "      <td>0.000655</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.748664</td>\n",
       "      <td>0.698730</td>\n",
       "      <td>0.735857</td>\n",
       "      <td>0.738759</td>\n",
       "      <td>0.735142</td>\n",
       "      <td>0.731431</td>\n",
       "      <td>0.017049</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.083945</td>\n",
       "      <td>0.006975</td>\n",
       "      <td>0.003051</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.812321</td>\n",
       "      <td>0.766388</td>\n",
       "      <td>0.824713</td>\n",
       "      <td>0.815763</td>\n",
       "      <td>0.801353</td>\n",
       "      <td>0.804107</td>\n",
       "      <td>0.020289</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.071071</td>\n",
       "      <td>0.005864</td>\n",
       "      <td>0.003412</td>\n",
       "      <td>0.000195</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.748937</td>\n",
       "      <td>0.703665</td>\n",
       "      <td>0.739318</td>\n",
       "      <td>0.751133</td>\n",
       "      <td>0.738710</td>\n",
       "      <td>0.736353</td>\n",
       "      <td>0.017086</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.079819</td>\n",
       "      <td>0.004423</td>\n",
       "      <td>0.002986</td>\n",
       "      <td>0.000341</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.01, 'class_weight': 'balanced', 'fit_i...</td>\n",
       "      <td>0.809736</td>\n",
       "      <td>0.770791</td>\n",
       "      <td>0.822562</td>\n",
       "      <td>0.815472</td>\n",
       "      <td>0.802890</td>\n",
       "      <td>0.804290</td>\n",
       "      <td>0.017959</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.116096</td>\n",
       "      <td>0.009270</td>\n",
       "      <td>0.003723</td>\n",
       "      <td>0.000378</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.763612</td>\n",
       "      <td>0.705108</td>\n",
       "      <td>0.756808</td>\n",
       "      <td>0.761819</td>\n",
       "      <td>0.761149</td>\n",
       "      <td>0.749699</td>\n",
       "      <td>0.022407</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.123630</td>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.002833</td>\n",
       "      <td>0.000191</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.756854</td>\n",
       "      <td>0.702146</td>\n",
       "      <td>0.753882</td>\n",
       "      <td>0.752932</td>\n",
       "      <td>0.760699</td>\n",
       "      <td>0.745303</td>\n",
       "      <td>0.021747</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.086468</td>\n",
       "      <td>0.014755</td>\n",
       "      <td>0.003761</td>\n",
       "      <td>0.000280</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.764769</td>\n",
       "      <td>0.723460</td>\n",
       "      <td>0.760882</td>\n",
       "      <td>0.767865</td>\n",
       "      <td>0.769316</td>\n",
       "      <td>0.757258</td>\n",
       "      <td>0.017145</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.100373</td>\n",
       "      <td>0.009581</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': None, 'fit_intercep...</td>\n",
       "      <td>0.768469</td>\n",
       "      <td>0.718532</td>\n",
       "      <td>0.763156</td>\n",
       "      <td>0.765655</td>\n",
       "      <td>0.781030</td>\n",
       "      <td>0.759368</td>\n",
       "      <td>0.021324</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.145386</td>\n",
       "      <td>0.006570</td>\n",
       "      <td>0.003972</td>\n",
       "      <td>0.000567</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.793361</td>\n",
       "      <td>0.760916</td>\n",
       "      <td>0.803201</td>\n",
       "      <td>0.788688</td>\n",
       "      <td>0.778779</td>\n",
       "      <td>0.784989</td>\n",
       "      <td>0.014377</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.134309</td>\n",
       "      <td>0.012461</td>\n",
       "      <td>0.003206</td>\n",
       "      <td>0.000270</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.827926</td>\n",
       "      <td>0.776731</td>\n",
       "      <td>0.840339</td>\n",
       "      <td>0.818208</td>\n",
       "      <td>0.794867</td>\n",
       "      <td>0.811614</td>\n",
       "      <td>0.022943</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.092019</td>\n",
       "      <td>0.010144</td>\n",
       "      <td>0.003871</td>\n",
       "      <td>0.000707</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.783262</td>\n",
       "      <td>0.752696</td>\n",
       "      <td>0.796161</td>\n",
       "      <td>0.780419</td>\n",
       "      <td>0.771375</td>\n",
       "      <td>0.776782</td>\n",
       "      <td>0.014423</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.125083</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>0.003008</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 0.1, 'class_weight': 'balanced', 'fit_in...</td>\n",
       "      <td>0.824327</td>\n",
       "      <td>0.773963</td>\n",
       "      <td>0.836736</td>\n",
       "      <td>0.816941</td>\n",
       "      <td>0.791058</td>\n",
       "      <td>0.808605</td>\n",
       "      <td>0.022874</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.323977</td>\n",
       "      <td>0.016622</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.812132</td>\n",
       "      <td>0.774001</td>\n",
       "      <td>0.820466</td>\n",
       "      <td>0.806209</td>\n",
       "      <td>0.827049</td>\n",
       "      <td>0.807971</td>\n",
       "      <td>0.018409</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.178206</td>\n",
       "      <td>0.015851</td>\n",
       "      <td>0.003107</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.808427</td>\n",
       "      <td>0.776501</td>\n",
       "      <td>0.816973</td>\n",
       "      <td>0.798651</td>\n",
       "      <td>0.821405</td>\n",
       "      <td>0.804391</td>\n",
       "      <td>0.015968</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.111624</td>\n",
       "      <td>0.004162</td>\n",
       "      <td>0.003405</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.812289</td>\n",
       "      <td>0.784269</td>\n",
       "      <td>0.819132</td>\n",
       "      <td>0.810213</td>\n",
       "      <td>0.823133</td>\n",
       "      <td>0.809807</td>\n",
       "      <td>0.013587</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.162661</td>\n",
       "      <td>0.014436</td>\n",
       "      <td>0.003020</td>\n",
       "      <td>0.000218</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': None, 'fit_intercept'...</td>\n",
       "      <td>0.809167</td>\n",
       "      <td>0.779428</td>\n",
       "      <td>0.813793</td>\n",
       "      <td>0.807028</td>\n",
       "      <td>0.817902</td>\n",
       "      <td>0.805464</td>\n",
       "      <td>0.013551</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.436908</td>\n",
       "      <td>0.016627</td>\n",
       "      <td>0.003908</td>\n",
       "      <td>0.000516</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.823961</td>\n",
       "      <td>0.758214</td>\n",
       "      <td>0.824046</td>\n",
       "      <td>0.813712</td>\n",
       "      <td>0.783656</td>\n",
       "      <td>0.800718</td>\n",
       "      <td>0.025888</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.226536</td>\n",
       "      <td>0.024896</td>\n",
       "      <td>0.002819</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.829339</td>\n",
       "      <td>0.763507</td>\n",
       "      <td>0.828179</td>\n",
       "      <td>0.812750</td>\n",
       "      <td>0.786466</td>\n",
       "      <td>0.804048</td>\n",
       "      <td>0.025496</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.130704</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.003355</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.821876</td>\n",
       "      <td>0.751027</td>\n",
       "      <td>0.820562</td>\n",
       "      <td>0.806642</td>\n",
       "      <td>0.781182</td>\n",
       "      <td>0.796258</td>\n",
       "      <td>0.026937</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.198420</td>\n",
       "      <td>0.010248</td>\n",
       "      <td>0.003119</td>\n",
       "      <td>0.000379</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 1, 'class_weight': 'balanced', 'fit_inte...</td>\n",
       "      <td>0.824193</td>\n",
       "      <td>0.757097</td>\n",
       "      <td>0.825337</td>\n",
       "      <td>0.809957</td>\n",
       "      <td>0.780466</td>\n",
       "      <td>0.799410</td>\n",
       "      <td>0.026634</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.689387</td>\n",
       "      <td>0.005129</td>\n",
       "      <td>0.003652</td>\n",
       "      <td>0.000264</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.805129</td>\n",
       "      <td>0.742384</td>\n",
       "      <td>0.799351</td>\n",
       "      <td>0.791176</td>\n",
       "      <td>0.789820</td>\n",
       "      <td>0.785572</td>\n",
       "      <td>0.022303</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.304198</td>\n",
       "      <td>0.019562</td>\n",
       "      <td>0.002839</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.811606</td>\n",
       "      <td>0.763933</td>\n",
       "      <td>0.806510</td>\n",
       "      <td>0.799829</td>\n",
       "      <td>0.800388</td>\n",
       "      <td>0.796453</td>\n",
       "      <td>0.016824</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.173497</td>\n",
       "      <td>0.008028</td>\n",
       "      <td>0.003802</td>\n",
       "      <td>0.000363</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.802178</td>\n",
       "      <td>0.735388</td>\n",
       "      <td>0.801343</td>\n",
       "      <td>0.793541</td>\n",
       "      <td>0.787513</td>\n",
       "      <td>0.783993</td>\n",
       "      <td>0.024890</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.257155</td>\n",
       "      <td>0.009759</td>\n",
       "      <td>0.002936</td>\n",
       "      <td>0.000309</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': None, 'fit_intercept...</td>\n",
       "      <td>0.806079</td>\n",
       "      <td>0.760296</td>\n",
       "      <td>0.813044</td>\n",
       "      <td>0.798992</td>\n",
       "      <td>0.798702</td>\n",
       "      <td>0.795423</td>\n",
       "      <td>0.018338</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.889216</td>\n",
       "      <td>0.020716</td>\n",
       "      <td>0.003533</td>\n",
       "      <td>0.000303</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.788535</td>\n",
       "      <td>0.723217</td>\n",
       "      <td>0.804160</td>\n",
       "      <td>0.780465</td>\n",
       "      <td>0.773932</td>\n",
       "      <td>0.774062</td>\n",
       "      <td>0.027355</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.363046</td>\n",
       "      <td>0.023834</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.803443</td>\n",
       "      <td>0.740623</td>\n",
       "      <td>0.814370</td>\n",
       "      <td>0.789522</td>\n",
       "      <td>0.781389</td>\n",
       "      <td>0.785869</td>\n",
       "      <td>0.025305</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.262555</td>\n",
       "      <td>0.037190</td>\n",
       "      <td>0.003818</td>\n",
       "      <td>0.000475</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.787963</td>\n",
       "      <td>0.723560</td>\n",
       "      <td>0.803814</td>\n",
       "      <td>0.784527</td>\n",
       "      <td>0.772106</td>\n",
       "      <td>0.774394</td>\n",
       "      <td>0.027356</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.330131</td>\n",
       "      <td>0.020646</td>\n",
       "      <td>0.003220</td>\n",
       "      <td>0.000275</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'C': 10, 'class_weight': 'balanced', 'fit_int...</td>\n",
       "      <td>0.800135</td>\n",
       "      <td>0.735252</td>\n",
       "      <td>0.809489</td>\n",
       "      <td>0.791235</td>\n",
       "      <td>0.778954</td>\n",
       "      <td>0.783013</td>\n",
       "      <td>0.025920</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_C  \\\n",
       "0        0.069818      0.006295         0.003921        0.000327    0.01   \n",
       "1        0.078660      0.006576         0.002795        0.000251    0.01   \n",
       "2        0.062631      0.004946         0.003359        0.000160    0.01   \n",
       "3        0.071163      0.006025         0.002876        0.000416    0.01   \n",
       "4        0.084816      0.010311         0.004229        0.000655    0.01   \n",
       "5        0.083945      0.006975         0.003051        0.000273    0.01   \n",
       "6        0.071071      0.005864         0.003412        0.000195    0.01   \n",
       "7        0.079819      0.004423         0.002986        0.000341    0.01   \n",
       "8        0.116096      0.009270         0.003723        0.000378     0.1   \n",
       "9        0.123630      0.005508         0.002833        0.000191     0.1   \n",
       "10       0.086468      0.014755         0.003761        0.000280     0.1   \n",
       "11       0.100373      0.009581         0.002679        0.000145     0.1   \n",
       "12       0.145386      0.006570         0.003972        0.000567     0.1   \n",
       "13       0.134309      0.012461         0.003206        0.000270     0.1   \n",
       "14       0.092019      0.010144         0.003871        0.000707     0.1   \n",
       "15       0.125083      0.005968         0.003008        0.000069     0.1   \n",
       "16       0.323977      0.016622         0.003720        0.000253       1   \n",
       "17       0.178206      0.015851         0.003107        0.000458       1   \n",
       "18       0.111624      0.004162         0.003405        0.000190       1   \n",
       "19       0.162661      0.014436         0.003020        0.000218       1   \n",
       "20       0.436908      0.016627         0.003908        0.000516       1   \n",
       "21       0.226536      0.024896         0.002819        0.000206       1   \n",
       "22       0.130704      0.010495         0.003355        0.000114       1   \n",
       "23       0.198420      0.010248         0.003119        0.000379       1   \n",
       "24       0.689387      0.005129         0.003652        0.000264      10   \n",
       "25       0.304198      0.019562         0.002839        0.000194      10   \n",
       "26       0.173497      0.008028         0.003802        0.000363      10   \n",
       "27       0.257155      0.009759         0.002936        0.000309      10   \n",
       "28       0.889216      0.020716         0.003533        0.000303      10   \n",
       "29       0.363046      0.023834         0.002887        0.000281      10   \n",
       "30       0.262555      0.037190         0.003818        0.000475      10   \n",
       "31       0.330131      0.020646         0.003220        0.000275      10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None               False            l1   \n",
       "3                None               False            l2   \n",
       "4            balanced                True            l1   \n",
       "5            balanced                True            l2   \n",
       "6            balanced               False            l1   \n",
       "7            balanced               False            l2   \n",
       "8                None                True            l1   \n",
       "9                None                True            l2   \n",
       "10               None               False            l1   \n",
       "11               None               False            l2   \n",
       "12           balanced                True            l1   \n",
       "13           balanced                True            l2   \n",
       "14           balanced               False            l1   \n",
       "15           balanced               False            l2   \n",
       "16               None                True            l1   \n",
       "17               None                True            l2   \n",
       "18               None               False            l1   \n",
       "19               None               False            l2   \n",
       "20           balanced                True            l1   \n",
       "21           balanced                True            l2   \n",
       "22           balanced               False            l1   \n",
       "23           balanced               False            l2   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None               False            l1   \n",
       "27               None               False            l2   \n",
       "28           balanced                True            l1   \n",
       "29           balanced                True            l2   \n",
       "30           balanced               False            l1   \n",
       "31           balanced               False            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.691393   \n",
       "1   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.692737   \n",
       "2   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.691542   \n",
       "3   {'C': 0.01, 'class_weight': None, 'fit_interce...           0.696126   \n",
       "4   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.748664   \n",
       "5   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.812321   \n",
       "6   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.748937   \n",
       "7   {'C': 0.01, 'class_weight': 'balanced', 'fit_i...           0.809736   \n",
       "8   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.763612   \n",
       "9   {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.756854   \n",
       "10  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.764769   \n",
       "11  {'C': 0.1, 'class_weight': None, 'fit_intercep...           0.768469   \n",
       "12  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.793361   \n",
       "13  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.827926   \n",
       "14  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.783262   \n",
       "15  {'C': 0.1, 'class_weight': 'balanced', 'fit_in...           0.824327   \n",
       "16  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.812132   \n",
       "17  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.808427   \n",
       "18  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.812289   \n",
       "19  {'C': 1, 'class_weight': None, 'fit_intercept'...           0.809167   \n",
       "20  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.823961   \n",
       "21  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.829339   \n",
       "22  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.821876   \n",
       "23  {'C': 1, 'class_weight': 'balanced', 'fit_inte...           0.824193   \n",
       "24  {'C': 10, 'class_weight': None, 'fit_intercept...           0.805129   \n",
       "25  {'C': 10, 'class_weight': None, 'fit_intercept...           0.811606   \n",
       "26  {'C': 10, 'class_weight': None, 'fit_intercept...           0.802178   \n",
       "27  {'C': 10, 'class_weight': None, 'fit_intercept...           0.806079   \n",
       "28  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.788535   \n",
       "29  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.803443   \n",
       "30  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.787963   \n",
       "31  {'C': 10, 'class_weight': 'balanced', 'fit_int...           0.800135   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.620713           0.659239           0.664309   \n",
       "1            0.623044           0.660652           0.666703   \n",
       "2            0.622935           0.662098           0.665514   \n",
       "3            0.629097           0.667299           0.672810   \n",
       "4            0.698730           0.735857           0.738759   \n",
       "5            0.766388           0.824713           0.815763   \n",
       "6            0.703665           0.739318           0.751133   \n",
       "7            0.770791           0.822562           0.815472   \n",
       "8            0.705108           0.756808           0.761819   \n",
       "9            0.702146           0.753882           0.752932   \n",
       "10           0.723460           0.760882           0.767865   \n",
       "11           0.718532           0.763156           0.765655   \n",
       "12           0.760916           0.803201           0.788688   \n",
       "13           0.776731           0.840339           0.818208   \n",
       "14           0.752696           0.796161           0.780419   \n",
       "15           0.773963           0.836736           0.816941   \n",
       "16           0.774001           0.820466           0.806209   \n",
       "17           0.776501           0.816973           0.798651   \n",
       "18           0.784269           0.819132           0.810213   \n",
       "19           0.779428           0.813793           0.807028   \n",
       "20           0.758214           0.824046           0.813712   \n",
       "21           0.763507           0.828179           0.812750   \n",
       "22           0.751027           0.820562           0.806642   \n",
       "23           0.757097           0.825337           0.809957   \n",
       "24           0.742384           0.799351           0.791176   \n",
       "25           0.763933           0.806510           0.799829   \n",
       "26           0.735388           0.801343           0.793541   \n",
       "27           0.760296           0.813044           0.798992   \n",
       "28           0.723217           0.804160           0.780465   \n",
       "29           0.740623           0.814370           0.789522   \n",
       "30           0.723560           0.803814           0.784527   \n",
       "31           0.735252           0.809489           0.791235   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.683607         0.663852        0.024622               32  \n",
       "1            0.684559         0.665539        0.024218               31  \n",
       "2            0.687291         0.665876        0.024395               30  \n",
       "3            0.687861         0.670639        0.023185               29  \n",
       "4            0.735142         0.731431        0.017049               28  \n",
       "5            0.801353         0.804107        0.020289                8  \n",
       "6            0.738710         0.736353        0.017086               27  \n",
       "7            0.802890         0.804290        0.017959                7  \n",
       "8            0.761149         0.749699        0.022407               25  \n",
       "9            0.760699         0.745303        0.021747               26  \n",
       "10           0.769316         0.757258        0.017145               24  \n",
       "11           0.781030         0.759368        0.021324               23  \n",
       "12           0.778779         0.784989        0.014377               17  \n",
       "13           0.794867         0.811614        0.022943                1  \n",
       "14           0.771375         0.776782        0.014423               20  \n",
       "15           0.791058         0.808605        0.022874                3  \n",
       "16           0.827049         0.807971        0.018409                4  \n",
       "17           0.821405         0.804391        0.015968                6  \n",
       "18           0.823133         0.809807        0.013587                2  \n",
       "19           0.817902         0.805464        0.013551                5  \n",
       "20           0.783656         0.800718        0.025888               10  \n",
       "21           0.786466         0.804048        0.025496                9  \n",
       "22           0.781182         0.796258        0.026937               13  \n",
       "23           0.780466         0.799410        0.026634               11  \n",
       "24           0.789820         0.785572        0.022303               16  \n",
       "25           0.800388         0.796453        0.016824               12  \n",
       "26           0.787513         0.783993        0.024890               18  \n",
       "27           0.798702         0.795423        0.018338               14  \n",
       "28           0.773932         0.774062        0.027355               22  \n",
       "29           0.781389         0.785869        0.025305               15  \n",
       "30           0.772106         0.774394        0.027356               21  \n",
       "31           0.778954         0.783013        0.025920               19  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(logReg_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perceptron Classifier with optimal hyperparameters had an average macro f1 score of 0.6638453325874798 using the following hyperparameters: {'alpha': 0.01, 'class_weight': None, 'fit_intercept': False, 'penalty': 'l1'}\n"
     ]
    }
   ],
   "source": [
    "## build model\n",
    "perceptron = Perceptron(random_state=42)\n",
    "perceptron_params = {'penalty':['l1', 'l2', 'elasticnet'], 'alpha':[0.01,0.1,1,10], 'class_weight': [None,'balanced'], 'fit_intercept':[True, False]}\n",
    "perceptron_tuner = GridSearchCV(perceptron, perceptron_params, scoring='f1_macro', cv=5)\n",
    "## fit model\n",
    "perceptron_tuner.fit(X_train, y_train)\n",
    "print('Perceptron Classifier with optimal hyperparameters had an average macro f1 score of '+str(perceptron_tuner.best_score_)+' using the following hyperparameters: '+str(perceptron_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_fit_intercept</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.051514</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.002958</td>\n",
       "      <td>0.000436</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.422714</td>\n",
       "      <td>0.228387</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.044065</td>\n",
       "      <td>0.010088</td>\n",
       "      <td>0.002887</td>\n",
       "      <td>0.000110</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.390907</td>\n",
       "      <td>0.465924</td>\n",
       "      <td>0.353482</td>\n",
       "      <td>0.676705</td>\n",
       "      <td>0.698250</td>\n",
       "      <td>0.517054</td>\n",
       "      <td>0.143947</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.072693</td>\n",
       "      <td>0.016617</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.000272</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.691837</td>\n",
       "      <td>0.620503</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.459505</td>\n",
       "      <td>0.619040</td>\n",
       "      <td>0.082949</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.054194</td>\n",
       "      <td>0.002420</td>\n",
       "      <td>0.002699</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.691183</td>\n",
       "      <td>0.620503</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.663845</td>\n",
       "      <td>0.024751</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.039682</td>\n",
       "      <td>0.006168</td>\n",
       "      <td>0.002971</td>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.468615</td>\n",
       "      <td>0.666497</td>\n",
       "      <td>0.352515</td>\n",
       "      <td>0.704783</td>\n",
       "      <td>0.485385</td>\n",
       "      <td>0.535559</td>\n",
       "      <td>0.131366</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.059388</td>\n",
       "      <td>0.004253</td>\n",
       "      <td>0.002812</td>\n",
       "      <td>0.000249</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'fit_int...</td>\n",
       "      <td>0.741041</td>\n",
       "      <td>0.619574</td>\n",
       "      <td>0.718993</td>\n",
       "      <td>0.472695</td>\n",
       "      <td>0.709569</td>\n",
       "      <td>0.652374</td>\n",
       "      <td>0.098926</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.058831</td>\n",
       "      <td>0.001044</td>\n",
       "      <td>0.003145</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.664112</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.366842</td>\n",
       "      <td>0.250996</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.053430</td>\n",
       "      <td>0.012606</td>\n",
       "      <td>0.002924</td>\n",
       "      <td>0.000466</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.672555</td>\n",
       "      <td>0.624268</td>\n",
       "      <td>0.237771</td>\n",
       "      <td>0.236650</td>\n",
       "      <td>0.329157</td>\n",
       "      <td>0.420080</td>\n",
       "      <td>0.190046</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.079359</td>\n",
       "      <td>0.016785</td>\n",
       "      <td>0.003227</td>\n",
       "      <td>0.000775</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.584274</td>\n",
       "      <td>0.688672</td>\n",
       "      <td>0.734781</td>\n",
       "      <td>0.704620</td>\n",
       "      <td>0.562029</td>\n",
       "      <td>0.654875</td>\n",
       "      <td>0.068712</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.058905</td>\n",
       "      <td>0.005183</td>\n",
       "      <td>0.003042</td>\n",
       "      <td>0.000387</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.478869</td>\n",
       "      <td>0.659278</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.664112</td>\n",
       "      <td>0.702969</td>\n",
       "      <td>0.590341</td>\n",
       "      <td>0.105832</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.049650</td>\n",
       "      <td>0.009888</td>\n",
       "      <td>0.002803</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.310301</td>\n",
       "      <td>0.658873</td>\n",
       "      <td>0.231079</td>\n",
       "      <td>0.677344</td>\n",
       "      <td>0.679613</td>\n",
       "      <td>0.511442</td>\n",
       "      <td>0.198294</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.081505</td>\n",
       "      <td>0.015121</td>\n",
       "      <td>0.002983</td>\n",
       "      <td>0.000555</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'f...</td>\n",
       "      <td>0.713241</td>\n",
       "      <td>0.675217</td>\n",
       "      <td>0.717411</td>\n",
       "      <td>0.257741</td>\n",
       "      <td>0.654561</td>\n",
       "      <td>0.603634</td>\n",
       "      <td>0.174539</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.044153</td>\n",
       "      <td>0.004529</td>\n",
       "      <td>0.002643</td>\n",
       "      <td>0.000285</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.034990</td>\n",
       "      <td>0.002545</td>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.000311</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.250584</td>\n",
       "      <td>0.484345</td>\n",
       "      <td>0.275352</td>\n",
       "      <td>0.447192</td>\n",
       "      <td>0.458299</td>\n",
       "      <td>0.383154</td>\n",
       "      <td>0.099180</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.042928</td>\n",
       "      <td>0.001580</td>\n",
       "      <td>0.002441</td>\n",
       "      <td>0.000114</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.536554</td>\n",
       "      <td>0.110564</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.060658</td>\n",
       "      <td>0.005897</td>\n",
       "      <td>0.002717</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.045928</td>\n",
       "      <td>0.010646</td>\n",
       "      <td>0.002702</td>\n",
       "      <td>0.000358</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.276761</td>\n",
       "      <td>0.606355</td>\n",
       "      <td>0.611060</td>\n",
       "      <td>0.661393</td>\n",
       "      <td>0.485735</td>\n",
       "      <td>0.528261</td>\n",
       "      <td>0.138376</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.050029</td>\n",
       "      <td>0.004311</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.000302</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'fit_inte...</td>\n",
       "      <td>0.691183</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.683607</td>\n",
       "      <td>0.585369</td>\n",
       "      <td>0.113879</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.047569</td>\n",
       "      <td>0.004566</td>\n",
       "      <td>0.002586</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.051930</td>\n",
       "      <td>0.006131</td>\n",
       "      <td>0.002782</td>\n",
       "      <td>0.000182</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.431913</td>\n",
       "      <td>0.568393</td>\n",
       "      <td>0.264987</td>\n",
       "      <td>0.241772</td>\n",
       "      <td>0.569452</td>\n",
       "      <td>0.415303</td>\n",
       "      <td>0.141550</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.057353</td>\n",
       "      <td>0.006758</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.000067</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.266429</td>\n",
       "      <td>0.208879</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.052373</td>\n",
       "      <td>0.003846</td>\n",
       "      <td>0.002539</td>\n",
       "      <td>0.000156</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.048559</td>\n",
       "      <td>0.007575</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.302026</td>\n",
       "      <td>0.472568</td>\n",
       "      <td>0.271560</td>\n",
       "      <td>0.247733</td>\n",
       "      <td>0.662307</td>\n",
       "      <td>0.391239</td>\n",
       "      <td>0.156824</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.055955</td>\n",
       "      <td>0.005060</td>\n",
       "      <td>0.002464</td>\n",
       "      <td>0.000190</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'fi...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.620503</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.571348</td>\n",
       "      <td>0.103934</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.046235</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.002815</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.056743</td>\n",
       "      <td>0.004168</td>\n",
       "      <td>0.002763</td>\n",
       "      <td>0.000542</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.188212</td>\n",
       "      <td>0.191956</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.291777</td>\n",
       "      <td>0.126346</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.048565</td>\n",
       "      <td>0.002078</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.000230</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.053356</td>\n",
       "      <td>0.006722</td>\n",
       "      <td>0.002701</td>\n",
       "      <td>0.000351</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.008813</td>\n",
       "      <td>0.002645</td>\n",
       "      <td>0.000244</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.191956</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.343440</td>\n",
       "      <td>0.126248</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.059403</td>\n",
       "      <td>0.004404</td>\n",
       "      <td>0.002915</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'fit_interc...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.045029</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.002395</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.084745</td>\n",
       "      <td>0.016906</td>\n",
       "      <td>0.002415</td>\n",
       "      <td>0.000149</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.538267</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.451379</td>\n",
       "      <td>0.295135</td>\n",
       "      <td>0.165344</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.053302</td>\n",
       "      <td>0.003759</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>0.000172</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.049318</td>\n",
       "      <td>0.002136</td>\n",
       "      <td>0.002588</td>\n",
       "      <td>0.000340</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.075215</td>\n",
       "      <td>0.011847</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.191956</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.395592</td>\n",
       "      <td>0.101818</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.057138</td>\n",
       "      <td>0.004926</td>\n",
       "      <td>0.002587</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'fit_...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.041837</td>\n",
       "      <td>0.001393</td>\n",
       "      <td>0.002342</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.059505</td>\n",
       "      <td>0.004720</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.188212</td>\n",
       "      <td>0.191956</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.291777</td>\n",
       "      <td>0.126346</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.066559</td>\n",
       "      <td>0.004917</td>\n",
       "      <td>0.002446</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.050779</td>\n",
       "      <td>0.002474</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>0.000588</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.066635</td>\n",
       "      <td>0.005991</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.000116</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.191956</td>\n",
       "      <td>0.185718</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.343440</td>\n",
       "      <td>0.126248</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.072261</td>\n",
       "      <td>0.005202</td>\n",
       "      <td>0.002574</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>10</td>\n",
       "      <td>None</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': None, 'fit_inter...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.047055</td>\n",
       "      <td>0.002502</td>\n",
       "      <td>0.002562</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.084671</td>\n",
       "      <td>0.013361</td>\n",
       "      <td>0.002980</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.538267</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.451379</td>\n",
       "      <td>0.295135</td>\n",
       "      <td>0.165344</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.070346</td>\n",
       "      <td>0.006279</td>\n",
       "      <td>0.002515</td>\n",
       "      <td>0.000222</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>True</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.161929</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.275781</td>\n",
       "      <td>0.139390</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.055609</td>\n",
       "      <td>0.005756</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.002133</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.075414</td>\n",
       "      <td>0.013042</td>\n",
       "      <td>0.002690</td>\n",
       "      <td>0.000384</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.191956</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.395592</td>\n",
       "      <td>0.101818</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.075976</td>\n",
       "      <td>0.006066</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>10</td>\n",
       "      <td>balanced</td>\n",
       "      <td>False</td>\n",
       "      <td>elasticnet</td>\n",
       "      <td>{'alpha': 10, 'class_weight': 'balanced', 'fit...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.051514      0.009536         0.002958        0.000436        0.01   \n",
       "1        0.044065      0.010088         0.002887        0.000110        0.01   \n",
       "2        0.072693      0.016617         0.002992        0.000272        0.01   \n",
       "3        0.054194      0.002420         0.002699        0.000099        0.01   \n",
       "4        0.039682      0.006168         0.002971        0.000084        0.01   \n",
       "5        0.059388      0.004253         0.002812        0.000249        0.01   \n",
       "6        0.058831      0.001044         0.003145        0.000492        0.01   \n",
       "7        0.053430      0.012606         0.002924        0.000466        0.01   \n",
       "8        0.079359      0.016785         0.003227        0.000775        0.01   \n",
       "9        0.058905      0.005183         0.003042        0.000387        0.01   \n",
       "10       0.049650      0.009888         0.002803        0.000334        0.01   \n",
       "11       0.081505      0.015121         0.002983        0.000555        0.01   \n",
       "12       0.044153      0.004529         0.002643        0.000285         0.1   \n",
       "13       0.034990      0.002545         0.002725        0.000311         0.1   \n",
       "14       0.042928      0.001580         0.002441        0.000114         0.1   \n",
       "15       0.060658      0.005897         0.002717        0.000358         0.1   \n",
       "16       0.045928      0.010646         0.002702        0.000358         0.1   \n",
       "17       0.050029      0.004311         0.002624        0.000302         0.1   \n",
       "18       0.047569      0.004566         0.002586        0.000421         0.1   \n",
       "19       0.051930      0.006131         0.002782        0.000182         0.1   \n",
       "20       0.057353      0.006758         0.002562        0.000067         0.1   \n",
       "21       0.052373      0.003846         0.002539        0.000156         0.1   \n",
       "22       0.048559      0.007575         0.002915        0.000265         0.1   \n",
       "23       0.055955      0.005060         0.002464        0.000190         0.1   \n",
       "24       0.046235      0.002815         0.002815        0.000370           1   \n",
       "25       0.056743      0.004168         0.002763        0.000542           1   \n",
       "26       0.048565      0.002078         0.002519        0.000230           1   \n",
       "27       0.053356      0.006722         0.002701        0.000351           1   \n",
       "28       0.061100      0.008813         0.002645        0.000244           1   \n",
       "29       0.059403      0.004404         0.002915        0.000489           1   \n",
       "30       0.045029      0.002307         0.002395        0.000189           1   \n",
       "31       0.084745      0.016906         0.002415        0.000149           1   \n",
       "32       0.053302      0.003759         0.002522        0.000172           1   \n",
       "33       0.049318      0.002136         0.002588        0.000340           1   \n",
       "34       0.075215      0.011847         0.002502        0.000226           1   \n",
       "35       0.057138      0.004926         0.002587        0.000188           1   \n",
       "36       0.041837      0.001393         0.002342        0.000098          10   \n",
       "37       0.059505      0.004720         0.002562        0.000105          10   \n",
       "38       0.066559      0.004917         0.002446        0.000095          10   \n",
       "39       0.050779      0.002474         0.002661        0.000588          10   \n",
       "40       0.066635      0.005991         0.002700        0.000116          10   \n",
       "41       0.072261      0.005202         0.002574        0.000160          10   \n",
       "42       0.047055      0.002502         0.002562        0.000267          10   \n",
       "43       0.084671      0.013361         0.002980        0.000690          10   \n",
       "44       0.070346      0.006279         0.002515        0.000222          10   \n",
       "45       0.055609      0.005756         0.004044        0.002133          10   \n",
       "46       0.075414      0.013042         0.002690        0.000384          10   \n",
       "47       0.075976      0.006066         0.002594        0.000181          10   \n",
       "\n",
       "   param_class_weight param_fit_intercept param_penalty  \\\n",
       "0                None                True            l1   \n",
       "1                None                True            l2   \n",
       "2                None                True    elasticnet   \n",
       "3                None               False            l1   \n",
       "4                None               False            l2   \n",
       "5                None               False    elasticnet   \n",
       "6            balanced                True            l1   \n",
       "7            balanced                True            l2   \n",
       "8            balanced                True    elasticnet   \n",
       "9            balanced               False            l1   \n",
       "10           balanced               False            l2   \n",
       "11           balanced               False    elasticnet   \n",
       "12               None                True            l1   \n",
       "13               None                True            l2   \n",
       "14               None                True    elasticnet   \n",
       "15               None               False            l1   \n",
       "16               None               False            l2   \n",
       "17               None               False    elasticnet   \n",
       "18           balanced                True            l1   \n",
       "19           balanced                True            l2   \n",
       "20           balanced                True    elasticnet   \n",
       "21           balanced               False            l1   \n",
       "22           balanced               False            l2   \n",
       "23           balanced               False    elasticnet   \n",
       "24               None                True            l1   \n",
       "25               None                True            l2   \n",
       "26               None                True    elasticnet   \n",
       "27               None               False            l1   \n",
       "28               None               False            l2   \n",
       "29               None               False    elasticnet   \n",
       "30           balanced                True            l1   \n",
       "31           balanced                True            l2   \n",
       "32           balanced                True    elasticnet   \n",
       "33           balanced               False            l1   \n",
       "34           balanced               False            l2   \n",
       "35           balanced               False    elasticnet   \n",
       "36               None                True            l1   \n",
       "37               None                True            l2   \n",
       "38               None                True    elasticnet   \n",
       "39               None               False            l1   \n",
       "40               None               False            l2   \n",
       "41               None               False    elasticnet   \n",
       "42           balanced                True            l1   \n",
       "43           balanced                True            l2   \n",
       "44           balanced                True    elasticnet   \n",
       "45           balanced               False            l1   \n",
       "46           balanced               False            l2   \n",
       "47           balanced               False    elasticnet   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.161929   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.390907   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.691837   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.691183   \n",
       "4   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.468615   \n",
       "5   {'alpha': 0.01, 'class_weight': None, 'fit_int...           0.741041   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.161929   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.672555   \n",
       "8   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.584274   \n",
       "9   {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.478869   \n",
       "10  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.310301   \n",
       "11  {'alpha': 0.01, 'class_weight': 'balanced', 'f...           0.713241   \n",
       "12  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.446530   \n",
       "13  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.250584   \n",
       "14  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.446530   \n",
       "15  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.446530   \n",
       "16  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.276761   \n",
       "17  {'alpha': 0.1, 'class_weight': None, 'fit_inte...           0.691183   \n",
       "18  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.161929   \n",
       "19  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.431913   \n",
       "20  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.161929   \n",
       "21  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.446530   \n",
       "22  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.302026   \n",
       "23  {'alpha': 0.1, 'class_weight': 'balanced', 'fi...           0.446530   \n",
       "24  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.446530   \n",
       "25  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.188212   \n",
       "26  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.446530   \n",
       "27  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.446530   \n",
       "28  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.446530   \n",
       "29  {'alpha': 1, 'class_weight': None, 'fit_interc...           0.446530   \n",
       "30  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.161929   \n",
       "31  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.538267   \n",
       "32  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.161929   \n",
       "33  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.446530   \n",
       "34  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.446530   \n",
       "35  {'alpha': 1, 'class_weight': 'balanced', 'fit_...           0.446530   \n",
       "36  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.446530   \n",
       "37  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.188212   \n",
       "38  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.446530   \n",
       "39  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.446530   \n",
       "40  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.446530   \n",
       "41  {'alpha': 10, 'class_weight': None, 'fit_inter...           0.446530   \n",
       "42  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.161929   \n",
       "43  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.538267   \n",
       "44  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.161929   \n",
       "45  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.446530   \n",
       "46  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.446530   \n",
       "47  {'alpha': 10, 'class_weight': 'balanced', 'fit...           0.446530   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.161929           0.659045           0.446478   \n",
       "1            0.465924           0.353482           0.676705   \n",
       "2            0.620503           0.659045           0.664309   \n",
       "3            0.620503           0.659045           0.664309   \n",
       "4            0.666497           0.352515           0.704783   \n",
       "5            0.619574           0.718993           0.472695   \n",
       "6            0.161929           0.162050           0.664112   \n",
       "7            0.624268           0.237771           0.236650   \n",
       "8            0.688672           0.734781           0.704620   \n",
       "9            0.659278           0.446478           0.664112   \n",
       "10           0.658873           0.231079           0.677344   \n",
       "11           0.675217           0.717411           0.257741   \n",
       "12           0.446530           0.446478           0.446478   \n",
       "13           0.484345           0.275352           0.447192   \n",
       "14           0.446530           0.659045           0.446478   \n",
       "15           0.446530           0.446478           0.446478   \n",
       "16           0.606355           0.611060           0.661393   \n",
       "17           0.446530           0.659045           0.446478   \n",
       "18           0.161929           0.162050           0.446478   \n",
       "19           0.568393           0.264987           0.241772   \n",
       "20           0.161929           0.162050           0.162050   \n",
       "21           0.446530           0.446478           0.446478   \n",
       "22           0.472568           0.271560           0.247733   \n",
       "23           0.620503           0.659045           0.446478   \n",
       "24           0.446530           0.446478           0.446478   \n",
       "25           0.191956           0.185718           0.446478   \n",
       "26           0.446530           0.446478           0.446478   \n",
       "27           0.446530           0.446478           0.446478   \n",
       "28           0.191956           0.185718           0.446478   \n",
       "29           0.446530           0.446478           0.446478   \n",
       "30           0.161929           0.162050           0.446478   \n",
       "31           0.161929           0.162050           0.162050   \n",
       "32           0.161929           0.162050           0.446478   \n",
       "33           0.446530           0.446478           0.446478   \n",
       "34           0.191956           0.446478           0.446478   \n",
       "35           0.446530           0.446478           0.446478   \n",
       "36           0.446530           0.446478           0.446478   \n",
       "37           0.191956           0.185718           0.446478   \n",
       "38           0.446530           0.446478           0.446478   \n",
       "39           0.446530           0.446478           0.446478   \n",
       "40           0.191956           0.185718           0.446478   \n",
       "41           0.446530           0.446478           0.446478   \n",
       "42           0.161929           0.162050           0.446478   \n",
       "43           0.161929           0.162050           0.162050   \n",
       "44           0.161929           0.162050           0.446478   \n",
       "45           0.446530           0.446478           0.446478   \n",
       "46           0.191956           0.446478           0.446478   \n",
       "47           0.446530           0.446478           0.446478   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.684187         0.422714        0.228387               29  \n",
       "1            0.698250         0.517054        0.143947               12  \n",
       "2            0.459505         0.619040        0.082949                4  \n",
       "3            0.684187         0.663845        0.024751                1  \n",
       "4            0.485385         0.535559        0.131366               10  \n",
       "5            0.709569         0.652374        0.098926                3  \n",
       "6            0.684187         0.366842        0.250996               36  \n",
       "7            0.329157         0.420080        0.190046               30  \n",
       "8            0.562029         0.654875        0.068712                2  \n",
       "9            0.702969         0.590341        0.105832                6  \n",
       "10           0.679613         0.511442        0.198294               13  \n",
       "11           0.654561         0.603634        0.174539                5  \n",
       "12           0.446520         0.446507        0.000024               14  \n",
       "13           0.458299         0.383154        0.099180               35  \n",
       "14           0.684187         0.536554        0.110564                9  \n",
       "15           0.446520         0.446507        0.000024               14  \n",
       "16           0.485735         0.528261        0.138376               11  \n",
       "17           0.683607         0.585369        0.113879                7  \n",
       "18           0.446520         0.275781        0.139390               43  \n",
       "19           0.569452         0.415303        0.141550               31  \n",
       "20           0.684187         0.266429        0.208879               48  \n",
       "21           0.446520         0.446507        0.000024               14  \n",
       "22           0.662307         0.391239        0.156824               34  \n",
       "23           0.684187         0.571348        0.103934                8  \n",
       "24           0.446520         0.446507        0.000024               14  \n",
       "25           0.446520         0.291777        0.126346               41  \n",
       "26           0.446520         0.446507        0.000024               14  \n",
       "27           0.446520         0.446507        0.000024               14  \n",
       "28           0.446520         0.343440        0.126248               37  \n",
       "29           0.446520         0.446507        0.000024               14  \n",
       "30           0.446520         0.275781        0.139390               43  \n",
       "31           0.451379         0.295135        0.165344               39  \n",
       "32           0.446520         0.275781        0.139390               43  \n",
       "33           0.446520         0.446507        0.000024               14  \n",
       "34           0.446520         0.395592        0.101818               32  \n",
       "35           0.446520         0.446507        0.000024               14  \n",
       "36           0.446520         0.446507        0.000024               14  \n",
       "37           0.446520         0.291777        0.126346               41  \n",
       "38           0.446520         0.446507        0.000024               14  \n",
       "39           0.446520         0.446507        0.000024               14  \n",
       "40           0.446520         0.343440        0.126248               37  \n",
       "41           0.446520         0.446507        0.000024               14  \n",
       "42           0.446520         0.275781        0.139390               43  \n",
       "43           0.451379         0.295135        0.165344               39  \n",
       "44           0.446520         0.275781        0.139390               43  \n",
       "45           0.446520         0.446507        0.000024               14  \n",
       "46           0.446520         0.395592        0.101818               32  \n",
       "47           0.446520         0.446507        0.000024               14  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(perceptron_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: SGD Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Classifier with optimal hyperparameters had an average macro f1 score of 0.8126167718289083 using the following hyperparameters: {'alpha': 0.01, 'class_weight': 'balanced', 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "sgd = SGDClassifier(random_state=42)\n",
    "sgd_params = {'penalty':['l1', 'l2'], 'alpha':[0.01, 0.1, 1], 'class_weight': [None,'balanced'], 'loss':['hinge', 'modified_huber']}\n",
    "sgd_tuner = GridSearchCV(sgd, sgd_params, scoring='f1_macro', cv=5)\n",
    "## fit model\n",
    "sgd_tuner.fit(X_train, y_train)\n",
    "print('SGD Classifier with optimal hyperparameters had an average macro f1 score of '+str(sgd_tuner.best_score_)+' using the following hyperparameters: '+str(sgd_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.074553</td>\n",
       "      <td>0.021639</td>\n",
       "      <td>0.002823</td>\n",
       "      <td>0.000315</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.691812</td>\n",
       "      <td>0.620713</td>\n",
       "      <td>0.659434</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.683607</td>\n",
       "      <td>0.663975</td>\n",
       "      <td>0.024709</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.043085</td>\n",
       "      <td>0.002442</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.000122</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.691812</td>\n",
       "      <td>0.621062</td>\n",
       "      <td>0.659434</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.683607</td>\n",
       "      <td>0.664045</td>\n",
       "      <td>0.024587</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.065177</td>\n",
       "      <td>0.007594</td>\n",
       "      <td>0.002694</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.695983</td>\n",
       "      <td>0.626865</td>\n",
       "      <td>0.665704</td>\n",
       "      <td>0.677076</td>\n",
       "      <td>0.687396</td>\n",
       "      <td>0.670605</td>\n",
       "      <td>0.024104</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.051897</td>\n",
       "      <td>0.005027</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000135</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.717189</td>\n",
       "      <td>0.655707</td>\n",
       "      <td>0.699380</td>\n",
       "      <td>0.708596</td>\n",
       "      <td>0.725579</td>\n",
       "      <td>0.701290</td>\n",
       "      <td>0.024403</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.162608</td>\n",
       "      <td>0.048593</td>\n",
       "      <td>0.002657</td>\n",
       "      <td>0.000419</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.733467</td>\n",
       "      <td>0.654710</td>\n",
       "      <td>0.696558</td>\n",
       "      <td>0.709091</td>\n",
       "      <td>0.705893</td>\n",
       "      <td>0.699944</td>\n",
       "      <td>0.025692</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.066511</td>\n",
       "      <td>0.011136</td>\n",
       "      <td>0.002911</td>\n",
       "      <td>0.000342</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.778634</td>\n",
       "      <td>0.719639</td>\n",
       "      <td>0.773851</td>\n",
       "      <td>0.783498</td>\n",
       "      <td>0.785944</td>\n",
       "      <td>0.768313</td>\n",
       "      <td>0.024689</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.170773</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.000261</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.744335</td>\n",
       "      <td>0.722037</td>\n",
       "      <td>0.764628</td>\n",
       "      <td>0.756284</td>\n",
       "      <td>0.754879</td>\n",
       "      <td>0.748433</td>\n",
       "      <td>0.014691</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.080107</td>\n",
       "      <td>0.015219</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.823528</td>\n",
       "      <td>0.785199</td>\n",
       "      <td>0.836155</td>\n",
       "      <td>0.819343</td>\n",
       "      <td>0.798859</td>\n",
       "      <td>0.812617</td>\n",
       "      <td>0.018217</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.071986</td>\n",
       "      <td>0.009426</td>\n",
       "      <td>0.002495</td>\n",
       "      <td>0.000173</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.051365</td>\n",
       "      <td>0.008247</td>\n",
       "      <td>0.002713</td>\n",
       "      <td>0.000518</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.449310</td>\n",
       "      <td>0.460289</td>\n",
       "      <td>0.455681</td>\n",
       "      <td>0.449255</td>\n",
       "      <td>0.459373</td>\n",
       "      <td>0.454782</td>\n",
       "      <td>0.004748</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.092420</td>\n",
       "      <td>0.017650</td>\n",
       "      <td>0.002834</td>\n",
       "      <td>0.000385</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.460289</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.449259</td>\n",
       "      <td>0.005515</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.047032</td>\n",
       "      <td>0.003146</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.689740</td>\n",
       "      <td>0.621237</td>\n",
       "      <td>0.659629</td>\n",
       "      <td>0.664309</td>\n",
       "      <td>0.680904</td>\n",
       "      <td>0.663164</td>\n",
       "      <td>0.023633</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.061347</td>\n",
       "      <td>0.014706</td>\n",
       "      <td>0.002709</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.691183</td>\n",
       "      <td>0.620503</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.161953</td>\n",
       "      <td>0.473319</td>\n",
       "      <td>0.183040</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.058438</td>\n",
       "      <td>0.007763</td>\n",
       "      <td>0.003293</td>\n",
       "      <td>0.000527</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.588270</td>\n",
       "      <td>0.705336</td>\n",
       "      <td>0.604029</td>\n",
       "      <td>0.539817</td>\n",
       "      <td>0.480157</td>\n",
       "      <td>0.583522</td>\n",
       "      <td>0.074668</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.075415</td>\n",
       "      <td>0.010958</td>\n",
       "      <td>0.002659</td>\n",
       "      <td>0.000392</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.691183</td>\n",
       "      <td>0.620503</td>\n",
       "      <td>0.659045</td>\n",
       "      <td>0.664112</td>\n",
       "      <td>0.684187</td>\n",
       "      <td>0.663806</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.061007</td>\n",
       "      <td>0.003561</td>\n",
       "      <td>0.003073</td>\n",
       "      <td>0.000622</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.794935</td>\n",
       "      <td>0.738211</td>\n",
       "      <td>0.807216</td>\n",
       "      <td>0.806017</td>\n",
       "      <td>0.794726</td>\n",
       "      <td>0.788221</td>\n",
       "      <td>0.025557</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.072602</td>\n",
       "      <td>0.006803</td>\n",
       "      <td>0.002804</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.056824</td>\n",
       "      <td>0.005858</td>\n",
       "      <td>0.002470</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.114967</td>\n",
       "      <td>0.012846</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446520</td>\n",
       "      <td>0.446507</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.050105</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>0.002391</td>\n",
       "      <td>0.000115</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.452075</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.448331</td>\n",
       "      <td>0.459373</td>\n",
       "      <td>0.450557</td>\n",
       "      <td>0.004855</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.056362</td>\n",
       "      <td>0.003439</td>\n",
       "      <td>0.002868</td>\n",
       "      <td>0.000219</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.162050</td>\n",
       "      <td>0.161953</td>\n",
       "      <td>0.332708</td>\n",
       "      <td>0.139382</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.047631</td>\n",
       "      <td>0.005504</td>\n",
       "      <td>0.002642</td>\n",
       "      <td>0.000232</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.323492</td>\n",
       "      <td>0.670815</td>\n",
       "      <td>0.319284</td>\n",
       "      <td>0.260009</td>\n",
       "      <td>0.161953</td>\n",
       "      <td>0.347111</td>\n",
       "      <td>0.172039</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.055320</td>\n",
       "      <td>0.004126</td>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.000276</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446530</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.446478</td>\n",
       "      <td>0.161953</td>\n",
       "      <td>0.389594</td>\n",
       "      <td>0.113821</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.043593</td>\n",
       "      <td>0.003971</td>\n",
       "      <td>0.002553</td>\n",
       "      <td>0.000179</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.676344</td>\n",
       "      <td>0.706482</td>\n",
       "      <td>0.696231</td>\n",
       "      <td>0.574523</td>\n",
       "      <td>0.256711</td>\n",
       "      <td>0.582058</td>\n",
       "      <td>0.169301</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.074553      0.021639         0.002823        0.000315        0.01   \n",
       "1        0.043085      0.002442         0.002510        0.000122        0.01   \n",
       "2        0.065177      0.007594         0.002694        0.000347        0.01   \n",
       "3        0.051897      0.005027         0.002600        0.000135        0.01   \n",
       "4        0.162608      0.048593         0.002657        0.000419        0.01   \n",
       "5        0.066511      0.011136         0.002911        0.000342        0.01   \n",
       "6        0.170773      0.038500         0.002641        0.000261        0.01   \n",
       "7        0.080107      0.015219         0.002740        0.000232        0.01   \n",
       "8        0.071986      0.009426         0.002495        0.000173         0.1   \n",
       "9        0.051365      0.008247         0.002713        0.000518         0.1   \n",
       "10       0.092420      0.017650         0.002834        0.000385         0.1   \n",
       "11       0.047032      0.003146         0.002470        0.000137         0.1   \n",
       "12       0.061347      0.014706         0.002709        0.000695         0.1   \n",
       "13       0.058438      0.007763         0.003293        0.000527         0.1   \n",
       "14       0.075415      0.010958         0.002659        0.000392         0.1   \n",
       "15       0.061007      0.003561         0.003073        0.000622         0.1   \n",
       "16       0.072602      0.006803         0.002804        0.000373           1   \n",
       "17       0.056824      0.005858         0.002470        0.000063           1   \n",
       "18       0.114967      0.012846         0.002600        0.000194           1   \n",
       "19       0.050105      0.007366         0.002391        0.000115           1   \n",
       "20       0.056362      0.003439         0.002868        0.000219           1   \n",
       "21       0.047631      0.005504         0.002642        0.000232           1   \n",
       "22       0.055320      0.004126         0.002641        0.000276           1   \n",
       "23       0.043593      0.003971         0.002553        0.000179           1   \n",
       "\n",
       "   param_class_weight      param_loss param_penalty  \\\n",
       "0                None           hinge            l1   \n",
       "1                None           hinge            l2   \n",
       "2                None  modified_huber            l1   \n",
       "3                None  modified_huber            l2   \n",
       "4            balanced           hinge            l1   \n",
       "5            balanced           hinge            l2   \n",
       "6            balanced  modified_huber            l1   \n",
       "7            balanced  modified_huber            l2   \n",
       "8                None           hinge            l1   \n",
       "9                None           hinge            l2   \n",
       "10               None  modified_huber            l1   \n",
       "11               None  modified_huber            l2   \n",
       "12           balanced           hinge            l1   \n",
       "13           balanced           hinge            l2   \n",
       "14           balanced  modified_huber            l1   \n",
       "15           balanced  modified_huber            l2   \n",
       "16               None           hinge            l1   \n",
       "17               None           hinge            l2   \n",
       "18               None  modified_huber            l1   \n",
       "19               None  modified_huber            l2   \n",
       "20           balanced           hinge            l1   \n",
       "21           balanced           hinge            l2   \n",
       "22           balanced  modified_huber            l1   \n",
       "23           balanced  modified_huber            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.691812   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.691812   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.695983   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.717189   \n",
       "4   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.733467   \n",
       "5   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.778634   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.744335   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.823528   \n",
       "8   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.446530   \n",
       "9   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.449310   \n",
       "10  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.446530   \n",
       "11  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.689740   \n",
       "12  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.691183   \n",
       "13  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.588270   \n",
       "14  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.691183   \n",
       "15  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.794935   \n",
       "16  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.446530   \n",
       "17  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.446530   \n",
       "18  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.446530   \n",
       "19  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.446530   \n",
       "20  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.446530   \n",
       "21  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.323492   \n",
       "22  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.446530   \n",
       "23  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.676344   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.620713           0.659434           0.664309   \n",
       "1            0.621062           0.659434           0.664309   \n",
       "2            0.626865           0.665704           0.677076   \n",
       "3            0.655707           0.699380           0.708596   \n",
       "4            0.654710           0.696558           0.709091   \n",
       "5            0.719639           0.773851           0.783498   \n",
       "6            0.722037           0.764628           0.756284   \n",
       "7            0.785199           0.836155           0.819343   \n",
       "8            0.446530           0.446478           0.446478   \n",
       "9            0.460289           0.455681           0.449255   \n",
       "10           0.460289           0.446478           0.446478   \n",
       "11           0.621237           0.659629           0.664309   \n",
       "12           0.620503           0.446478           0.446478   \n",
       "13           0.705336           0.604029           0.539817   \n",
       "14           0.620503           0.659045           0.664112   \n",
       "15           0.738211           0.807216           0.806017   \n",
       "16           0.446530           0.446478           0.446478   \n",
       "17           0.446530           0.446478           0.446478   \n",
       "18           0.446530           0.446478           0.446478   \n",
       "19           0.452075           0.446478           0.448331   \n",
       "20           0.446530           0.446478           0.162050   \n",
       "21           0.670815           0.319284           0.260009   \n",
       "22           0.446530           0.446478           0.446478   \n",
       "23           0.706482           0.696231           0.574523   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.683607         0.663975        0.024709                9  \n",
       "1            0.683607         0.664045        0.024587                8  \n",
       "2            0.687396         0.670605        0.024104                7  \n",
       "3            0.725579         0.701290        0.024403                5  \n",
       "4            0.705893         0.699944        0.025692                6  \n",
       "5            0.785944         0.768313        0.024689                3  \n",
       "6            0.754879         0.748433        0.014691                4  \n",
       "7            0.798859         0.812617        0.018217                1  \n",
       "8            0.446520         0.446507        0.000024               18  \n",
       "9            0.459373         0.454782        0.004748               15  \n",
       "10           0.446520         0.449259        0.005515               17  \n",
       "11           0.680904         0.663164        0.023633               11  \n",
       "12           0.161953         0.473319        0.183040               14  \n",
       "13           0.480157         0.583522        0.074668               12  \n",
       "14           0.684187         0.663806        0.024750               10  \n",
       "15           0.794726         0.788221        0.025557                2  \n",
       "16           0.446520         0.446507        0.000024               18  \n",
       "17           0.446520         0.446507        0.000024               18  \n",
       "18           0.446520         0.446507        0.000024               18  \n",
       "19           0.459373         0.450557        0.004855               16  \n",
       "20           0.161953         0.332708        0.139382               24  \n",
       "21           0.161953         0.347111        0.172039               23  \n",
       "22           0.161953         0.389594        0.113821               22  \n",
       "23           0.256711         0.582058        0.169301               13  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(sgd_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV Metrics: Cutoff 4\n",
      "\n",
      "Tuned Logistic Regression Model:\n",
      "Accuracy Average: 0.8644697213667427\n",
      "Precision Average: 0.7729522060593936\n",
      "F1 Score Average: 0.7760569343610646\n",
      "ROC AUC Score Average: 0.7894831831558848\n",
      "Confusion Matrix Average:\n",
      "[4270.2  439.2]\n",
      "[352.  776.4]\n",
      "\n",
      "\n",
      "Tuned Perceptron Model:\n",
      "Accuracy Average: 0.8486386621875559\n",
      "Precision Average: 0.9118543439469056\n",
      "F1 Score Average: 0.6208495699084164\n",
      "ROC AUC Score Average: 0.6041334727121703\n",
      "Confusion Matrix Average:\n",
      "[4.7054e+03 4.0000e+00]\n",
      "[879.6 248.8]\n",
      "\n",
      "\n",
      "Tuned SGD Classifier:\n",
      "Accuracy Average: 0.8632705162627772\n",
      "Precision Average: 0.7721938922800688\n",
      "F1 Score Average: 0.772743996838867\n",
      "ROC AUC Score Average: 0.7841207659774085\n",
      "Confusion Matrix Average:\n",
      "[4282.4  427. ]\n",
      "[371.2 757.2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print average k-fold CV metrics for optimally tuned models\n",
    "cutoff = 4\n",
    "\n",
    "print(f\"5-Fold CV Metrics: Cutoff {cutoff}\\n\")\n",
    "\n",
    "print(\"Tuned Logistic Regression Model:\")\n",
    "logReg.set_params(**logReg_tuner.best_params_)\n",
    "predictions = cv_metrics(logReg, 2)\n",
    "\n",
    "print(\"Tuned Perceptron Model:\")\n",
    "perceptron.set_params(**perceptron_tuner.best_params_)\n",
    "predictions = cv_metrics(perceptron, 2)\n",
    "\n",
    "print(\"Tuned SGD Classifier:\")\n",
    "sgd.set_params(**sgd_tuner.best_params_)\n",
    "predictions = cv_metrics(sgd, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Testing\n",
    "For the last cutoff, logistic regression outperforms the other two models, so I'll use this model to make predictions on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save test predictions\n",
    "y_test_hat_4 = logReg.predict(X_test)\n",
    "out_results(y_test_hat_4, \"binary\", 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a macro f1 score of 0.82972 on the test set on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Multiclass Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 0: Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plot 5 ROC curves and average ROC curve with AUC scores for each\n",
    "def plot_roc(model, tuner, X, y):\n",
    "    y = label_binarize(y, classes=[1,2,3,4,5])\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8)\n",
    "    model_binary = OneVsRestClassifier(tuner)\n",
    "    if model == 'Gaussian NB':\n",
    "        model_binary.fit(X_train.toarray(), y_train)\n",
    "        y_score = model_binary.predict_proba(X_test.toarray())\n",
    "    else:\n",
    "        model_binary.fit(X_train, y_train)\n",
    "        y_score = model_binary.predict_proba(X_test)\n",
    "\n",
    "## figure creation heavily inspired by: https://scikit-learn.org/stable/auto_examples/model_selection/plot_roc.html\n",
    "    fpr = {}\n",
    "    tpr = {}\n",
    "    roc_auc = {}\n",
    "    for i in range(5):\n",
    "        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_score[:, i])\n",
    "        roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "        \n",
    "    plt.figure()\n",
    "    n=1\n",
    "    for i in range(5):\n",
    "        plt.plot(fpr[i], tpr[i], label='ROC Curve of class '+str(n)+' area = {1:0.2f}'\n",
    "                ''.format(i, roc_auc[i]))\n",
    "        n+=1\n",
    "        \n",
    "    plt.plot([0, 1], [0, 1], \"k--\", label=\"ROC curve for chance level (AUC = 0.5)\")\n",
    "    plt.axis(\"square\")\n",
    "    plt.xlabel(\"False Positive Rate\")\n",
    "    plt.ylabel(\"True Positive Rate\")\n",
    "    plt.title(f\"{model}: Extension of Receiver Operating Characteristic to binarized multiclass\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Feature Engineering\n",
    "\n",
    "I used the same feature vector for multiclass classification as I did for the binary classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Annotation\n",
    "The 'overall' column will be the target and is already labeled, thus there is no need for additional data annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        1\n",
      "1        1\n",
      "2        1\n",
      "3        1\n",
      "4        1\n",
      "        ..\n",
      "29184    5\n",
      "29185    5\n",
      "29186    5\n",
      "29187    5\n",
      "29188    5\n",
      "Name: overall, Length: 29189, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y_train = df_train['overall']\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 1: One-vs-Rest Multiclass Classifier (using Logistic Regression and common optimal hyperparameters from the binary classifications)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-vs-Rest Classifier with optimal hyperparameters had an average macro f1 score of 0.5779077133237489 using the following hyperparameters: {'estimator__fit_intercept': True, 'n_jobs': -1}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "oneVRest = OneVsRestClassifier(LogisticRegression(max_iter=200, C=1, penalty='l2', class_weight='balanced', solver='liblinear', random_state=42))\n",
    "oneVRest_params = {'n_jobs':[-1, 1, 3], 'estimator__fit_intercept':[True, False]}\n",
    "oneVRest_tuner = GridSearchCV(oneVRest, oneVRest_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "oneVRest_tuner.fit(X_train, y_train)\n",
    "print('One-vs-Rest Classifier with optimal hyperparameters had an average macro f1 score of '+str(oneVRest_tuner.best_score_)+' using the following hyperparameters: '+str(oneVRest_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_estimator__fit_intercept</th>\n",
       "      <th>param_n_jobs</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.178267</td>\n",
       "      <td>0.647394</td>\n",
       "      <td>0.014265</td>\n",
       "      <td>0.001146</td>\n",
       "      <td>True</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'estimator__fit_intercept': True, 'n_jobs': -1}</td>\n",
       "      <td>0.576855</td>\n",
       "      <td>0.519773</td>\n",
       "      <td>0.602208</td>\n",
       "      <td>0.593572</td>\n",
       "      <td>0.597132</td>\n",
       "      <td>0.577908</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.132864</td>\n",
       "      <td>0.061139</td>\n",
       "      <td>0.005073</td>\n",
       "      <td>0.000483</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>{'estimator__fit_intercept': True, 'n_jobs': 1}</td>\n",
       "      <td>0.576855</td>\n",
       "      <td>0.519773</td>\n",
       "      <td>0.602208</td>\n",
       "      <td>0.593572</td>\n",
       "      <td>0.597132</td>\n",
       "      <td>0.577908</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.963413</td>\n",
       "      <td>0.559994</td>\n",
       "      <td>0.008284</td>\n",
       "      <td>0.003352</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>{'estimator__fit_intercept': True, 'n_jobs': 3}</td>\n",
       "      <td>0.576855</td>\n",
       "      <td>0.519773</td>\n",
       "      <td>0.602208</td>\n",
       "      <td>0.593572</td>\n",
       "      <td>0.597132</td>\n",
       "      <td>0.577908</td>\n",
       "      <td>0.030286</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.203158</td>\n",
       "      <td>0.710877</td>\n",
       "      <td>0.014586</td>\n",
       "      <td>0.001957</td>\n",
       "      <td>False</td>\n",
       "      <td>-1</td>\n",
       "      <td>{'estimator__fit_intercept': False, 'n_jobs': -1}</td>\n",
       "      <td>0.576864</td>\n",
       "      <td>0.518385</td>\n",
       "      <td>0.602148</td>\n",
       "      <td>0.594390</td>\n",
       "      <td>0.594809</td>\n",
       "      <td>0.577319</td>\n",
       "      <td>0.030618</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.031643</td>\n",
       "      <td>0.041521</td>\n",
       "      <td>0.004697</td>\n",
       "      <td>0.000281</td>\n",
       "      <td>False</td>\n",
       "      <td>1</td>\n",
       "      <td>{'estimator__fit_intercept': False, 'n_jobs': 1}</td>\n",
       "      <td>0.576864</td>\n",
       "      <td>0.518385</td>\n",
       "      <td>0.602148</td>\n",
       "      <td>0.594390</td>\n",
       "      <td>0.594809</td>\n",
       "      <td>0.577319</td>\n",
       "      <td>0.030618</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.913867</td>\n",
       "      <td>0.539289</td>\n",
       "      <td>0.013812</td>\n",
       "      <td>0.001165</td>\n",
       "      <td>False</td>\n",
       "      <td>3</td>\n",
       "      <td>{'estimator__fit_intercept': False, 'n_jobs': 3}</td>\n",
       "      <td>0.576864</td>\n",
       "      <td>0.518385</td>\n",
       "      <td>0.602148</td>\n",
       "      <td>0.594390</td>\n",
       "      <td>0.594809</td>\n",
       "      <td>0.577319</td>\n",
       "      <td>0.030618</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.178267      0.647394         0.014265        0.001146   \n",
       "1       1.132864      0.061139         0.005073        0.000483   \n",
       "2       0.963413      0.559994         0.008284        0.003352   \n",
       "3       1.203158      0.710877         0.014586        0.001957   \n",
       "4       1.031643      0.041521         0.004697        0.000281   \n",
       "5       0.913867      0.539289         0.013812        0.001165   \n",
       "\n",
       "  param_estimator__fit_intercept param_n_jobs  \\\n",
       "0                           True           -1   \n",
       "1                           True            1   \n",
       "2                           True            3   \n",
       "3                          False           -1   \n",
       "4                          False            1   \n",
       "5                          False            3   \n",
       "\n",
       "                                              params  split0_test_score  \\\n",
       "0   {'estimator__fit_intercept': True, 'n_jobs': -1}           0.576855   \n",
       "1    {'estimator__fit_intercept': True, 'n_jobs': 1}           0.576855   \n",
       "2    {'estimator__fit_intercept': True, 'n_jobs': 3}           0.576855   \n",
       "3  {'estimator__fit_intercept': False, 'n_jobs': -1}           0.576864   \n",
       "4   {'estimator__fit_intercept': False, 'n_jobs': 1}           0.576864   \n",
       "5   {'estimator__fit_intercept': False, 'n_jobs': 3}           0.576864   \n",
       "\n",
       "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
       "0           0.519773           0.602208           0.593572           0.597132   \n",
       "1           0.519773           0.602208           0.593572           0.597132   \n",
       "2           0.519773           0.602208           0.593572           0.597132   \n",
       "3           0.518385           0.602148           0.594390           0.594809   \n",
       "4           0.518385           0.602148           0.594390           0.594809   \n",
       "5           0.518385           0.602148           0.594390           0.594809   \n",
       "\n",
       "   mean_test_score  std_test_score  rank_test_score  \n",
       "0         0.577908        0.030286                1  \n",
       "1         0.577908        0.030286                1  \n",
       "2         0.577908        0.030286                1  \n",
       "3         0.577319        0.030618                4  \n",
       "4         0.577319        0.030618                4  \n",
       "5         0.577319        0.030618                4  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(oneVRest_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc('One-vs-Rest', oneVRest_tuner, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 2: Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Guassian Naive Bayes Classifier with optimal hyperparameters had an average macro f1 score of 0.49747510603136913 using the following hyperparameters: {'var_smoothing': 0.005623413251903491}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "gaussianNB = GaussianNB()\n",
    "gaussianNB_params = {'var_smoothing': np.logspace(0, -9, num = 5)}\n",
    "gaussianNB_tuner = GridSearchCV(gaussianNB, gaussianNB_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "gaussianNB_tuner.fit(X_train.toarray(), y_train)\n",
    "print('Guassian Naive Bayes Classifier with optimal hyperparameters had an average macro f1 score of '+str(gaussianNB_tuner.best_score_)+' using the following hyperparameters: '+str(gaussianNB_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_var_smoothing</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.241206</td>\n",
       "      <td>0.058901</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.010896</td>\n",
       "      <td>1</td>\n",
       "      <td>{'var_smoothing': 1.0}</td>\n",
       "      <td>0.485558</td>\n",
       "      <td>0.406302</td>\n",
       "      <td>0.455247</td>\n",
       "      <td>0.459355</td>\n",
       "      <td>0.477370</td>\n",
       "      <td>0.456766</td>\n",
       "      <td>0.027601</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.231365</td>\n",
       "      <td>0.021176</td>\n",
       "      <td>0.819186</td>\n",
       "      <td>0.009588</td>\n",
       "      <td>0.00562341</td>\n",
       "      <td>{'var_smoothing': 0.005623413251903491}</td>\n",
       "      <td>0.516672</td>\n",
       "      <td>0.404936</td>\n",
       "      <td>0.522421</td>\n",
       "      <td>0.518884</td>\n",
       "      <td>0.524462</td>\n",
       "      <td>0.497475</td>\n",
       "      <td>0.046348</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.190778</td>\n",
       "      <td>0.021463</td>\n",
       "      <td>0.832852</td>\n",
       "      <td>0.033716</td>\n",
       "      <td>3.16228e-05</td>\n",
       "      <td>{'var_smoothing': 3.1622776601683795e-05}</td>\n",
       "      <td>0.463140</td>\n",
       "      <td>0.378701</td>\n",
       "      <td>0.471990</td>\n",
       "      <td>0.484665</td>\n",
       "      <td>0.467672</td>\n",
       "      <td>0.453233</td>\n",
       "      <td>0.037951</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.194631</td>\n",
       "      <td>0.019062</td>\n",
       "      <td>0.823637</td>\n",
       "      <td>0.015223</td>\n",
       "      <td>1.77828e-07</td>\n",
       "      <td>{'var_smoothing': 1.7782794100389227e-07}</td>\n",
       "      <td>0.420926</td>\n",
       "      <td>0.362878</td>\n",
       "      <td>0.415899</td>\n",
       "      <td>0.432164</td>\n",
       "      <td>0.423174</td>\n",
       "      <td>0.411008</td>\n",
       "      <td>0.024635</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.203798</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>0.828251</td>\n",
       "      <td>0.010301</td>\n",
       "      <td>1e-09</td>\n",
       "      <td>{'var_smoothing': 1e-09}</td>\n",
       "      <td>0.385698</td>\n",
       "      <td>0.327701</td>\n",
       "      <td>0.368210</td>\n",
       "      <td>0.396788</td>\n",
       "      <td>0.393814</td>\n",
       "      <td>0.374442</td>\n",
       "      <td>0.025397</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "0       1.241206      0.058901         0.813187        0.010896   \n",
       "1       1.231365      0.021176         0.819186        0.009588   \n",
       "2       1.190778      0.021463         0.832852        0.033716   \n",
       "3       1.194631      0.019062         0.823637        0.015223   \n",
       "4       1.203798      0.024219         0.828251        0.010301   \n",
       "\n",
       "  param_var_smoothing                                     params  \\\n",
       "0                   1                     {'var_smoothing': 1.0}   \n",
       "1          0.00562341    {'var_smoothing': 0.005623413251903491}   \n",
       "2         3.16228e-05  {'var_smoothing': 3.1622776601683795e-05}   \n",
       "3         1.77828e-07  {'var_smoothing': 1.7782794100389227e-07}   \n",
       "4               1e-09                   {'var_smoothing': 1e-09}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0           0.485558           0.406302           0.455247           0.459355   \n",
       "1           0.516672           0.404936           0.522421           0.518884   \n",
       "2           0.463140           0.378701           0.471990           0.484665   \n",
       "3           0.420926           0.362878           0.415899           0.432164   \n",
       "4           0.385698           0.327701           0.368210           0.396788   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0           0.477370         0.456766        0.027601                2  \n",
       "1           0.524462         0.497475        0.046348                1  \n",
       "2           0.467672         0.453233        0.037951                3  \n",
       "3           0.423174         0.411008        0.024635                4  \n",
       "4           0.393814         0.374442        0.025397                5  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(gaussianNB_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc('Gaussian NB', gaussianNB_tuner, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model 3: Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD Multiclass Classifier with optimal hyperparameters had an average macro f1 score of 0.5655516961736582 using the following hyperparameters: {'alpha': 0.01, 'class_weight': None, 'loss': 'modified_huber', 'penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "## build model and tuner\n",
    "sgd_multi = SGDClassifier(random_state=42)\n",
    "sgd_multi_params = {'penalty':['l1', 'l2'], 'alpha':[0.01, 0.1, 1], 'class_weight': [None,'balanced'], 'loss':['hinge', 'modified_huber']}\n",
    "sgd_multi_tuner = GridSearchCV(sgd_multi, sgd_multi_params, scoring='f1_macro', cv=5)\n",
    "## tune model\n",
    "sgd_multi_tuner.fit(X_train, y_train)\n",
    "print('SGD Multiclass Classifier with optimal hyperparameters had an average macro f1 score of '+str(sgd_multi_tuner.best_score_)+' using the following hyperparameters: '+str(sgd_multi_tuner.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>param_class_weight</th>\n",
       "      <th>param_loss</th>\n",
       "      <th>param_penalty</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.408339</td>\n",
       "      <td>0.066925</td>\n",
       "      <td>0.004250</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.363216</td>\n",
       "      <td>0.280596</td>\n",
       "      <td>0.336655</td>\n",
       "      <td>0.337768</td>\n",
       "      <td>0.351563</td>\n",
       "      <td>0.333960</td>\n",
       "      <td>0.028409</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.255627</td>\n",
       "      <td>0.004830</td>\n",
       "      <td>0.003960</td>\n",
       "      <td>0.000212</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.554181</td>\n",
       "      <td>0.469204</td>\n",
       "      <td>0.566214</td>\n",
       "      <td>0.558083</td>\n",
       "      <td>0.564057</td>\n",
       "      <td>0.542348</td>\n",
       "      <td>0.036820</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.327843</td>\n",
       "      <td>0.011084</td>\n",
       "      <td>0.003779</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.453724</td>\n",
       "      <td>0.365099</td>\n",
       "      <td>0.439349</td>\n",
       "      <td>0.450615</td>\n",
       "      <td>0.449041</td>\n",
       "      <td>0.431566</td>\n",
       "      <td>0.033579</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.279703</td>\n",
       "      <td>0.033363</td>\n",
       "      <td>0.003926</td>\n",
       "      <td>0.000421</td>\n",
       "      <td>0.01</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': None, 'loss': ...</td>\n",
       "      <td>0.572293</td>\n",
       "      <td>0.503945</td>\n",
       "      <td>0.587871</td>\n",
       "      <td>0.579071</td>\n",
       "      <td>0.584578</td>\n",
       "      <td>0.565552</td>\n",
       "      <td>0.031253</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.396693</td>\n",
       "      <td>0.060796</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.365258</td>\n",
       "      <td>0.276239</td>\n",
       "      <td>0.336655</td>\n",
       "      <td>0.337768</td>\n",
       "      <td>0.351563</td>\n",
       "      <td>0.333497</td>\n",
       "      <td>0.030469</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.256835</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.003951</td>\n",
       "      <td>0.000263</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.553294</td>\n",
       "      <td>0.471116</td>\n",
       "      <td>0.565860</td>\n",
       "      <td>0.554681</td>\n",
       "      <td>0.561351</td>\n",
       "      <td>0.541260</td>\n",
       "      <td>0.035366</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.348885</td>\n",
       "      <td>0.023002</td>\n",
       "      <td>0.004130</td>\n",
       "      <td>0.000498</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.453566</td>\n",
       "      <td>0.369883</td>\n",
       "      <td>0.439479</td>\n",
       "      <td>0.446313</td>\n",
       "      <td>0.448359</td>\n",
       "      <td>0.431520</td>\n",
       "      <td>0.031148</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.277213</td>\n",
       "      <td>0.005128</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000524</td>\n",
       "      <td>0.01</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.01, 'class_weight': 'balanced', 'l...</td>\n",
       "      <td>0.571331</td>\n",
       "      <td>0.502064</td>\n",
       "      <td>0.587942</td>\n",
       "      <td>0.579523</td>\n",
       "      <td>0.585275</td>\n",
       "      <td>0.565227</td>\n",
       "      <td>0.032091</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.354154</td>\n",
       "      <td>0.041757</td>\n",
       "      <td>0.003543</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.112096</td>\n",
       "      <td>0.117756</td>\n",
       "      <td>0.103305</td>\n",
       "      <td>0.101308</td>\n",
       "      <td>0.107609</td>\n",
       "      <td>0.108415</td>\n",
       "      <td>0.005968</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.231819</td>\n",
       "      <td>0.017830</td>\n",
       "      <td>0.004044</td>\n",
       "      <td>0.000519</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.529887</td>\n",
       "      <td>0.389666</td>\n",
       "      <td>0.536054</td>\n",
       "      <td>0.539359</td>\n",
       "      <td>0.539231</td>\n",
       "      <td>0.506839</td>\n",
       "      <td>0.058688</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.446703</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.003697</td>\n",
       "      <td>0.000298</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.209099</td>\n",
       "      <td>0.187025</td>\n",
       "      <td>0.187656</td>\n",
       "      <td>0.183445</td>\n",
       "      <td>0.106139</td>\n",
       "      <td>0.174673</td>\n",
       "      <td>0.035440</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.243317</td>\n",
       "      <td>0.014673</td>\n",
       "      <td>0.003944</td>\n",
       "      <td>0.000247</td>\n",
       "      <td>0.1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': None, 'loss': '...</td>\n",
       "      <td>0.549773</td>\n",
       "      <td>0.433541</td>\n",
       "      <td>0.567434</td>\n",
       "      <td>0.554995</td>\n",
       "      <td>0.562493</td>\n",
       "      <td>0.533647</td>\n",
       "      <td>0.050420</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.347701</td>\n",
       "      <td>0.038582</td>\n",
       "      <td>0.003897</td>\n",
       "      <td>0.000492</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.112096</td>\n",
       "      <td>0.117756</td>\n",
       "      <td>0.103305</td>\n",
       "      <td>0.100598</td>\n",
       "      <td>0.067833</td>\n",
       "      <td>0.100318</td>\n",
       "      <td>0.017361</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.238544</td>\n",
       "      <td>0.023478</td>\n",
       "      <td>0.004333</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.533114</td>\n",
       "      <td>0.387021</td>\n",
       "      <td>0.533606</td>\n",
       "      <td>0.542260</td>\n",
       "      <td>0.540646</td>\n",
       "      <td>0.507330</td>\n",
       "      <td>0.060265</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.468251</td>\n",
       "      <td>0.042186</td>\n",
       "      <td>0.003773</td>\n",
       "      <td>0.000557</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.209099</td>\n",
       "      <td>0.187025</td>\n",
       "      <td>0.104486</td>\n",
       "      <td>0.087106</td>\n",
       "      <td>0.108651</td>\n",
       "      <td>0.139273</td>\n",
       "      <td>0.049041</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.232835</td>\n",
       "      <td>0.010339</td>\n",
       "      <td>0.003988</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 0.1, 'class_weight': 'balanced', 'lo...</td>\n",
       "      <td>0.551147</td>\n",
       "      <td>0.434533</td>\n",
       "      <td>0.570827</td>\n",
       "      <td>0.556849</td>\n",
       "      <td>0.572118</td>\n",
       "      <td>0.537095</td>\n",
       "      <td>0.051906</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.385185</td>\n",
       "      <td>0.020050</td>\n",
       "      <td>0.003567</td>\n",
       "      <td>0.000382</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.065971</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.064781</td>\n",
       "      <td>0.066844</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.303230</td>\n",
       "      <td>0.019501</td>\n",
       "      <td>0.003934</td>\n",
       "      <td>0.000251</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'hi...</td>\n",
       "      <td>0.383757</td>\n",
       "      <td>0.313875</td>\n",
       "      <td>0.367384</td>\n",
       "      <td>0.364630</td>\n",
       "      <td>0.396504</td>\n",
       "      <td>0.365230</td>\n",
       "      <td>0.028155</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.618255</td>\n",
       "      <td>0.016119</td>\n",
       "      <td>0.003428</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.065971</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.064781</td>\n",
       "      <td>0.066844</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.249548</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>0.004557</td>\n",
       "      <td>0.000345</td>\n",
       "      <td>1</td>\n",
       "      <td>None</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': None, 'loss': 'mo...</td>\n",
       "      <td>0.459908</td>\n",
       "      <td>0.362856</td>\n",
       "      <td>0.422737</td>\n",
       "      <td>0.427319</td>\n",
       "      <td>0.468300</td>\n",
       "      <td>0.428224</td>\n",
       "      <td>0.037186</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.377269</td>\n",
       "      <td>0.011316</td>\n",
       "      <td>0.003402</td>\n",
       "      <td>0.000318</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.065971</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.064781</td>\n",
       "      <td>0.066844</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.312449</td>\n",
       "      <td>0.020338</td>\n",
       "      <td>0.004054</td>\n",
       "      <td>0.000488</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>hinge</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.386356</td>\n",
       "      <td>0.333498</td>\n",
       "      <td>0.386497</td>\n",
       "      <td>0.398891</td>\n",
       "      <td>0.306251</td>\n",
       "      <td>0.362299</td>\n",
       "      <td>0.035984</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.622680</td>\n",
       "      <td>0.023277</td>\n",
       "      <td>0.003632</td>\n",
       "      <td>0.000373</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l1</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.065971</td>\n",
       "      <td>0.067824</td>\n",
       "      <td>0.064781</td>\n",
       "      <td>0.066844</td>\n",
       "      <td>0.001257</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.242662</td>\n",
       "      <td>0.013233</td>\n",
       "      <td>0.003806</td>\n",
       "      <td>0.000214</td>\n",
       "      <td>1</td>\n",
       "      <td>balanced</td>\n",
       "      <td>modified_huber</td>\n",
       "      <td>l2</td>\n",
       "      <td>{'alpha': 1, 'class_weight': 'balanced', 'loss...</td>\n",
       "      <td>0.459462</td>\n",
       "      <td>0.388066</td>\n",
       "      <td>0.424172</td>\n",
       "      <td>0.426793</td>\n",
       "      <td>0.437630</td>\n",
       "      <td>0.427225</td>\n",
       "      <td>0.023197</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time param_alpha  \\\n",
       "0        0.408339      0.066925         0.004250        0.000737        0.01   \n",
       "1        0.255627      0.004830         0.003960        0.000212        0.01   \n",
       "2        0.327843      0.011084         0.003779        0.000201        0.01   \n",
       "3        0.279703      0.033363         0.003926        0.000421        0.01   \n",
       "4        0.396693      0.060796         0.003838        0.000383        0.01   \n",
       "5        0.256835      0.004034         0.003951        0.000263        0.01   \n",
       "6        0.348885      0.023002         0.004130        0.000498        0.01   \n",
       "7        0.277213      0.005128         0.004044        0.000524        0.01   \n",
       "8        0.354154      0.041757         0.003543        0.000299         0.1   \n",
       "9        0.231819      0.017830         0.004044        0.000519         0.1   \n",
       "10       0.446703      0.038462         0.003697        0.000298         0.1   \n",
       "11       0.243317      0.014673         0.003944        0.000247         0.1   \n",
       "12       0.347701      0.038582         0.003897        0.000492         0.1   \n",
       "13       0.238544      0.023478         0.004333        0.000618         0.1   \n",
       "14       0.468251      0.042186         0.003773        0.000557         0.1   \n",
       "15       0.232835      0.010339         0.003988        0.000401         0.1   \n",
       "16       0.385185      0.020050         0.003567        0.000382           1   \n",
       "17       0.303230      0.019501         0.003934        0.000251           1   \n",
       "18       0.618255      0.016119         0.003428        0.000226           1   \n",
       "19       0.249548      0.006209         0.004557        0.000345           1   \n",
       "20       0.377269      0.011316         0.003402        0.000318           1   \n",
       "21       0.312449      0.020338         0.004054        0.000488           1   \n",
       "22       0.622680      0.023277         0.003632        0.000373           1   \n",
       "23       0.242662      0.013233         0.003806        0.000214           1   \n",
       "\n",
       "   param_class_weight      param_loss param_penalty  \\\n",
       "0                None           hinge            l1   \n",
       "1                None           hinge            l2   \n",
       "2                None  modified_huber            l1   \n",
       "3                None  modified_huber            l2   \n",
       "4            balanced           hinge            l1   \n",
       "5            balanced           hinge            l2   \n",
       "6            balanced  modified_huber            l1   \n",
       "7            balanced  modified_huber            l2   \n",
       "8                None           hinge            l1   \n",
       "9                None           hinge            l2   \n",
       "10               None  modified_huber            l1   \n",
       "11               None  modified_huber            l2   \n",
       "12           balanced           hinge            l1   \n",
       "13           balanced           hinge            l2   \n",
       "14           balanced  modified_huber            l1   \n",
       "15           balanced  modified_huber            l2   \n",
       "16               None           hinge            l1   \n",
       "17               None           hinge            l2   \n",
       "18               None  modified_huber            l1   \n",
       "19               None  modified_huber            l2   \n",
       "20           balanced           hinge            l1   \n",
       "21           balanced           hinge            l2   \n",
       "22           balanced  modified_huber            l1   \n",
       "23           balanced  modified_huber            l2   \n",
       "\n",
       "                                               params  split0_test_score  \\\n",
       "0   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.363216   \n",
       "1   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.554181   \n",
       "2   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.453724   \n",
       "3   {'alpha': 0.01, 'class_weight': None, 'loss': ...           0.572293   \n",
       "4   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.365258   \n",
       "5   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.553294   \n",
       "6   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.453566   \n",
       "7   {'alpha': 0.01, 'class_weight': 'balanced', 'l...           0.571331   \n",
       "8   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.112096   \n",
       "9   {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.529887   \n",
       "10  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.209099   \n",
       "11  {'alpha': 0.1, 'class_weight': None, 'loss': '...           0.549773   \n",
       "12  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.112096   \n",
       "13  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.533114   \n",
       "14  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.209099   \n",
       "15  {'alpha': 0.1, 'class_weight': 'balanced', 'lo...           0.551147   \n",
       "16  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.067824   \n",
       "17  {'alpha': 1, 'class_weight': None, 'loss': 'hi...           0.383757   \n",
       "18  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.067824   \n",
       "19  {'alpha': 1, 'class_weight': None, 'loss': 'mo...           0.459908   \n",
       "20  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.067824   \n",
       "21  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.386356   \n",
       "22  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.067824   \n",
       "23  {'alpha': 1, 'class_weight': 'balanced', 'loss...           0.459462   \n",
       "\n",
       "    split1_test_score  split2_test_score  split3_test_score  \\\n",
       "0            0.280596           0.336655           0.337768   \n",
       "1            0.469204           0.566214           0.558083   \n",
       "2            0.365099           0.439349           0.450615   \n",
       "3            0.503945           0.587871           0.579071   \n",
       "4            0.276239           0.336655           0.337768   \n",
       "5            0.471116           0.565860           0.554681   \n",
       "6            0.369883           0.439479           0.446313   \n",
       "7            0.502064           0.587942           0.579523   \n",
       "8            0.117756           0.103305           0.101308   \n",
       "9            0.389666           0.536054           0.539359   \n",
       "10           0.187025           0.187656           0.183445   \n",
       "11           0.433541           0.567434           0.554995   \n",
       "12           0.117756           0.103305           0.100598   \n",
       "13           0.387021           0.533606           0.542260   \n",
       "14           0.187025           0.104486           0.087106   \n",
       "15           0.434533           0.570827           0.556849   \n",
       "16           0.067824           0.065971           0.067824   \n",
       "17           0.313875           0.367384           0.364630   \n",
       "18           0.067824           0.065971           0.067824   \n",
       "19           0.362856           0.422737           0.427319   \n",
       "20           0.067824           0.065971           0.067824   \n",
       "21           0.333498           0.386497           0.398891   \n",
       "22           0.067824           0.065971           0.067824   \n",
       "23           0.388066           0.424172           0.426793   \n",
       "\n",
       "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "0            0.351563         0.333960        0.028409               15  \n",
       "1            0.564057         0.542348        0.036820                3  \n",
       "2            0.449041         0.431566        0.033579                9  \n",
       "3            0.584578         0.565552        0.031253                1  \n",
       "4            0.351563         0.333497        0.030469               16  \n",
       "5            0.561351         0.541260        0.035366                4  \n",
       "6            0.448359         0.431520        0.031148               10  \n",
       "7            0.585275         0.565227        0.032091                2  \n",
       "8            0.107609         0.108415        0.005968               19  \n",
       "9            0.539231         0.506839        0.058688                8  \n",
       "10           0.106139         0.174673        0.035440               17  \n",
       "11           0.562493         0.533647        0.050420                6  \n",
       "12           0.067833         0.100318        0.017361               20  \n",
       "13           0.540646         0.507330        0.060265                7  \n",
       "14           0.108651         0.139273        0.049041               18  \n",
       "15           0.572118         0.537095        0.051906                5  \n",
       "16           0.064781         0.066844        0.001257               21  \n",
       "17           0.396504         0.365230        0.028155               13  \n",
       "18           0.064781         0.066844        0.001257               21  \n",
       "19           0.468300         0.428224        0.037186               11  \n",
       "20           0.064781         0.066844        0.001257               21  \n",
       "21           0.306251         0.362299        0.035984               14  \n",
       "22           0.064781         0.066844        0.001257               21  \n",
       "23           0.437630         0.427225        0.023197               12  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## print all hyperparamters combo scores\n",
    "df_cv_res = pd.DataFrame(sgd_multi_tuner.cv_results_)\n",
    "df_cv_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_roc('SGD Multiclass', sgd_multi_tuner, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5-Fold CV Metrics: Multiclass\n",
      "Tuned One-vs-Rest (Logistic Regression) Model:\n",
      "Accuracy Average: 0.4673723396769014\n",
      "Precision Average: 0.5058313863100972\n",
      "F1 Score Average: 0.47044019035648893\n",
      "Confusion Matrix Average:\n",
      "[690.4 265.2 114.   68.8  53. ]\n",
      "[390.  408.2 236.2 115.   42.4]\n",
      "[233.2 218.  485.  183.   53.2]\n",
      "[192.4 119.6 194.8 461.2 185.8]\n",
      "[164.2  64.6  62.6 153.4 683.6]\n",
      "\n",
      "\n",
      "Tuned Gaussian Naive Bayes:\n",
      "Accuracy Average: 0.4320163693319067\n",
      "Precision Average: 0.4498658444282869\n",
      "F1 Score Average: 0.41998327389133044\n",
      "Confusion Matrix Average:\n",
      "[644.  124.2 124.4  82.  216.8]\n",
      "[345.2 291.4 222.6 127.8 204.8]\n",
      "[202.6 132.8 451.4 173.  212.6]\n",
      "[167.4  89.  165.8 371.4 360.2]\n",
      "[132.4  54.2  65.8 112.2 763.8]\n",
      "\n",
      "\n",
      "Tuned SGD Classifier:\n",
      "Accuracy Average: 0.4638771823530921\n",
      "Precision Average: 0.5252168881389154\n",
      "F1 Score Average: 0.46223585672451667\n",
      "Confusion Matrix Average:\n",
      "[768.6 218.2  91.4  57.2  56. ]\n",
      "[480.  367.8 207.   89.8  47.2]\n",
      "[279.6 190.6 489.4 150.   62.8]\n",
      "[226.4 110.2 210.  405.  202.2]\n",
      "[203.6  52.   50.8 144.8 677.2]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## print average k-fold CV metrics for optimally tuned models\n",
    "print(\"5-Fold CV Metrics: Multiclass\")\n",
    "\n",
    "print(\"Tuned One-vs-Rest (Logistic Regression) Model:\")\n",
    "oneVRest = OneVsRestClassifier(LogisticRegression(max_iter=200, C=1, penalty='l2', class_weight='balanced', solver='liblinear', fit_intercept=False, random_state=42))\n",
    "oneVRest.set_params(**oneVRest_tuner.best_params_)\n",
    "predictions = cv_metrics(oneVRest, 5)\n",
    "\n",
    "print(\"Tuned Gaussian Naive Bayes:\")\n",
    "gaussianNB.set_params(**gaussianNB_tuner.best_params_)\n",
    "predictions = cv_metrics(gaussianNB, 5, gaussian=True)\n",
    "\n",
    "print(f\"Tuned SGD Classifier:\")\n",
    "sgd_multi.set_params(**sgd_multi_tuner.best_params_)\n",
    "predictions = cv_metrics(sgd_multi, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tuned One-vs-Rest classifier appears to have the best performance, so I will use this to make my test predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "## save test predictions\n",
    "y_test_hat_multi = oneVRest.predict(X_test)\n",
    "out_results(y_test_hat_multi, \"multi\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model achieved a macro f1 score of 0.59201 on the test set on Kaggle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Processing and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 2)\n"
     ]
    }
   ],
   "source": [
    "## vectorize reviewText into TF-IDF matrices\n",
    "review_vectorizer = TfidfVectorizer(min_df=0.2,max_df=0.8,stop_words=\"english\") \n",
    "X = review_vectorizer.fit_transform(df_test['reviewText'].tolist())\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Data Annotation\n",
    "The 'category' column needs to be converted into numerical labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "## transform categorical column to numerical\n",
    "categories = df_test['category'].copy()\n",
    "labels = categories.unique()\n",
    "labels_idx = list(range(0, len(labels)))\n",
    "y = np.array(categories.replace(labels, labels_idx)).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: Model Selection and Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model: K-Mean Clustering\n",
    "To tune the `n_clusters` hyperparameter, I will construct an elbow graph and choose the optimal value based on the \"bend\" in the elbow graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/logan/opt/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "## construct and plot elbow graph\n",
    "ssd = []\n",
    "ks = range(4,8)\n",
    "for num_clusters in ks:\n",
    "    kmeans = KMeans(n_clusters=num_clusters)\n",
    "    kmeans.fit(X)\n",
    "    ssd.append(kmeans.inertia_)\n",
    "plt.plot(ks, ssd)\n",
    "plt.xlabel('K') \n",
    "plt.ylabel('Sum of squared distances') \n",
    "plt.title('Elbow Graph for Choosing K')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the above graph and the elbow test, `k=6` appears to be the best option for K in the KMeans classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMeans Cluster Model with optimal hyperparameters had a silhouette score of 0.9882771373157031 and a rand index of 0.5295491837692327\n"
     ]
    }
   ],
   "source": [
    "## fit and test model\n",
    "kmeans = KMeans(n_clusters=6)\n",
    "kmeans.fit(X)\n",
    "print('KMeans Cluster Model with optimal hyperparameters had a silhouette score of '+str(silhouette_score(X, kmeans.labels_))+' and a rand index of '+str(rand_score(y, kmeans.labels_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
